{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91ae938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/gcu/zgca,gpt-5-minimal/mols/gcu_conv2d_1010_42.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "all_mols = a['all_mols']\n",
    "len(all_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adbac11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('/root/nian/MOLLM/problem/gcu/prompt_info.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config['description']\n",
    "\n",
    "with open('/root/nian/MOLLM/problem/gcu/prompt_info.yaml','w') as f:\n",
    "    yaml.dump(config,f,allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d6b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个题目是要写燧原 GCU(TopsCC)算子, 下面是我给你总结的教程GCU 是燃原的 AI 计算加速设备。TopsCC 是基于 GCU 的编程平台，TopsCC 包含一套工具集和 runtime 库，支持 C/C++ 编程，可以生成在设备端和主机端运行的程序。本文件主要介绍如何在 GCU 上通过 TopsCC 进行算子编程。\n",
      "表 1‑2 词汇表：\n",
      "\n",
      "| 术语      | 描述                                   |\n",
      "|-----------|----------------------------------------|\n",
      "| GCU       | 燃原 AI 加速卡                         |\n",
      "| TopsCC    | 燃原编程平台                           |\n",
      "| clang     | C/C++ 编译器                           |\n",
      "| llvm      | 编译器套件                             |\n",
      "| Kernel    | 核函数，运行在设备端的程序             |\n",
      "| Fatbin    | 包含了设备端和主机端运行程序的二进制文件 |\n",
      "| DTE       | 数据搬运引擎                           |\n",
      "| RTC       | 运行时编译                             |\n",
      "| SIMT      | 单指令多线程                           |\n",
      "| SIP       | 硬件计算核心                           |\n",
      "| i20       | 第二代 GCU 推理卡                      |\n",
      "| GCU210    | 第二代 GCU 推理卡，和 i20 等价         |\n",
      "| TopsRider | 燃原 SDK 开发套件                     |\n",
      "---\n",
      "\n",
      "# 2 简介\n",
      "人工智能领域对计算性能的需求极高。GCU 作为强大的计算引擎，提供了必要的算力支撑。而 TopsCC 则扮演了编程平台的角色，它通过优化编程环境，使得 GCU 的计算潜能得到更充分的释放。TopsCC 通过扩展 C++ 语言，使得开发者能够以接近 C++ 的编程方式，高效地为 GCU 编写程序。\n",
      "GCU 具备多计算核心和多级存储的设计，这些架构特性会反映到具体的编程模型上。\n",
      "\n",
      "（图 2‑1 GCU 架构图）\n",
      "\n",
      "## 2.1 计算核心\n",
      "\n",
      "SIP 计算核心是燃原科技打造面向云端数据中心的人工智能训练一体芯片采用全新的通用计算单元 GCU‑CARE 架构，为深度学习提供强大的算力支持。计算核心支持标量、向量和张量计算。通过燃原科技自有知识产权的软硬件架构 TopsRider，可以广泛地支持视觉、语音、NLP、推荐、LLM 等各技术方向的模型训练与推理。i20 一共含 24 个计算核心。\n",
      "\n",
      "## 2.2 多级存储\n",
      "\n",
      "GCU 包含 L1–L3 三级存储。\n",
      "\n",
      "(图 2‑2 三级存储)\n",
      "\n",
      "L1: 每个计算核心内部包含了一个私有存储（L1）。i20 中每一个计算核心具有 1 M 的 L1。\n",
      "L2: 12 个计算核心可以组成一个计算簇，同一个 GCU 内包含多个计算簇。每个计算簇内的计算核心可以共享一个簇内的 24 M L2 共享存储。\n",
      "L3: GCU 拥有一个全局设备存储（L3），对所有计算簇可见，i20 的 L3 大小为 16 GB。\n",
      "L1、L2 的介质是 SRAM，L3 介质一般是 HBM 或者 GDDR。\n",
      "\n",
      "---\n",
      "\n",
      "# 3 TopsCC 编程模型\n",
      "\n",
      "## 3.1 概述\n",
      "\n",
      "### 3.1.1 函数类型限定符\n",
      "\n",
      "TopsCC 支持设备端和主机端混合编程，使用 __device__ 和 __global__ 标记设备端程序，使用 __host__ 标记主机端程序。没有标记的函数默认为主机端程序。\n",
      "\n",
      "示例代码：\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__global__ void foo() {\n",
      "    // TODO: add code here\n",
      "}\n",
      "\n",
      "int main(int argc, char **argv) {\n",
      "    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "\n",
      "    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "表 3‑1 函数类型限定符：\n",
      "\n",
      "| 函数类型限定符 | 执行                     | 调用                                                                 |\n",
      "|----------------|--------------------------|-----------------------------------------------------------------------|\n",
      "| __device__     | 在设备端运行的函数       | 可以被 __global__ 函数调用，但不能被 __host__ 函数调用                 |\n",
      "| __global__     | 在设备端运行的入口函数   | 只能由 __host__ 函数启动，不能被 __device__ 或其他 __global__ 函数调用 |\n",
      "| __host__       | 在主机端运行的函数       | 只能被 __host__ 函数调用                                             |\n",
      "\n",
      "说明：一个函数可以同时标记为 __device__ 和 __host__，这种函数在设备端和主机端都能被调用。没有标记的函数默认都是 __host__ 函数。\n",
      "\n",
      "### 3.1.2 线程模型\n",
      "\n",
      "TopsCC 支持类似 SIMT 的编程模型，多个 Thread 可同时执行同一份代码。Thread 的层次结构分为 Thread、Block 和 Grid 三层，每层可用 x、y、z 三个维度指定程序运行的层次结构。\n",
      "\n",
      "- **Thread**：对应一个标量或向量执行程序，物理上映射到一个计算核心 SIP 上执行。在线程内部可以通过 `threadIdx.x`、`threadIdx.y`、`threadIdx.z` 获取当前 thread 的坐标。\n",
      "- **Block**：包含一组 Thread，物理上映射到一组 SIP。在线程内部可以通过 `blockIdx.x`、`blockIdx.y`、`blockIdx.z` 获取当前 block 的坐标。可以使用 `blockDim.x`、`blockDim.y`、`blockDim.z` 指定 block 的维度大小，作为内核调用符 `<<<>>>` 的参数。\n",
      "  - 硬件特性：在 gcu210 上 block dims 的乘积最大为 12，即 `blockDim.x * blockDim.y * blockDim.z <= 12`。\n",
      "- **Grid**：包含一组 Block。可以使用 `gridDim.x`、`gridDim.y`、`gridDim.z` 指定 grid 的维度大小作为内核调用符 `<<<>>>` 的参数。\n",
      "  - 硬件特性：设备上 grid dims 的乘积最大为 2，即 `gridDim.x * gridDim.y * gridDim.z <= 2`。\n",
      "\n",
      "图 3‑1 thread 模型：线程按照 Thread → Block → Grid 三级结构组织，并映射到芯片上多个 SIP 计算核心和存储层级。\n",
      "\n",
      "TopsCC 支持 cooperative 模式。当一个 __global__ 函数（kernel）被标记为 cooperative 模式时，这个 kernel 会被运行时使用 `topsLaunchCooperativeKernel` 启动。在这种模式下 grid 中所有的 block 会同时运行。内核中可以使用 `__synchblocks()` 调用进行 block 间的同步。\n",
      "\n",
      "示例代码：\n",
      "```cpp\n",
      "__global__ __cooperative__ void foo() {\n",
      "    __synchblocks();\n",
      "}\n",
      "```\n",
      "\n",
      "### 3.1.3 存储模型\n",
      "\n",
      "i20 GCU 的存储系统结构如下图所示（图 3‑2）。用户视角可见以下地址空间：\n",
      "\n",
      "- `__device__`：全局的地址空间，所有 block 可见。对应硬件的全局设备存储（L3）。\n",
      "\n",
      "  ```c\n",
      "  __device__ int data[100];\n",
      "  ```\n",
      "\n",
      "说明：在 GCU 2.0 中，kernel/SIP 不直接访问 L3，需要由 DTE 将数据搬运到 L1 后访问。\n",
      "\n",
      "* `__constant__`：全局的常量地址空间，所有 thread 可见。对应硬件的全局设备存储（L3）。\n",
      "\n",
      "  ```c\n",
      "  __constant__ int a = 2;\n",
      "  ```\n",
      "\n",
      "* `__shared__`：block 内共享地址空间，block 内的 thread 可见。对应硬件的簇内共享存储（L2）。\n",
      "\n",
      "  ```c\n",
      "  __shared__ int data[100];        // static size shared memory\n",
      "  extern __shared__ int data2[];   // dynamic size shared memory\n",
      "  ```\n",
      "\n",
      "  说明：在 GCU 2.0 中，不允许直接访问 L2，只能用于 DTE 数据搬运操作。动态大小的 shared memory 每个 **global** 函数只能使用一个。每个计算簇最大支持 24 MB 的 shared memory。\n",
      "\n",
      "* 无修饰符变量：位于 thread 的私有地址空间，对应硬件的计算核心私有存储（L1）。\n",
      "\n",
      "  ```c\n",
      "  int data;\n",
      "  float data2[100];\n",
      "  ```\n",
      "\n",
      "* `__aligned__`：对于私有空间的存储，如果会被向量操作使用，需要使用 `__aligned__` 进行对齐。\n",
      "\n",
      "  ```c\n",
      "  __aligned__ int data[100];\n",
      "  ```\n",
      "\n",
      "### 3.1.4 内建的宏\n",
      "\n",
      "* `__TOPS_DEVICE_COMPILE__`：编译设备端代码时会被定义。\n",
      "* `__GCU_ARCH__`：由 3 位数字组成；i20 的值为 210。\n",
      "\n",
      "## 3.2 编程接口\n",
      "\n",
      "TopsCC 通过扩展 C++，提供设备端和主机端的运行时库来支持基于 C++ 的编程。编译方式包括两种：离线编译和运行时编译。\n",
      "\n",
      "\n",
      "### 图 3‑3 TopsCC 离线编译\n",
      "\n",
      "离线编译流程中，C/C++ 源代码与 kernel 库、host 库一起经由编译器生成 fatbin 文件，运行时由 CPU 和 GCU 装载执行。本次竞赛采用离线编译方式。\n",
      "\n",
      "### 3.2.2 运行时编译\n",
      "\n",
      "运行时需要实时编译源文件时，可使用运行时编译（RTC）接口。主机端接口支持嵌入源文件编译并运行：仅设备端代码会被编译并加载，主机端代码会被忽略，生成的可执行文件会缓存在内存中，便于重复调用。\n",
      "\n",
      "### 3.2.3 一个简单的程序例子\n",
      "\n",
      "示例程序如下。它在 GCU 上启动一个空的 kernel 函数 `foo`，`dim3(1,1,1)` 与 `1` 等价。\n",
      "\n",
      "```c++\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__global__ void foo() { }\n",
      "\n",
      "int main(int argc, char **argv) {\n",
      "    // 启动一个 block，block 中有一个 thread 执行 kernel 函数 foo\n",
      "    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "\n",
      "    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "**内核调用运算符 `<<<grid_dim, block_dim, share_memory_sz, stream>>>`** 接受 4 个参数：\n",
      "\n",
      "1. `grid_dim`：Grid 的尺寸，可参照线程层次结构选择。\n",
      "2. `block_dim`：Block 的尺寸，同样参照线程层次结构。\n",
      "3. `share_memory_sz`：kernel 在 block 中申请的动态共享数组字节数（如 `__shared__ int data[]`）。默认值为 0 Byte；如果申请大小超过硬件共享内存限制，程序会出错。\n",
      "4. `stream`：流对象，默认为空；用于异步调用。\n",
      "\n",
      "建议在 kernel 调用后使用 `topsGetLastError` 检查执行是否成功。\n",
      "\n",
      "**资源限制：**最大 grid 尺寸可以通过 `topsGetDeviceProperties` 查询。gcu210 硬件限制为 `gridDim.x ≤ 65536`、`gridDim.y ≤ 256`、`gridDim.z ≤ 256`。对于 cooperative 模式，grid 的总大小 `gridDim.x * gridDim.y * gridDim.z` 不得超过设备的 `multiProcessorCount`（gcu210 为 2）。block 的总线程数不得超过设备 `maxThreadsPerMultiProcessor`（gcu210 为 12）。下面代码展示如何查询这些属性并设置 block 大小：\n",
      "\n",
      "```c++\n",
      "topsDeviceProp_t prop;\n",
      "int deviceId = 0;\n",
      "topsGetDeviceProperties(&prop, deviceId);\n",
      "\n",
      "dim3 blockDims;\n",
      "blockDims.x = prop.maxThreadsPerMultiProcessor;\n",
      "blockDims.y = 1;\n",
      "blockDims.z = 1;\n",
      "\n",
      "foo<<<1, blockDims>>>();\n",
      "```\n",
      "\n",
      "### 3.2.4 设备端编程\n",
      "\n",
      "#### 打印和断言\n",
      "\n",
      "在 GCU 2.0 中 kernel 直接访问的存储地址只支持私有地址空间（L1）和 `__constant__` 地址空间；对于 `__shared__` 和 `__device__` 地址空间，需要通过 DTE 将数据搬运到 L1 后访问。使用 `printf` 和 `assert` 有以下限制：\n",
      "\n",
      "* kernel 函数中可以使用 `printf`，但格式字符串必须是常量，且不支持 `%p` 和 `%.` 等格式。\n",
      "* `assert` 默认在 O3 优化级别关闭，如需开启可在编译时定义 `-DTOPS_ENABLE_ASSERT`。\n",
      "* 当 kernel 代码调用 `printf` 或 `assert` 时，运行时处于 debug 同步模式，此时同一 stream 上函数的执行是同步的。\n",
      "\n",
      "#### 3.2.4.1 数据流编程\n",
      "\n",
      "TopsCC 使用 DTE（Data Transfer Engine）接口进行数据搬运，允许计算与搬运并行。\n",
      "一次数据搬运，通常包含以下流程：  \n",
      "1. 声明DTE上下文\n",
      "2. 使用mdspan给memory加入信息\n",
      "3. 使用ctx操作接口\n",
      "\n",
      "一个DTE编程示例如下，将数据从设备端指针from线性拷贝到设备端指针to（from和to所指向的均为L3上的内存）：\n",
      "```c\n",
      "__global__ void copy_d2d(int *from, int *to, size_t N) {\n",
      "  __private_dte__tops_dte_ctx_t ctx;  // Declare a DTE Context\n",
      "  tops::dte_scope s(ctx);             // Initalize DTE Context\n",
      "\n",
      "  tops:: mdspan src(tops::Global, from, N);   // Add shape info for source\n",
      "  tops::mdspan dst(tops::Global, to, N);      // Add shape info for dest\n",
      "\n",
      "  tpos::memcpy(ctx, dst, src);        // Copy data from source to dest\n",
      "}\n",
      "```\n",
      "\n",
      "##### 支持的标量数据类型\n",
      "\n",
      "* 基本类型：`bool`、`char`、`unsigned char`、`short`、`unsigned short`、`int`、`unsigned int`、`float`。\n",
      "* 扩展浮点类型：`tops::half` 和 `tops::bfloat`。例如可通过 `#include <tops/half.h>` 和 `#include <tops/bfloat.h>` 引入。\n",
      "\n",
      "代码：ops::haf 和tops::bfloat 的定义方式示例\n",
      "```c\n",
      "#include<tops/half.h>\n",
      "#include<tops/bfloat.h>\n",
      "\n",
      "__device__ void test(){\n",
      "  tops::half value1(0.2);\n",
      "  tops::bfloat value2(2.4);\n",
      "}\n",
      "```\n",
      "\n",
      "##### DTE Context（DTE 上下文）\n",
      "\n",
      "在 `__shared__` 或 `__device__` 地址空间上的数据需通过 DTE 搬运。使用 DTE 前需声明 DTE 上下文，TopsCC 支持三种类型：\n",
      "\n",
      "* **Block 级共享 DTE Context**：`__shared_dte__ tops_dte_ctx_t ctx[n];`——block 内线程共享 DTE 上下文，只能支持 Global 和 Shared 之间的数据传输。\n",
      "* **Block 级私有 DTE Context**：`__private_dte__ tops_dte_ctx_t ctx;`——Block 级的 DTE 资源，只能支持 Global 和 Shared 之间的数据传输。\n",
      "* **Thread 级 DTE Context**：`tops_dte_ctx_t ctx;`——线程私有 DTE 资源，可支持 Global、Shared 和 Private 之间的数据传输。\n",
      "\n",
      "##### mdspan\n",
      "\n",
      "TopsCC使用一种名为`mdspan`的数据结构来给设备地址附加额外的信息（如维度、形状、所属内存空间、总大小等），其构造函数参数包括：\n",
      "\n",
      "1. 所属地址空间（可选）：`tops::Global`、`tops::Shared`、`tops::Private`，对应 L3/L2/L1。\n",
      "2. 起始地址指针。\n",
      "3. 形状维度大小列表。\n",
      "\n",
      "DTE相关结构都使用`mdspan`作为配置参数。\n",
      "\n",
      "示例：声明 `mdspan` 的两种方式：\n",
      "\n",
      "```c++\n",
      "// method 1\n",
      "tops::mdspan src1(tops::Global, from, N, H, W, C);\n",
      "tops::mdspan src2(from, N, H, W, C);\n",
      "\n",
      "// method 2\n",
      "auto shape = {N, H, W, C};\n",
      "tops::mdspan src3(tops::Global, from, shape);\n",
      "tops::mdspan src4(from, shape);\n",
      "```\n",
      "\n",
      "其中 `from` 为某数据类型的起始地址，DTE 操作一般支持九种数据类型（`int8_t`、`uint8_t`、`int16_t`、`uint16_t`、`int32_t`、`uint32_t`、`tops::bfloat`、`tops::half` 和 `float`）。`shape`是数据的形状，`shape[0]` 为数据最高维度的大小，通常对应内存中步幅最大（最不连续）的那一维。\n",
      "\n",
      "##### DTE 支持的操作模式\n",
      "\n",
      "DTE 支持两种使用模式：\n",
      "\n",
      "1. **配置与启动分离模式**：适用于计算与搬运流水并行的场景。先调用配置接口，再调用启动接口。支持同步和异步两种启动方式。\n",
      "\n",
      "   * **同步启动**（`trigger_and_wait`）：\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     ctx.config_memcpy(dst, src);\n",
      "     ctx.trigger_and_wait();\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "   * **异步启动**（`trigger`）：返回 `tops::event`，可用 `tops::wait` 等待。\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     ctx.config_memcpy(dst, src);\n",
      "     tops::event ev = ctx.trigger();\n",
      "     tops::wait(ev);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "2. **配置和启动合并模式**：代码更简洁，同时支持同步和异步两种方式。\n",
      "\n",
      "   * **同步启动**：\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     tops::memcpy(ctx, dst, src);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "   * **异步启动**：调用以 `_async` 结尾的函数返回 `tops::event`，可用 `tops::wait` 等待。\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     auto ev = tops::memcpy_async(ctx, dst, src);\n",
      "     tops::wait(ev);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "##### 全量配置接口\n",
      "\n",
      "全量配置需要完整设置 DTE 的参数。多数搬运接口含有两个 `mdspan` 参数，第一个为目标地址对象，第二个为源地址对象。常用接口见下表：\n",
      "\n",
      "| 接口                                    | 描述                                                                             |\n",
      "| ------------------------------------- | ------------------------------------------------------------------------------ |\n",
      "| `ctx.config_memcpy(dst, src)`         | 以 `src` 总大小拷贝 `src` 到 `dst`，用户需确保 `dst` 足够大。                                   |\n",
      "| `ctx.config_memset(dst, const_value)` | 将 `dst` 指定的内存设置为 `const_value`。                                                |\n",
      "| `ctx.config_slice(dst, src, offset)`  | 按 `dst` 指定的形状和 `offset` 指定的位置从 `src` 中拷贝数据到 `dst`。若 `dst` 大小或偏置超出 `src`，将自动填充。**切片操作：** 在GCU的应用中，通常处理的数据量很大，而GCU的执行单元 SIP 所能访问的SIP memory比较小，所以在数据处理上，需要将大块数据切片搬运到 SIP memory，供SIP处理加工，这种操作称为slice，你想的操作称为deslice。根据数据处理需求，可选择以下切片方式：(1)**线性切片**：依次将相应的数据片段搬运到SIP memory中。一个典型的例子：如果要处理的是一个2维数组，而SIP每次可以处理数组中的完整一行，则可以对该数组进行线性切片。  (2)**等维切片**：对多维数组同时沿各维切割成多个形状相同的块（将一个 N 维数组切为多个小的 N 维数组）。一个典型的例子：将一个3维数组切分成多个小形状的3维数组，可以理解为把一个大的立方体切分成多个小立方体。 (3)**多维切片**：仅在指定的部分维度上进行切片。可以把线性切片和等维切片理解为多维切片的两个特例|\n",
      "| `ctx.config_deslice(dst, src, offset)`                            | 把 `src` 指定的数据拷贝并覆盖到 `dst` 的 `offset` 位置。                 |\n",
      "| `ctx.config_transpose(dst, src, layout)`                          | 按 `layout` 对 `src` 进行转置并拷贝至 `dst`，layout的数据排列定义为形如{0,1,2,3}。                       |\n",
      "| `ctx.config_slice_transpose(dst, src, offset, layout)`            | slice和transpose的组合，先对 `src` 切片，再按 `layout` 转置切片并放入 `dst`。                   |\n",
      "| `ctx.config_transpose_deslice(dst, src, offset, layout)`          | transpose和deslice的组合，先对 `src` 按 `layout` 转置，再拷贝并覆盖到 `dst` 指定位置。               |\n",
      "| `ctx.config_pad(dst, src, pad_low, pad_high, pad_mid, pad_value)` | 垫片操作，把src指定的数据，按照dst所指定的形状和大小，用pad_value的值设置到src的首部（pad_low有效），尾部（pad_high有效），或者中间（pad_mid有效），并把结果移动到dst所指的位置。 |\n",
      "| `ctx.config_mirror_tb(dst, src)`                                  | 按第一维（X 轴，shape的最后一个元素）翻转 `src`，结果放入 `dst`。                        |\n",
      "| `ctx.config_mirror_lr(dst, src)`                                  | 按第二维（Y 轴，shape的倒数第二个元素）翻转 `src`，结果放入 `dst`。                        |\n",
      "| `ctx.config_broadcast(dst, src)`                                  | 根据 `src` 到 `dst` 维度变化扩展 `src` 数据，结果放入 `dst`。             |\n",
      "\n",
      "##### 增量配置接口\n",
      "\n",
      "增量配置接口是指在完成一次全量 DTE 配置后，后续仅对发生变化的部分调用相应的API进行配置，可以减少DTE配置时间。增量配置接口可以在不修改DTE数据搬运操作的类型的情况下改变 DTE context 的配置。\n",
      "\n",
      "* **基础增量接口：**\n",
      "\n",
      "| 接口                       | 描述          |\n",
      "| ------------------------ | ----------- |\n",
      "| `ctx.set_dst_addr(addr)` | 设置新的 dst 地址 |\n",
      "| `ctx.set_src_addr(addr)` | 设置新的 src 地址 |\n",
      "| `ctx.set_dst_offset(dim, offset)`               | 设置 `dst` 在维度 `dim` 的偏移 |\n",
      "| `ctx.set_src_offset(dim, offset)`               | 设置 `src` 在维度 `dim` 的偏移 |\n",
      "| `ctx.set_dst_dim_size(dim, size)`               | 设置 `dst` 在维度 `dim` 的大小 |\n",
      "| `ctx.set_src_dim_size(dim, size)`               | 设置 `src` 在维度 `dim` 的大小 |\n",
      "| `ctx.set_total_size(size)`                      | 设置整体大小，常用于 memcpy      |\n",
      "| `ctx.set_transpose_layout(layout)`              | 设置转置的 `layout`         |\n",
      "| `ctx.set_pad_config(pad_low, pad_high, ad_mid)` | 设置 pad 参数              |\n",
      "\n",
      "##### 启动和同步接口\n",
      "\n",
      "* **启动接口（配置与启动分离时使用）：**\n",
      "\n",
      "| 接口                       | 描述                     |\n",
      "| ------------------------ | ---------------------- |\n",
      "| `ctx.trigger()`          | 触发 DTE 操作，返回一个 `event` |\n",
      "| `ctx.trigger_and_wait()` | 触发 DTE 操作并等待完成         |\n",
      "\n",
      "* **同步接口：**\n",
      "\n",
      "| 接口            | 描述              |\n",
      "| ------------- | --------------- |\n",
      "| `wait(event)` | 等待指定 `event` 完成 |\n",
      "\n",
      "##### 配置和启动合并接口\n",
      "\n",
      "在接口中，ctx参数是指定DTE上下文，dst是mdspan指定的数据搬运的输出位置，src是mdspan指定的数据搬运的输入位置。\n",
      "使用下列函数可同时完成配置和启动，均支持九种数据类型，并提供 `_async` 后缀的异步版本：\n",
      "\n",
      "| 接口                                                                | 描述                                       |\n",
      "| ----------------------------------------------------------------- | ---------------------------------------- |\n",
      "| `tops::memcpy(ctx, dst, src)`                                     | 以 `src` 总大小拷贝 `src` 到 `dst`              |\n",
      "| `tops::memset(ctx, dst, const_value)`                             | 将 `dst` 指定的内存设置为 `const_value`           |\n",
      "| `tops::slice(ctx, dst, src, offset)`                              | 按 `dst` 形状和 `offset` 从 `src` 拷贝数据到 `dst` |\n",
      "| `tops::deslice(ctx, dst, src, offset)`                            | 把 `src` 数据拷贝并覆盖到 `dst` 指定位置              |\n",
      "| `tops::transpose(ctx, dst, src, layout)`                          | 按 `layout` 转置 `src` 并拷贝至 `dst`           |\n",
      "| `tops::slice_transpose(ctx, dst, src, offset, layout)`            | 先切片再转置再拷贝至 `dst`                         |\n",
      "| `tops::transpose_deslice(ctx, dst, src, offset, layout)`          | 先转置再覆盖到 `dst`                            |\n",
      "| `tops::pad(ctx, dst, src, pad_low, pad_high, pad_mid, pad_value)` | 按形状填补并拷贝至 `dst`                          |\n",
      "| `tops::mirror_tb(ctx, dst, src)`                                  | 第一维翻转并拷贝至 `dst`                          |\n",
      "| `tops::mirror_lr(ctx, dst, src)`                                  | 第二维翻转并拷贝至 `dst`                          |\n",
      "| `tops::broadcast(ctx, dst, src)`                                  | 按维度变化扩展 `src` 并拷贝至 `dst`                 |\n",
      "\n",
      "##### DTE 软件流水编程\n",
      "\n",
      "使用异步编程接口可以完成数据流的软件流水，把计算和数据搬运的并行起来，从而达到更好的计算性能。\n",
      "代码：计算和数据搬运流水并行示例代码\n",
      "\n",
      "```c\n",
      "    tops_dte_ctx_t ctxs[2][2];\n",
      "    tops::event evs[2][2];\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        for (int j = 0; j < 2; j++)\n",
      "            ctxs[i][j].init();\n",
      "\n",
      "    __aligned__ int input_buffer[2][tile_size];\n",
      "    __aligned__ int output_buffer[2][tile_size];\n",
      "\n",
      "    tops::mdspan input(tops::Global, in, tile_size);  // in 为 L3 指针\n",
      "    tops::mdspan output(tops::Global, out, tile_size); // out 为 L3 指针\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        ctxs[0][i].config_memcpy(tops::mdspan(tops::Private,\n",
      "                               input_buffer[i], tile), input, tile_size);\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        ctxs[1][i].config_memcpy(output,\n",
      "                               tops::mdspan(tops::Private, output_buffer[i], tile), tile_size);\n",
      "\n",
      "    evs[0][0] = ctxs[0][0].trigger();\n",
      "    int iter = 0;\n",
      "\n",
      "    for (int i = 0; i < size; i += tile_size) {\n",
      "        evs[0][iter%2].wait();\n",
      "        if (i + tile_size < size) {\n",
      "            ctxs[0][(iter+1)%2].set_src_addr(in + i);\n",
      "            evs[0][(iter+1)%2] = ctxs[0][(iter+1)%2].trigger();\n",
      "        }\n",
      "\n",
      "        // do computation\n",
      "        foo(input_buffer[iter%2], output_buffer[iter%2]);\n",
      "\n",
      "        if (i != 0) {\n",
      "            evs[1][(iter-1)%2].wait();\n",
      "        }\n",
      "        ctxs[1][iter%2].set_dst_addr(output + i);\n",
      "        evs[1][iter%2] = ctxs[1][iter%2].trigger();\n",
      "        if (i + tile_size >= size) {\n",
      "            evs[1][iter%2].wait();\n",
      "        }\n",
      "        iter++;\n",
      "    }\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        for (int j = 0; j < 2; j++)\n",
      "            ctxs[i][j].destroy();\n",
      "```\n",
      "\n",
      "默认情况下，DTE 的非法行为不会报错，加上宏 -DTOPS_ENABLE_DTE_CHECK 会检查非法行为。\n",
      "\n",
      "#### 3.2.4.2 计算流程编程\n",
      "\n",
      "一般地，topscc 支持标量计算。计算只能发生在线程内部，且从 L1 中读取数据。对于 L1 的地址，可以直接使用下标索引数据。\n",
      "\n",
      "```c\n",
      "    __aligned__ int inp[128];\n",
      "    __aligned__ int out[128];\n",
      "    for (size_t i = 0; i < 128; ++i) {\n",
      "        out[i] = inp[i] * inp[i];\n",
      "    }\n",
      "```\n",
      "\n",
      "此外，TopsCC 提供了向量接口和矩阵计算接口，以利用 GCU 的 1D 和 2D 算力。\n",
      "\n",
      "##### 1D 计算流编程\n",
      "\n",
      "一个 `vector` 类型默认长度为 **128** 字节，支持的 `vector` 类型如下所示。\n",
      "\n",
      "###### 表 3-7 支持的 `vector` 类型\n",
      "\n",
      "| 类型        | 说明                    | 默认的元素个数                                   |\n",
      "| --------- | --------------------- | ----------------------------------------- |\n",
      "| `vchar`   | `char` 向量类型           | 一个 `vchar` 向量包含 **128** 个 `int8_t`        |\n",
      "| `vuchar`  | `unsigned char` 向量类型  | 一个 `vuchar` 向量包含 **128** 个 `uint8_t`      |\n",
      "| `vshort`  | `short` 向量类型          | 一个 `vshort` 向量包含 **64** 个 `int16_t`       |\n",
      "| `vushort` | `unsigned short` 向量类型 | 一个 `vushort` 向量包含 **64** 个 `uint16_t`     |\n",
      "| `vint`    | `int` 向量类型            | 一个 `vint` 向量包含 **32** 个 `int`             |\n",
      "| `vuint`   | `unsigned int` 向量类型   | 一个 `vuint` 向量包含 **32** 个 `unsigned int`   |\n",
      "| `vfloat`  | `float` 向量类型          | 一个 `vfloat` 向量包含 **32** 个 `float`         |\n",
      "| `vhalf`   | `half` 向量类型           | 一个 `vhalf` 向量包含 **64** 个 `tops::half`     |\n",
      "| `vbfloat` | `bfloat` 向量类型         | 一个 `vbfloat` 向量包含 **64** 个 `tops::bfloat` |\n",
      "\n",
      "> 支持的 `vector` 操作包括：\n",
      "\n",
      "###### 表 3-8 支持的 `vector` 操作（I）\n",
      "\n",
      "| 接口           | 描述                                                                                       |\n",
      "| ------------ | ---------------------------------------------------------------------------------------- |\n",
      "| `vload`      | 从指定地址开始读取一个向量数据。`vload` 访问的地址需要对齐，即需要用 `__aligned__` 修饰。例如：`auto v = vload<vint>(addr);` |\n",
      "| `vstore`     | 存储一个向量数据到某个指定地址。例如：`vstore(value, addr);`                                                |\n",
      "| `vlength`    | 根据给定的数据类型，返回对应的 `vector` 计算所支持的向量长度。例如：`__aligned__ int buf[tops::vlength<vint>()]`      |\n",
      "| `vzero`      | 返回一个向量，所有值都设置为 `0`                                                                       |\n",
      "| `vadd`       | 返回两个向量的和。例如：`vint sum = tops::vadd(lhs, rhs)`                                            |\n",
      "| `vsub`       | 返回两个向量的差。例如：`vint diff = tops::vsub(lhs, rhs)`                                           |\n",
      "| `vmul`       | 返回两个向量的乘积。例如：`vint prdt = tops::vmul(lhs, rhs)`                                          |\n",
      "| `vdiv`       | 返回两个向量的商。例如：`vint quot = tops::vdiv(lhs, rhs)`                                           |\n",
      "| `vmod`       | 返回两个向量的模。例如：`vint md = tops::vmod(lhs, rhs)`                                             |\n",
      "| `vrem`       | 返回两个向量的余数。例如：`vint rm = tops::vrem(lhs, rhs)`                                            |\n",
      "| `vsign`      | 返回一个向量中每个元素的“符号”型，正数返回 1，负数返回 −1。例如：`vint sgn = tops::vsign(v)`                          |\n",
      "| `vbroadcast` | 将一个标量的值赋给向量的所有成员。例如：`vint brd = tops::vbroadcast(int2)`                                  |\n",
      "| `vcast`      | 因为向量类型不支持隐式转换，所以可以用这个函数进行**显示类型转换**                                                      |\n",
      "| `vbitcast`   | 将一个向量强制转换为另外一个相同大小的向量。例如：`vchar cv = tops::vbitcast(iv)`                                 |\n",
      "| `vsin`       | 返回一个向量每个元素的正弦，仅支持 `vfloat` 类型。例如：`auto vsn = tops::vsin(fv)`                             |\n",
      "| `vasin`      | 返回一个向量每个元素的反正弦，仅支持 `vfloat` 类型。例如：`auto vasn = tops::vasin(fv)`                          |\n",
      "| `vsinh`  | 返回一个向量每个元素的双曲正弦，仅支持 `vfloat` 类型。例如：`auto vhs = tops::vsinh(fv)`                                               |\n",
      "| `vasinh` | 返回一个向量每个元素的反双曲正弦，仅支持 `vfloat` 类型。例如：`auto vahs = tops::vasinh(fv)`                                            |\n",
      "| `vcos`   | 返回一个向量每个元素的余弦，仅支持 `vfloat` 类型。例如：`auto vcs = tops::vcos(fv)`                                                  |\n",
      "| `vcosh`  | 返回一个向量每个元素的双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhcs = tops::vcosh(fv)`                                              |\n",
      "| `vacos`  | 返回一个向量每个元素的反余弦，仅支持 `vfloat` 类型。例如：`auto vacs = tops::vacos(fv)`                                               |\n",
      "| `vacosh` | 返回一个向量每个元素的反双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhacs = tops::vacosh(fv)`                                           |\n",
      "| `vabs`   | 返回一个向量每个元素的绝对值，仅支持 `vfloat` 类型。例如：`auto vabso = tops::vabs(fv)`                                               |\n",
      "| `vcbrt`  | 返回一个向量每个元素的立方根，仅支持 `vfloat` 类型。例如：`auto vcbr = tops::vcbrt(fv)`                                               |\n",
      "| `vtan`   | 返回一个向量每个元素的正切，仅支持 `vfloat` 类型。例如：`auto vtn = tops::vtan(fv)`                                                  |\n",
      "| `vatan`  | 返回一个向量每个元素的反正切，仅支持 `vfloat` 类型。例如：`auto vatn = tops::vatan(fv)`                                               |\n",
      "| `vatan2` | 将两个向量每个元素分别相除，再对结果进行反正切，仅支持 `vfloat` 类型。例如：`auto vatan2 = tops::vatan2(fv1, fv2)`                             |\n",
      "| `vneg`   | 返回一个向量的符号相反的值，支持所有符号类型。例如：`auto vng = tops::vneg(fv)`                                                         |\n",
      "| `vsqrt`  | 返回一个向量每个元素的平方根，仅支持 `vfloat` 类型。例如：`auto vsqt = tops::vsqrt(fv)`                                               |\n",
      "| `vrsqrt` | 返回一个向量每个元素的**反平方根**，仅支持 `vfloat` 类型。例如：`auto vrsqt = tops::vrsqrt(fv)`                                        |\n",
      "| `vfloor` | 返回一个向量每个元素的**向下取整**（最接近且不大于自身的整数），仅支持 `vfloat` 类型。例如：`auto vflr = tops::vfloor(fv)`                           |\n",
      "| `vceil`  | 返回一个向量每个元素的**向上取整**（最接近且不小于自身的整数），仅支持 `vfloat` 类型。例如：`auto vcl = tops::vceil(fv)`                             |\n",
      "| `vround` | 返回一个向量每个元素**最接近**的整数，仅支持 `vfloat` 类型。例如：`auto vrnd = tops::vround(fv)`                                        |\n",
      "| `vtrunc` | 按截断规则 `trunc(x) = x >= 0 ? floor(x) : ceil(x)` 处理向量每个元素返回，仅支持 `vfloat` 类型。例如：`auto vtrc = tops::vtrunc(fv)`   |\n",
      "| `vrint`  | 和 `vround` 很像，例如把 `x=5.5` 的浮点数，`round` 会处理成 `+1`，`rint` 是 `×`；仅支持 `vfloat` 类型。例如：`auto vri = tops::vrint(fv)` |\n",
      "| `vexp`   | 按输入向量的每个元素作为数学常数 `e` 的指数计算后，返回一个**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto vxp = tops::vexp(fv)`                     |\n",
      "| `vexpm1` | 按输入向量的每个元素作为指数的 **`e^x - 1`** 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxpm = tops::vexpm1(fv)`                |\n",
      "| `vexp2`  | 按输入向量的每个元素为 2 的指数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxp2 = tops::vexp2(fv)`                              |\n",
      "| `vlog`   | 按输入向量的每个元素为数学常数 `e` 的对数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg = tops::vlog(fv)`                          |\n",
      "| `vlog1p`    | 按输入向量的每个元素加 1 后作自然对数计算（`log(1+x)`），返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlgp = tops::vlog1p(fv)`                     |\n",
      "| `vlog2`     | 按输入向量的每个元素为 2 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg2 = tops::vlog2(fv)`                                     |\n",
      "| `vlog10`    | 按输入向量的每个元素为 10 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg10 = tops::vlog10(fv)`                                  |\n",
      "| `vlogb`     | 按输入向量的每个元素以 10 为底的对数，只保留**整数部分**，并返回**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto v lgb = tops::vlogb(fv)`                    |\n",
      "| `vilogb`    | 按输入向量的每个元素以 10 为底的对数，只保留结果的**整数部分**，并返回一个**整数型**向量，仅支持 `vfloat` 类型。例如：`auto vilgb = tops::vilogb(fv)`               |\n",
      "| `vpower`    | 按第一个输入向量的每个元素为底数、第二个输入向量的对应元素为指数计算，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vpw = tops::vpower(fv1, fv2)`               |\n",
      "| `vgelu`     | 计算输入向量每个元素的高斯误差线性单元，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vglu = tops::vgelu(fv)`                                    |\n",
      "| `vsoftplus` | 按照规则 `vlog(vexp(v)+1)` 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vstp = tops::vsoftplus(fv)`                          |\n",
      "| `vsigmoid`  | 计算输入向量每个元素的 Sigmoid 函数，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vsigmoid(fv)`                               |\n",
      "| `vdim`      | 计算第一个输入向量和第二个向量的差值，如果差值是个负数则返回 `0`，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vdim(fv1, fv2)`                 |\n",
      "| `vhypot`    | 以第一个向量每个元素的直角边，以及第二个向量的对应元素作为第二直角边，计算相应的斜边，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vhypot(fv1, fv2)`    |\n",
      "| `vcopysign` | 以第二个向量的每个元素的符号，作为第一个向量对应元素的符号，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vcopysign(fv1, fv2)`                |\n",
      "| `visnan`    | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素不是 `NaN`，其它位代表 `NaN`，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visnan(fv)`       |\n",
      "| `visfinite` | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素是 `NaN` 或者 `INF`，其它代表不是，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visfinite(fv)` |\n",
      "| `vmax`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最大**值组成，支持所有类型。例如：`auto vmx = tops::vmax(v1, v2)`                                      |\n",
      "| `vmin`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最小**值组成，支持所有类型。例如：`auto vmn = tops::vmin(v1, v2)`                                      |\n",
      "| `vand`      | 按照两个输入向量的位计算“与”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vand(v1, v2)`                                              |\n",
      "| `vor`       | 按照两个输入向量的位计算“或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vor(v1, v2)`                                               |\n",
      "| `vxor`      | 按照两个输入向量的位计算“异或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vxor(v1, v2)`                                             |\n",
      "| `vnot`    | 按照两个输入向量的位计算“非”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vnot(v1, v2)`                                                    |\n",
      "| `vshl`    | 按照向量 `v` 中的每个元素指定的位数，按位向左移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshl(v1, v2)`          |\n",
      "| `vshr`    | 按照向量 `v` 中的每个元素指定的位数，按位向右移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshr(v1, v2)`          |\n",
      "| `vshli`   | 按照参数 `is` 指定的位数，按位向左移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshli(iv, is)`                 |\n",
      "| `vshri`   | 按照参数 `is` 指定的位数，按位向右移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshri(iv, is)`                 |\n",
      "| `vselect` | 按照第一个向量每个元素的条件（`0` 代表否），选择第二个向量对应元素（条件为是）或第三个（条件为否），并返回和后两个向量相同的类型的向量，支持所有类型。例如：`auto vsel = tops::vselect(vcnd, v1, v2)` |\n",
      "\n",
      "#### 3.2.4.2 2D 计算流编程\n",
      "\n",
      "（在 2D 计算相关题目里，会在题目说明中提供 2DAPI 使用方法。）\n",
      "\n",
      "#### 3.2.4.3 同步\n",
      "\n",
      "TopsCC 支持 **Block** 内的所有 **Thread** 同步，以及整个 **Grid** 的全局同步。\n",
      "\n",
      "* `__syncthreads`：Block 内所有 Thread 做一次同步。\n",
      "* `__synclockblocks`：Grid 内所有 Thread 做一次同步。\n",
      "\n",
      "> 说明：使用 `__synclockblocks` 的 `kernel` 需必须声明为 `__cooperative__`。\n",
      "\n",
      "### 3.2.5 主机端编程\n",
      "\n",
      "> 注：本次竞赛主要考察设备端编程，主机端编程部分作为参考，帮助参赛者理解主机侧。\n",
      "\n",
      "主机端运行时实现依赖 `TopsRT` 库中，基于 TopsCC 开发的应用程序会动态链接到 `libtopsrt.so`。运行时所有接口都以 `tops` 为命名前缀。运行时主要负责以下类别的管理：\n",
      "\n",
      "* 执行环境：描述了主机运行时的设备管理和初始化过程。\n",
      "* 存储系统：描述了运行时感知的存储管理系统。\n",
      "* 异步并行：描述了在不同层面上如何通过运行时接口实现异步并行。\n",
      "* 多设备：描述了跨多个设备编程时的相关接口行为。\n",
      "\n",
      "#### 3.2.5.1 互斥限制\n",
      "\n",
      "使用 `shared` 类型时，一个 **Block** 中只能有一个 `thread`（对应一个 **SIP**）执行 L3->L2 内存复制。\n",
      "\n",
      "#### 3.2.5.2 存储系统\n",
      "\n",
      "TopsCC 编程模型下假设系统由主机端和设备端组成，二者有独立的存储：**主存**和**设备内存**。Kernel 主要在设备内存中工作，主机运行时需要负责设备内存的**分配、释放、拷贝，以及在主存和设备内存间的数据搬运**。\n",
      "\n",
      "#### 3.2.5.3 设备内存\n",
      "\n",
      "当前设备内存为**线性内存**，内存句柄中仅包含地址信息，不包含维度解释、切片（tiling）等信息。\n",
      "当前设备地址空间为设备物理地址，因此和主机地址空间没有统一。设备地址空间的位宽如下所示：\n",
      "\n",
      "**表 3-9 设备内存**\n",
      "\n",
      "| 设备地址空间位宽 | T20           | i20           |\n",
      "| -------- | ------------- | ------------- |\n",
      "|          | 最大 **40bits** | 最大 **40bits** |\n",
      "\n",
      "线性内存分配在设备地址空间中，并**映射式**地映射到主机地址空间中。每个分配的内存对象可以在主机端通过指针来引用，主机端的指针被包装为运行时的内存对象句柄。而在设备端 **Kernel** 通过设备地址引用内存对象，其表现形式仍为指针。在主机端启动 Kernel 时，会将主机端指针转换为设备端指针，让工作在两个地址空间中的代码可以协同。\n",
      "\n",
      "内存对象通常通过 **topsMalloc()** 分配和 **topsFree()** 释放，数据搬运使用 **topsMemcpy** 接口（如前所述目前 **topsMalloc3D** 和 **topsMallocPitch** 类接口均不支持）。下面代码所示：\n",
      "\n",
      "```cpp\n",
      "#include <stdio.h>\n",
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__global__ void vec_add(int *from, int *to, size_t N)\n",
      "{\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "    __aligned__ int buffer[128];\n",
      "\n",
      "    tops::mdspan buf(tops::Private, &buffer, 128);\n",
      "\n",
      "    for (size_t i = 0; i < N; i += 128) {\n",
      "        tops::mdspan src(tops::Global, from + i, 128);\n",
      "        tops::mdspan dst(tops::Global, to + i, 128);\n",
      "        tops::memcpy(ctx, buf, src);\n",
      "\n",
      "        for (size_t j = 0; j < 128; j += tops::vlength<vint>()) {\n",
      "            const auto &v = tops::vload<vint>(buffer + j);\n",
      "            tops::vstore(tops::vadd<vint>(v, v), buffer + j);\n",
      "        }\n",
      "\n",
      "        tops::memcpy(ctx, dst, buf);\n",
      "    }\n",
      "}\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int *A_d, *C_d;\n",
      "    int *A_h, *C_h;\n",
      "    size_t N = 512;\n",
      "    size_t Nbytes = N * sizeof(int);\n",
      "\n",
      "    A_h = (int*)malloc(Nbytes);\n",
      "    C_h = (int*)malloc(Nbytes);\n",
      "\n",
      "    // Initialize the data.\n",
      "    ...\n",
      "\n",
      "    topsMalloc(&A_d, Nbytes);\n",
      "    topsMalloc(&C_d, Nbytes);\n",
      "\n",
      "    topsMemcpy(A_d, A_h, Nbytes, topsMemcpyHostToDevice);\n",
      "\n",
      "    vec_add<<<1, 1>>>(A_d, C_d, N);\n",
      "\n",
      "    topsMemcpy(C_h, C_d, Nbytes, topsMemcpyDeviceToHost);\n",
      "\n",
      "    topsFree(A_d);\n",
      "    topsFree(C_d);\n",
      "\n",
      "    free(A_h);\n",
      "    free(C_h);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "#### 3.2.5.4 访问主存\n",
      "\n",
      "除设备内存之外，设备也可以访问**问系统主存**，用户需要通过 ``topsMallocHost()`` 分配或 ``topsHostRegister()`` 接口注册分配的系统内存指针。主存同样会被映射到两个地址空间中，并且锁定在物理内存中（**pinned pages**）。\n",
      "\n",
      "设备端对其访问的性能会较低，但会有如下优点：\n",
      "\n",
      "* 可以实现设备端发起的异步数据拷贝从而和 ``Kernel`` 的执行并行。\n",
      "* 映射到设备地址空间后，设备端可以直接访问少量内存拷贝。\n",
      "* 目前在主存和设备内存之间自动迁移的内存对象尚不支持，即 ``topsMallocManaged()`` 当前不可用。\n",
      "\n",
      "#### 3.2.5.5 全局变量\n",
      "\n",
      "主机运行时还可以访问程序中的设备空间全局变量，示例如下：\n",
      "\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops/tops_runtime_api.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__device__ int globalIn[256];\n",
      "__device__ int globalOut[256];\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int data[256] = {0};\n",
      "    int* ptr;\n",
      "\n",
      "    topsMalloc(&ptr, 256 * sizeof(int));\n",
      "\n",
      "    topsMemcpyFromSymbol(data, globalIn, 256 * sizeof(int));\n",
      "\n",
      "    topsMemcpy(ptr, data, 256 * sizeof(int), topsMemcpyHostToDevice);\n",
      "\n",
      "    topsMemcpyToSymbol(globalOut, ptr, 256 * sizeof(int));\n",
      "\n",
      "    topsFree(ptr);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "``topsGetSymbolAddress()`` 可以获取全局变量的内存句柄，``topsGetSymbolSize()`` 可以获取内存对象的大小。\n",
      "\n",
      "#### 3.2.5.6 异步并行\n",
      "\n",
      "TopsRider 提供了一系列 **API**，为各种层级的计算和存储运并行提供支持：\n",
      "\n",
      "* 在主机端的计算\n",
      "* 在设备端的计算\n",
      "* 从主机端向设备搬运数据\n",
      "* 从设备端向主机搬运数据\n",
      "* 在指定设备内搬运数据\n",
      "* 在设备之间搬运数据\n",
      "\n",
      "上述这些任务可以在不同层面并行。\n",
      "\n",
      "##### 主机端和设备端并行\n",
      "\n",
      "主机端通过异步接口将任务下发到设备的队列中，设备执行完毕后会通知主机端（**event**），在此期间设备端可以执行其他任务而不是阻塞等待。设备端支持如下的异步任务：\n",
      "\n",
      "* 启动内核\n",
      "* 内存拷贝\n",
      "* 内存赋值\n",
      "\n",
      "上述任务同样支持对应的同步任务 API。\n",
      "\n",
      "#### 3.2.5.7 多核并行执行\n",
      "\n",
      "在同一个设备上，不同的进程、上下文、线程都可以使用并行下发的方式异步启动内核任务。多个内核使用的资源充足时，它们就会并行调度执行。\n",
      "\n",
      "##### 数据流与计算并行\n",
      "\n",
      "数据通道需要从主存搬运数据到设备内存，经由计算后将结果从设备内存搬回主存，这个过程可以通过**输入、计算、输出**三级流水，在内核逻辑里也有类似的流水并行优化，但是主机端运行时不感知，三者也可以并行执行。\n",
      "\n",
      "##### 数据传输并行\n",
      "\n",
      "在硬件上主数据搬运的带宽通常大于一个，因此输入、输出和设备内的数据搬运经常可以并行，受限于总线带宽和读写口数量，并发数据传输并不总是会获得更好的性能，部分场景下会有较大收益。\n",
      "\n",
      "##### Stream 任务流\n",
      "\n",
      "上述描述的所有并行场景都是通过一种称为 **stream** 的任务流来实现的。**stream** 是一段命令协议包（**command packet**）的序列，命令序列会被设备端按照顺序执行。不同的 stream 中的命令序列的执行顺序则是彼此独立的，可以在多个 stream 之间显式的添加依赖来控制它们执行顺序的关系。同步等待一个 stream 可以保证之前已下发的所有命令全部完成。\n",
      "\n",
      "**1. 创建和销毁**\n",
      "\n",
      "stream 的创建包括构造一个任务流对象以及添加任务流中的任务，例如启动内核、主存与设备内存之间的数据拷贝。下面代码例子中创建了两个 stream 对象并分配了一个映射到设备端的主存中的数组。\n",
      "\n",
      "```cpp\n",
      "topsStream_t stream[2];\n",
      "\n",
      "for (int i = 0; i < 2; ++i)\n",
      "    topsStreamCreate(&stream[i]);\n",
      "\n",
      "float* hostPtr;\n",
      "topsMallocHost(&hostPtr, 2 * size);\n",
      "```\n",
      "\n",
      "每个stream对象负责一个主存到设备内存的数据搬运、一个启动内核操作、一次设备内存到主存的数据搬运\n",
      "\n",
      "```cpp\n",
      "for (int i = 0; i < 2; ++i) {\n",
      "    topsMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,\n",
      "                    size, topsMemcpyHostToDevice, stream[i]);\n",
      "\n",
      "    MyKernel<<<1, 0, stream[i]>>>(\n",
      "        outputDevPtr + i * size, inputDevPtr + i * size, size);\n",
      "\n",
      "    topsMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,\n",
      "                    size, topsMemcpyDeviceToHost, stream[i]);\n",
      "}\n",
      "```\n",
      "\n",
      "两个 stream 都会拷贝自己的一段输入数组 **hostPtr** 到设备内存的 **inputDevPtr** 中，然后调用 **MyKernel()** 处理 **inputDevPtr**，再将结果 **outputDevPtr** 从设备内存中拷贝回 **hostPtr** 的主存里。根据设备的能力，两个 stream 交替或同时执行。\n",
      "\n",
      "用户需要主动销毁 stream 对象。\n",
      "\n",
      "```cpp\n",
      "for (int i = 0; i < 2; ++i)\n",
      "    topsStreamDestroy(stream[i]);\n",
      "```\n",
      "\n",
      "为避免用户阻塞正在执行的 stream，**topsStreamDestroy()** 接口会立即返回，但是 stream 对象和关联的资源会在设备端完成 stream 的执行后才会释放。\n",
      "\n",
      "**2. 默认 stream**\n",
      "\n",
      "用户调用异步任务接口时通常需要传递 **stream** 参数指定任务流。如果用户不指定或者传递空 **stream** 指针，则任务会被发送到**默认 stream** 上，并且按顺序下发顺序保证顺序执行。每个设备拥有一个默认 stream，所有线程在该设备上共享同一个默认 stream。尚不支持多线程下每个线程拥有独立的默认 stream。\n",
      "\n",
      "**3. 显式同步**\n",
      "\n",
      "用户可以主动同步 stream：\n",
      "\n",
      "* `topsDeviceSynchronize()` 会等待当前所有线程的所有 **stream** 全部执行完成。\n",
      "* `topsStreamSynchronize()` 接受一个 **stream** 对象作为参数，等待该 stream 对象上的所有任务都完成。\n",
      "* `topsStreamWaitEvent()` 接受一个 **stream** 和一个 **event** 作为参数，在任务流上构建一个异步等待任务，所有该任务之后下发的任务都会等待 **event** 对应的事件发生后才会继续执行。\n",
      "* `topsStreamQuery()` 供应用程序查询某个 **stream** 里的任务是否已经完成。\n",
      "\n",
      "**4. 隐式同步**\n",
      "\n",
      "不同 **stream** 的命令通常可以并行，暂时没有操作会触发隐含的同步行为。\n",
      "\n",
      "**5. 并发行为**\n",
      "\n",
      "多个 stream 上的命令，其并发行为取决于各自命令所在序列顺序，以及设备对各种类型任务支持的最大并发数量。\n",
      "例如，在设备上如果某个时钟的数据搬运任务的最大并发度是 **1**，那么两个 stream 上的内存拷贝操作将会结构性冒险（**structural hazard**），进而串行执行。运行时未来将提供接口可查询各类型任务当前执行环境下的最大并发度。\n",
      "两个 stream 上的不同类型的任务可以在设备端并发执行。\n",
      "\n",
      "**6. 主机端回调**\n",
      "\n",
      "运行时提供了 `topsStreamAddCallback()` 接口，可以向 stream 中插入一个异步的主机端回调任务，在这个任务之前的所有任务执行完毕后，该任务才会执行。下面例子中 **MyCallback** 函数会在设备内存到主存的数据搬运结束后被执行。\n",
      "\n",
      "```cpp\n",
      "void topsStreamCallback_t MyCallback(topsStream_t stream, topsError_t status, void *data) {\n",
      "    printf(\"inside callback %d\\n\", (size_t)data);\n",
      "}\n",
      "\n",
      "for (size_t i = 0; i < 2; ++i) {\n",
      "    topsMemcpyAsync(devPtrIn[i], hostPtr[i], size, topsMemcpyHostToDevice, stream[i]);\n",
      "\n",
      "    MyKernel<<<1, 1, 0, stream[i]>>>(devPtrOut[i], devPtrIn[i], size);\n",
      "\n",
      "    topsMemcpyAsync(hostPtr[i], devPtrOut[i], size, topsMemcpyDeviceToHost, stream[i]);\n",
      "\n",
      "    topsStreamAddCallback(stream[i], MyCallback, (void*)i);\n",
      "}\n",
      "```\n",
      "\n",
      "在主机端回调任务之后下发到 stream 上的任务不会等待回调函数结束后才执行，而是直接顺序执行。因此如果需要同步阻塞等待的场景，需要主机端使用同步接口例如 `topsStreamSynchronize()` 来实现。\n",
      "\n",
      "**7. Stream 优先级**\n",
      "\n",
      "当前 **stream 不支持优先级** 调度。\n",
      "\n",
      "##### 事件\n",
      "\n",
      "**event** 事件可以用于跟踪设备端异步任务的执行进度，显式同步设备端的多个 **stream**，同步主机端和设备端的任务。事件可以记录在 stream 上；当一个事件完成时，该 stream 上所有处于这个 **event** 前的任务都已经执行完成。默认 **stream** 上的事件发生时，所有 stream 上在这个事件记录之前下发的所有任务都已经执行完成。\n",
      "\n",
      "**创建和销毁：**\n",
      "\n",
      "```cpp\n",
      "topsEvent_t start, stop;\n",
      "\n",
      "topsEventCreate(&start);\n",
      "topsEventCreate(&stop);\n",
      "\n",
      "topsEventDestroy(start);\n",
      "topsEventDestroy(stop);\n",
      "```\n",
      "\n",
      "##### 同步任务调用\n",
      "\n",
      "有一些任务接口是**同步**的，在设备端将任务执行完之前，接口不会返回。可以通过 `topsSetDeviceFlags()` 接口来控制主机端线程此时是让步（yield）、阻塞或是忙等。\n",
      "\n",
      "#### 3.2.5.8 统一地址空间\n",
      "\n",
      "目前 TopsCC 程序尚未实现完整的统一地址空间机制。通过存储管理接口分配的内存对象句柄均为主机端指针，用户程序可以直接对其读写访问。当句柄被传递到接口中使用时，会根据需要将其转换到设备地址空间的指针，用户程序可以直接使用。\n",
      "\n",
      "```cpp\n",
      "__global__ void test(int *ptr)\n",
      "{\n",
      "    printf(\"%lx\\n\", (uint64_t)ptr); // device address pointer\n",
      "}\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int *data;\n",
      "\n",
      "    topsMalloc(&data, sizeof(int));\n",
      "    *data = 0; // host address pointer\n",
      "\n",
      "    test<<<1, 1>>>(data);\n",
      "\n",
      "    topsFree(data);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__device__ extern void foo();\n",
      "\n",
      "__global__ void bar() {\n",
      "    foo();\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    bar<<<1,1>>>();\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "### 3.4 编程限制汇总\n",
      "\n",
      "#### 3.4.1 编程相关\n",
      "\n",
      "1. **GCU 2.0 不支持全局寻址**。kernel 不能直接访问 `__shared__` 和 `__device__` 地址空间。需要通过 **DTE** 将 `__shared__` 和 `__device__` 地址的内容搬运至 **L1** 进行计算。\n",
      "2. 关于打印功能，在 kernel function 中 **printf** 只支持打印**整型**，不支持 **%s** 和 **%p**。关于地址打印，可以将指针对强制转换成 **long long** 类型。\n",
      "3. 在 **GCU210** 上 **Block dims** 的乘积最大为 **12**，即一个 Block 内**最多开 12 个 Thread**。\n",
      "4. 在 **GCU210** 上 **Grid dims** 的乘积最大为 **2**。\n",
      "5. **GCU 2.0 不允许直接访问 shared memory（L2）**，只能用于 **DTE** 数据搬运操作。动态大小的 shared memory，每个 `__global__` 函数只能使用一个。\n",
      "6. 有关硬件支持 shared memory 的大小限制，**i20** 上每个 Block **最大 share memory 24MB**。\n",
      "7. 当核函数里有 `printf` 或者 `assert` 调用时，runtime 处于 **debug 同步模式**，也就是一个 Stream 上核函数的运行是强制同步的。\n",
      "\n",
      "### 3.4.2 DTE 数据搬运\n",
      "\n",
      "1. 用 `__shared_dte__` 和 `__private_dte__` 声明的 **DTE Context** 只能支持 **Global** 和 **Shared** 之间的数据传输。不加任何修饰符声明的 **DTE Context** 是 **Thread** 私有的 DTE 上下文，支持 **Global、Shared 和 Private** 之间的数据传输。\n",
      "2. 使用 **shared dte** 时，一个 **Block** 中只有一个 **Thread** 可以做 **L3->L2** 或 **L2->L3** 搬运。\n",
      "\n",
      "### 3.5 性能调优指南\n",
      "\n",
      "尽量使用 **DTE 软件流水** 使得**数据搬运**和**计算**可以并行。\n",
      "\n",
      "---\n",
      "\n",
      "# 4 FAQ\n",
      "\n",
      "## 4.1 使用报错信息\n",
      "\n",
      "**Q：** 使用 `mdspan` 时地址空间类型设置错误，可能会引发程序 *hang*。\n",
      "**A：** 检查地址空间类型设置，**L1 内存**地址设置为 `tops::Private`，**L2 内存**地址设置为 `tops::Shared`，**L3 内存**地址设置为 `tops::Global`。\n",
      "示例程序如下：\n",
      "\n",
      "```cpp\n",
      "__global__ void foo(int *arr, int size) {\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "\n",
      "    int buf[size];\n",
      "\n",
      "    tops::mdspan L3(tops::Private, arr, size); // L3 should be set to tops::Global but wrongly set to tops::Private\n",
      "    tops::mdspan L1(tops::Global, buf, size);  // L1 should be set to tops::Private but wrongly set to tops::Global\n",
      "\n",
      "    tops::memcpy(ctx, L1, L3);                 // at this point the program may hang\n",
      "}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Q：** DTE 未经初始化直接使用，可能会引发程序 *hang*。\n",
      "**A：** 使用 `tops::dte_scope` 或者显式调用 `init` 函数，其中 `tops::dte_scope` 会自动完成 DTE 的初始化操作以及销毁操作；如果显式调用 `init` 函数，在 DTE 使用完成之后**注意调用** `destroy` 函数释放 DTE 资源。\n",
      "示例程序如下：\n",
      "\n",
      "```cpp\n",
      "__global__ void foo() {\n",
      "    int a[32];\n",
      "    int b[32];\n",
      "\n",
      "    tops::mdspan src(tops::Private, a, 32);\n",
      "    tops::mdspan dst(tops::Private, b, 32);\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "\n",
      "    tops::dte_scope s(ctx);       // use tops::dte_scope to initialize dte context\n",
      "    // ctx.init();                // or use init() to initialize dte context\n",
      "\n",
      "    tops::memcpy(ctx, dst, src);  // if dte is uninitialized, the program may hang or abort\n",
      "\n",
      "    // ctx.destroy();             // if use init(), remember to use destroy() to free dte context\n",
      "}\n",
      "```\n",
      "注意DTE 事件等待与地址复用不严，写回被覆盖或遗漏 → 输出出现 0\n",
      "\n",
      "**GCU210（i20）**，忽略 GCU200。并修正术语对齐到 v2（例如对齐修饰符统一为 `__aligned__`）。\n",
      "\n",
      "## 0. 适用范围与术语对齐\n",
      "- **芯片/平台**：GCU210（i20）。\n",
      "- **地址空间修饰**（与 v2 保持一致）：\n",
      "  - `tops::Global` ↔ L3（设备全局存储）\n",
      "  - `tops::Shared` ↔ L2（簇共享存储，**仅 DTE 通道**）\n",
      "  - `tops::Private` ↔ L1（SIP 私有存储，**可计算**）\n",
      "- **对齐修饰**：统一使用 `__aligned__`（v1 中出现的 `__valigned__` 系误写，按 v2 规范更正为 `__aligned__`）。\n",
      "---\n",
      "\n",
      "## 1. v2 未覆盖/强调不够的 **高层算子框架 API**\n",
      "> 这些 API 在 v1 被反复提及，但 v2 未系统收录；可显著简化典型“搬运→计算→写回”的模板代码。\n",
      "\n",
      "### 1.1 Elementwise（逐元素）框架\n",
      "- **场景**：在 L3 张量上执行逐元素函数（自动以 tile 方式搬运至 L1，再执行）。\n",
      "- **核心接口**（设备端）：\n",
      "  ```cpp\n",
      "  #include <tops/elemwise.h>\n",
      "\n",
      "  // 在 Kernel 内部直接调用\n",
      "  tops::elemwise_kernel(\n",
      "      [] __device__(auto &out, auto &in) {\n",
      "          out = in * in;  // 在 L1 上的逐元素操作\n",
      "      },\n",
      "      N,                          // 总元素个数\n",
      "      tops::Input(0), in_ptr,     // 输入\n",
      "      tops::Output(0), out_ptr    // 输出\n",
      "  );\n",
      "  ```\n",
      "- **变体/控制**：`elemwise_tiles`（按 tile 粒度自定义）、`elemwise_local`（已在 L1 的缓冲上直接算）。\n",
      "- **优势**：自动封装 DTE 切片/回写与对齐处理，减少手写样板代码。\n",
      "\n",
      "### 1.2 Reduction（归约）框架\n",
      "- **场景**：对张量做加/最大/最小等归约（可从 L3 直接发起或在 L1 上本地归约）。\n",
      "- **核心接口**（设备端，示例）：\n",
      "  ```cpp\n",
      "  #include <tops/reduction.h>\n",
      "\n",
      "  // kernel 级：从 L3 发起（内部自动搬运）\n",
      "  tops::reduction_kernel(\n",
      "      [] __device__(auto &acc, auto &x) {\n",
      "          acc = __reduction_add(acc, x);\n",
      "      },\n",
      "      out_ptr, out_shape,          // 归约输出\n",
      "      in_ptr,  in_shape,           // 归约输入\n",
      "      /*identity*/ 0               // 加法幺元\n",
      "  );\n",
      "\n",
      "  // local 级：对已在 L1 的缓冲做归约\n",
      "  tops::reduction_local(\n",
      "      [] __device__(auto &acc, auto &x) {\n",
      "          acc = __reduction_max(acc, x);\n",
      "      },\n",
      "      out_L1, in_L1\n",
      "  );\n",
      "  ```\n",
      "- **内置运算符**：`__reduction_add / __reduction_max / __reduction_min`。\n",
      "- **注意**：默认归约维度常为“中间维”，需与 `in_shape/out_shape` 对齐。\n",
      "\n",
      "### 1.3 Select / Broadcast 等辅助算子\n",
      "- **条件选择**：\n",
      "  ```cpp\n",
      "  #include <tops/select.h>\n",
      "  tops::select_kernel(\n",
      "      [] __device__(auto &o, auto &lhs, auto &rhs, auto &cond) {\n",
      "          o = cond ? lhs : rhs;\n",
      "      },\n",
      "      size, tops::Input(0), lhs, tops::Input(1), rhs, tops::Input(2), cond,\n",
      "      tops::Output(0), out\n",
      "  );\n",
      "  ```\n",
      "- **按维广播**：\n",
      "  ```cpp\n",
      "  #include <tops/broadcast.h>\n",
      "  tops::broadcast_in_dim(out, in, dim0, dim1, /*broadcast_dim*/1, /*bsize*/k);\n",
      "  ```\n",
      "\n",
      "> 这些高层 API 有助于**标准化**常见套路；v2 可在“3.2.4 设备端编程”后追加“高层封装”小节引入。\n",
      "\n",
      "---\n",
      "\n",
      "## 2. DTE 进阶：链式/异步流水的细节补全\n",
      "v2 已介绍同步/异步与软件流水；v1 另强调了“**多 DTE 上下文链式**”与若干 **易错点**：\n",
      "\n",
      "### 2.1 dte_chain（多上下文串联）\n",
      "```cpp\n",
      "// 伪头文件名，实际以你环境为准：\n",
      "#include <tops/dte_chain.h>\n",
      "\n",
      "tops_dte_ctx_t ctxA, ctxB;\n",
      "ctxA.init(); ctxB.init();\n",
      "\n",
      "auto chain = tops::dte_chain(ctxA, ctxB);\n",
      "chain.connect(...);               // 配置 A→B 的数据流\n",
      "chain.trigger();                  // 触发\n",
      "chain.wait();                     // 等待完成\n",
      "\n",
      "ctxB.destroy(); ctxA.destroy();\n",
      "```\n",
      "> 适合 **L3→L1→L3** 的双向搬运在不同 ctx 上交错、做更深流水。若你当前环境无 `dte_chain` 头（SDK 版本差异），可用**手动双 ctx + event** 等价实现（v2 已给出）。\n",
      "\n",
      "### 2.2 `slice_async` 签名易错\n",
      "- **正确**：必须给 **offset**（至少 4 参起），例如：\n",
      "  ```cpp\n",
      "  auto ev = tops::slice_async(ctx, dst_md, src_md, /*offset*/ {x0, y0, z0});\n",
      "  tops::wait(ev);\n",
      "  ```\n",
      "- **错误**：`slice_async(ctx, dst, src)`（少 offset）会编译/链接失败。\n",
      "\n",
      "### 2.3 `_async` 返回 `tops::event`\n",
      "- 只有带 `_async` 的接口返回 `tops::event`；**无后缀**版本为 `void`。\n",
      "- 典型易错：\n",
      "  ```cpp\n",
      "  // 错误：同步接口赋给 event\n",
      "  tops::event ev = tops::transpose_deslice(...); // ❌ 返回 void\n",
      "  // 正确：\n",
      "  tops::event ev = tops::transpose_deslice_async(...);\n",
      "  tops::wait(ev);\n",
      "  ```\n",
      "\n",
      "### 2.4 开发期健壮性\n",
      "- 建议全程开启：`-DTOPS_ENABLE_DTE_CHECK`（越界/地址空间不一致更早暴露）。\n",
      "- **地址空间配置**一旦写错（如把 L3 标成 `tops::Private`），现象多为 **hang** 而非报错。\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 向量工具与类型映射（补充）\n",
      "v2 列了大量向量算子，但 **类型映射/广播**在 v1 有更集中提示：\n",
      "\n",
      "- **固定向量宽**：128B；`vfloat`=32×`float`，`vhalf`=64×`tops::half`，`vbfloat`=64×`tops::bfloat`，…\n",
      "- **从标量到向量类型**：\n",
      "  ```cpp\n",
      "  // 由标量类型 T 查到对应的 vector 类型：\n",
      "  using V = typename tops::scalar2vector<float>::type; // -> vfloat\n",
      "  ```\n",
      "- **标量广播到向量**：\n",
      "  ```cpp\n",
      "  auto v = tops::vbroadcast(3.14f);      // vfloat\n",
      "  auto h = tops::vbroadcast(tops::half(1));\n",
      "  ```\n",
      "- **对齐与边界**：仅在**完全对齐且长度是 vlength<T> 的倍数**时用 `vload/vstore`，否则走标量尾。\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 调试/运行时补遗（v1 独有要点）\n",
      "- **printf/assert 导致同步**：kernel 内使用 `printf/assert` 会让 runtime 进入**调试同步模式**（同一 stream 强制同步），用于排错可以，但性能测试前务必移除。v2 有提及，但建议在“性能调优”再次**加粗提醒**。\n",
      "- **不存在 API 的“想当然命名”**：\n",
      "  - 如 `tops::reduce_add / tops::vreduce_add` **不存在**；应使用前述 **reduction** 框架或自己展开。\n",
      "- **评测/比赛环境可能禁用**某些 API：如把 `topsMalloc/topsFree` 宏重定向为 `_topsMalloc_disabled`。**算子实现不要私自设备端分配临时 L3**，尽量用 L1 缓冲或由上层传入。\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 典型模板（v1 风格，按 v2 术语修正）\n",
      "\n",
      "### 5.1 元素算子（完整可嵌入）\n",
      "```cpp\n",
      "#include <tops/elemwise.h>\n",
      "\n",
      "__global__ void square_kernel(float *out, const float *in, int N) {\n",
      "    // 自动按 tile 从 L3 → L1，L1 上逐元素操作，再写回\n",
      "    tops::elemwise_kernel(\n",
      "        [] __device__(auto &o, auto &x) {\n",
      "            o = x * x;\n",
      "        },\n",
      "        N,\n",
      "        tops::Input(0),  in,\n",
      "        tops::Output(0), out\n",
      "    );\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.2 手写 Tile + SIMD（与 v2 一致但给出“边界回退”套路）\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__global__ void vec_add(float *a, float *b, float *c, int N) {\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "\n",
      "    constexpr int TILE = 128;                         // 对齐 128B\n",
      "    __aligned__ float buf_a[TILE], buf_b[TILE], buf_c[TILE];\n",
      "\n",
      "    tops::mdspan A_L1(tops::Private, buf_a, TILE);\n",
      "    tops::mdspan B_L1(tops::Private, buf_b, TILE);\n",
      "    tops::mdspan C_L1(tops::Private, buf_c, TILE);\n",
      "\n",
      "    for (int i = 0; i < N; i += TILE) {\n",
      "        int n = min(TILE, N - i);\n",
      "\n",
      "        tops::memcpy(ctx, A_L1, tops::mdspan(tops::Global, a + i, n));\n",
      "        tops::memcpy(ctx, B_L1, tops::mdspan(tops::Global, b + i, n));\n",
      "\n",
      "        int j = 0;\n",
      "        // 向量快路径\n",
      "        for (; j + tops::vlength<vfloat>() <= n; j += tops::vlength<vfloat>()) {\n",
      "            auto va = tops::vload<vfloat>(buf_a + j);\n",
      "            auto vb = tops::vload<vfloat>(buf_b + j);\n",
      "            auto vc = tops::vadd(va, vb);\n",
      "            tops::vstore(vc, buf_c + j);\n",
      "        }\n",
      "        // 边界标量路径\n",
      "        for (; j < n; ++j) buf_c[j] = buf_a[j] + buf_b[j];\n",
      "\n",
      "        tops::memcpy(ctx, tops::mdspan(tops::Global, c + i, n), C_L1);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.3 归约（加和）示例\n",
      "```cpp\n",
      "#include <tops/reduction.h>\n",
      "\n",
      "__global__ void sum_kernel(float *out, const float *in, int N) {\n",
      "    // 对 1D 数组做加和，identity=0\n",
      "    tops::reduction_kernel(\n",
      "        [] __device__(auto &acc, auto &x) { acc = __reduction_add(acc, x); },\n",
      "        out, /*out_shape*/ N,\n",
      "        in,  /*in_shape*/  N,\n",
      "        0\n",
      "    );\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.4 GEMM 的“稳妥输出路径”提示\n",
      "- 若使用 `tops::transpose_deslice_async` 复杂组合在大规模/动态 tile 下出现偶发误差，**保守做法**：\n",
      "  1) 在 L1 计算出 `C`；\n",
      "  2) 需要转置的场景，**手工在 L1 做转置**到 `C_T`；\n",
      "  3) 用普通 `deslice` 写回 L3。  \n",
      "  实测该路径最稳，代价是多一次 L1 遍历。\n",
      "\n",
      "---\n",
      "\n",
      "## 6. GCU210 资源/并发提醒（与 v2 对齐但再次明确）\n",
      "- **Block 线程总数 ≤ 12**（`blockDim.x * blockDim.y * blockDim.z ≤ 12`）。\n",
      "- **Cooperative Kernel**：grid 总块数 ≤ `multiProcessorCount`（i20 为 **2**）。\n",
      "- **向量化前提**：所有参与 `vload/vstore` 的 L1 缓冲必须 `__aligned__`，且访问地址/长度满足 128B 自然对齐与 `vlength<T>` 整倍数。\n",
      "\n",
      "---\n",
      "\n",
      "## 7. MLP/激活实现的“一致性与稳定性”建议（补充条）\n",
      "> 与 v2 的一般指南不冲突，这里收拢为 **可复制到算子说明** 的检查清单：\n",
      "\n",
      "- **公式一致化**：向量与标量路径使用**同一**数学表达式（如 SiLU 用 `x/(1+exp(-x))`，向量用 `vexp/vdiv`，标量尾用 `exp/`相同公式）。\n",
      "- **边界一致性**：仅“完全对齐”时走向量路径；其余统一走**标量尾**，避免出现微妙的数值分歧。\n",
      "- **累加稳态化**：长链路加法用 **Kahan** 补偿或配对求和，固定加法顺序；批量/并行度变化后需重跑精度回归。\n",
      "- **可切换模式**：保留 `--precise / --fast` 两种路径开关，便于在评测与上线间切换。\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 常见陷阱对照表（v1 特有案例）\n",
      "| 症状 | 可能根因 | 解决方案 |\n",
      "|---|---|---|\n",
      "| kernel 无响应（hang） | DTE 未 init；mdspan 地址空间写错；对齐不足的 vload | 用 `tops::dte_scope`；开启 `-DTOPS_ENABLE_DTE_CHECK`；边界走标量 |\n",
      "| “把 void 当 event” 编译错 | 使用了同步 API 却当作 `_async` 用 | 仅 `_async` 返回 `tops::event`；用 `tops::wait` 同步 |\n",
      "| `slice_async` 参数不匹配 | 遗漏 `offset` | 使用 `slice_async(ctx, dst, src, {offset...})` |\n",
      "| 运行慢/卡住 | kernel 内 `printf/assert` | 调试阶段可用，性能测试前务必移除 |\n",
      "| 链接/编译异常 | 使用被评测环境禁用的分配 API | 不在设备端私自分配 L3；通过 L1 缓冲或调用方传入 |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 集成方式建议（如何合入 v2）\n",
      "- 在 **3.2.4 设备端编程** 后增设小节 **“高层算子封装（Elementwise / Reduction / Select / Broadcast）”**。\n",
      "- 在 **DTE 软件流水** 小节追加 **dte_chain/多 ctx 提示** 与 `_async`/`void` 返回值区别示例。\n",
      "- 在 **性能与正确性** 小节集中强调：`__aligned__`、边界标量尾、一致公式、`-DTOPS_ENABLE_DTE_CHECK`。\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "### 1) 内建编译期宏（**新**）\n",
      "- `__TOPS_DEVICE_COMPILE__`：设备端编译时定义（便于区分 host/device 代码路径）。  \n",
      "- `__GCU_ARCH__`：三位数字的架构码：`S60=300, T20=200, i20=210`。  \n",
      "  典型用法（按架构走不同实现）：\n",
      "```cpp\n",
      "#if defined(__TOPS_DEVICE_COMPILE__)\n",
      "  #if __GCU_ARCH__ >= 210\n",
      "    // i20 (GCU210) 专用路径\n",
      "  #else\n",
      "    // 其他架构路径\n",
      "  #endif\n",
      "#endif\n",
      "```\n",
      "\n",
      "### 2) 设备/并发属性查询与 cooperative 约束（**更细化**）\n",
      "- `topsGetDeviceProperties` 可取：  \n",
      "  - `multiProcessorCount`：**GCU210 = 2**  \n",
      "  - `maxThreadsPerMultiProcessor`：**GCU210 = 12**（即 Block 维度乘积最大 12）\n",
      "- cooperative kernel：**GCU210 上 Grid 维度乘积 ≤ 2**；且 Grid 总大小 ≤ `multiProcessorCount`。\n",
      "```cpp\n",
      "topsDeviceProp_t prop; int dev=0;\n",
      "topsGetDeviceProperties(&prop, dev);\n",
      "// 验证 GCU210 限制：\n",
      "assert(prop.multiProcessorCount == 2);\n",
      "dim3 block(prop.maxThreadsPerMultiProcessor, 1, 1); // 12\n",
      "// cooperative 启动前自检：\n",
      "auto gridProd = 2u; // 例如 dim3(2,1,1)\n",
      "assert(gridProd <= 2 && gridProd <= (unsigned)prop.multiProcessorCount);\n",
      "```\n",
      "\n",
      "### 3) 存储/寻址与容量（**细化 i20 数据**）\n",
      "- **GCU 2.0 不支持全局寻址**：L2/L3 仅能经 DTE 搬运；计算只能直接访问 L1（私有）与 `__constant__`。  \n",
      "- **共享内存上限**：**i20 = 24 MB**（动态 shared 每个 `__global__` 仅 1 个声明）。  \n",
      "- **设备内存地址宽度**：i20 **≤ 40 bits**。  \n",
      "- **Host 可用内存**：i20 机型示例：**64 GB**（运行库说明）。  \n",
      "\n",
      "### 4) Host 可见内存（pinned）与直访（**新**）\n",
      "- 通过 `topsMallocHost` 或 `topsHostRegister` 分配/注册 **锁页主存**，可映射到设备地址空间，被设备端直接访问或用于异步拷贝（带宽/延迟逊于设备内存；慎用 write‑combining）。\n",
      "```cpp\n",
      "float* hptr = nullptr;\n",
      "topsMallocHost(&hptr, N * sizeof(float));   // pinned host mem\n",
      "// … 填充 hptr …\n",
      "topsMemcpyAsync(devPtr, hptr, N*sizeof(float), topsMemcpyHostToDevice, stream);\n",
      "// kernel 也可直访 hptr（性能较低，场景化使用）\n",
      "```\n",
      "\n",
      "### 5) 设备端全局变量符号访问（**新**）\n",
      "```cpp\n",
      "__device__ int gIn[256];\n",
      "__device__ int gOut[256];\n",
      "\n",
      "// Host:\n",
      "int h[256] = {0};\n",
      "topsMemcpyFromSymbol(h, gIn, sizeof(h));    // 读设备端全局\n",
      "int* dtmp; topsMalloc(&dtmp, sizeof(h));\n",
      "topsMemcpy(dtmp, h, sizeof(h), topsMemcpyHostToDevice);\n",
      "topsMemcpyToSymbol(gOut, dtmp, sizeof(h));  // 写设备端全局\n",
      "topsFree(dtmp);\n",
      "```\n",
      "\n",
      "### 6) 运行时编译（RTC）与 Module 启动（**新**）\n",
      "- 支持 **运行时编译源代码** → 取回 `code` → `topsModuleLoadData` → `topsModuleLaunchKernel`。\n",
      "```cpp\n",
      "// 省略创建与编译…\n",
      "topsModule_t module; topsFunction_t fn;\n",
      "topsModuleLoadData(&module, code);\n",
      "topsModuleGetFunction(&fn, module, \"vector_square\");\n",
      "struct { topsDeviceptr_t a, b; size_t N; } args{A_d, C_d, N};\n",
      "void* cfg[] = { TOPS_LAUNCH_PARAM_BUFFER_POINTER, &args,\n",
      "                TOPS_LAUNCH_PARAM_BUFFER_SIZE,   (void*)sizeof(args),\n",
      "                TOPS_LAUNCH_PARAM_END };\n",
      "topsModuleLaunchKernel(fn, 1,1,1, 1,1,1, 0, nullptr, nullptr, cfg);\n",
      "```\n",
      "\n",
      "### 7) Stream / Event / 回调（**新**）\n",
      "- **默认 stream**：每设备共用一个（当前未区分线程）；不传入显式 stream 参数则落到默认 stream。  \n",
      "- **显式同步**：`topsDeviceSynchronize()`、`topsStreamSynchronize(s)`；事件依赖：`topsStreamWaitEvent(s, e)`。  \n",
      "- **回调**：可在 stream 完成前序任务后触发主机回调（不会阻塞后续命令排队）。\n",
      "```cpp\n",
      "topsStream_t s[2]; for (int i=0;i<2;++i) topsStreamCreate(&s[i]);\n",
      "// … H2D → Kernel → D2H 的三段流水，各自在 s[i] 上 …\n",
      "void MyCb(topsStream_t, topsError_t, void* tag){ printf(\"cb %ld\\n\",(long)tag); }\n",
      "topsStreamAddCallback(s[0], MyCb, (void*)0L);\n",
      "// 销毁：返回即刻，但资源在设备完成该 stream 后回收\n",
      "for (int i=0;i<2;++i) topsStreamDestroy(s[i]);\n",
      "```\n",
      "\n",
      "### 8) 向量计算接口补全与对齐要求（**新增目录**）\n",
      "- **统一长度 128B** 的向量寄存宽度；`tops::vlength<T>()` 可用于编译期尺寸。  \n",
      "- **`vload` 地址必须 `__valigned__` 对齐到向量宽度**（未对齐会触发 kernel abort，且未必被 host 立即捕获）。\n",
      "- 新增/补全的向量算子（除基本四则外）——示例：\n",
      "```cpp\n",
      "__valigned__ float buf[ tops::vlength<tops::vfloat>() ];\n",
      "auto vf = tops::vload<tops::vfloat>(buf);\n",
      "auto y  = tops::vsigmoid(vf);            // 激活\n",
      "auto g  = tops::vgelu(vf);               // GELU\n",
      "auto e2 = tops::vexp2(vf);               // 2^x\n",
      "auto ln = tops::vlog1p(vf);              // log(1+x)\n",
      "auto h  = tops::vhypot(vf, vf);          // hypot\n",
      "auto m  = tops::vmax(vf, y);             // 按元素最大\n",
      "tops::vstore(m, buf);\n",
      "```\n",
      "> v3 文档枚举了大量 **数学/位运算** 族函数（`vexp/expm1/log/log2/log10/logb/visnan/visfinite/vcopysign/vround/vtrunc/vrint/...` 等）；若 v1/v2 未完整列出，请据需合入“可用向量算子表”。\n",
      "\n",
      "### 9) DTE 接口补全（**更丰富**）\n",
      "- **全量配置**：`config_transpose / config_slice_transpose / config_pad / config_mirror_tb / config_mirror_lr / config_broadcast …`  \n",
      "- **增量配置**：`set_*_addr / set_*_offset / set_*_dim_size / set_total_size / set_transpose_layout / set_pad_config`  \n",
      "- **触发**：`trigger()` 返回 `tops::event`，`trigger_and_wait()` 同步；还有 `_async` 族的复合接口：\n",
      "```cpp\n",
      "tops_dte_ctx_t ctx; ctx.init();\n",
      "auto ev = tops::memcpy_async(ctx, dst, src);\n",
      "tops::wait(ev);\n",
      "ctx.destroy();\n",
      "```\n",
      "- **软件流水模板（双缓冲）**：v3 提供了计算‑搬运并行化的示例骨架，可直接套入 tile‑based 算子（GCU210 适用）。\n",
      "\n",
      "### 10) 同步原语（**小补**）\n",
      "- `__syncthreads()`：Block 内同步。  \n",
      "- `__syncblocks()`：Grid 级同步（Kernel 必须 `__cooperative__`）。\n",
      "\n",
      "\n",
      "### 12) 编程限制 / FAQ（**新增可操作排错点**）\n",
      "- **限制汇总（GCU210 相关）**：\n",
      "  - Block 维度乘积 ≤ **12**；cooperative Grid 维度乘积 ≤ **2**；GridMax：x=65536, y=256, z=256。  \n",
      "  - 动态 shared 每 kernel 仅 1 个；i20 shared 上限 **24MB**。  \n",
      "  - **使用 `shared dte` 时，每 Block 只有 1 个 Thread 能执行 L3↔L2 拷贝**。  \n",
      "  - Kernel 内含 `printf/assert` 时，runtime 进入 **debug 同步模式**（同一 stream 强制顺序执行）。\n",
      "- **常见挂起原因**：\n",
      "  1) `mdspan` 地址空间设置错误（把 L3 标成 `tops::Private` 等）：\n",
      "```cpp\n",
      "// 错误示例：arr 是 L3 指针，却被错误地标成 Private\n",
      "tops::mdspan L3_wrong(tops::Private, arr, size);\n",
      "tops::mdspan L1_wrong(tops::Global,  buf, size);\n",
      "tops::memcpy(ctx, L1_wrong, L3_wrong); // 可能 hang\n",
      "```\n",
      "  2) **DTE 未初始化** 就调用 `tops::*`：用 `tops::dte_scope` 或 `ctx.init()/destroy()` 包裹：\n",
      "```cpp\n",
      "tops_dte_ctx_t ctx;\n",
      "tops::dte_scope scope(ctx);     // 自动 init/destroy\n",
      "// ctx.init(); … tops::memcpy(ctx, …); ctx.destroy();\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/root/nian/MOLLM/problem/gcu/prompt_info.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(config['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6f9845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是资深 GCU/TopsCC 算子工程师与编译器专家'},\n",
       " {'role': 'system',\n",
       "  'content': '【GCU 教程】\\nGCU 是燃原的 AI 计算加速设备。TopsCC 是基于 GCU 的编程平台，TopsCC 包含一套工具集和 runtime 库，支持 C/C++ 编程，可以生成在设备端和主机端运行的程序。本文件主要介绍如何在 GCU 上通过 TopsCC 进行算子编程。\\n表 1‑2 词汇表：\\n\\n| 术语      | 描述                                   |\\n|-----------|----------------------------------------|\\n| GCU       | 燃原 AI 加速卡                         |\\n| TopsCC    | 燃原编程平台                           |\\n| clang     | C/C++ 编译器                           |\\n| llvm      | 编译器套件                             |\\n| Kernel    | 核函数，运行在设备端的程序             |\\n| Fatbin    | 包含了设备端和主机端运行程序的二进制文件 |\\n| DTE       | 数据搬运引擎                           |\\n| RTC       | 运行时编译                             |\\n| SIMT      | 单指令多线程                           |\\n| SIP       | 硬件计算核心                           |\\n| i20       | 第二代 GCU 推理卡                      |\\n| GCU210    | 第二代 GCU 推理卡，和 i20 等价         |\\n| TopsRider | 燃原 SDK 开发套件                     |\\n---\\n\\n# 2 简介\\n人工智能领域对计算性能的需求极高。GCU 作为强大的计算引擎，提供了必要的算力支撑。而 TopsCC 则扮演了编程平台的角色，它通过优化编程环境，使得 GCU 的计算潜能得到更充分的释放。TopsCC 通过扩展\\u202fC++\\u202f语言，使得开发者能够以接近\\u202fC++\\u202f的编程方式，高效地为 GCU 编写程序。\\nGCU 具备多计算核心和多级存储的设计，这些架构特性会反映到具体的编程模型上。\\n\\n（图 2‑1 GCU 架构图）\\n\\n## 2.1 计算核心\\n\\nSIP 计算核心是燃原科技打造面向云端数据中心的人工智能训练一体芯片采用全新的通用计算单元 GCU‑CARE 架构，为深度学习提供强大的算力支持。计算核心支持标量、向量和张量计算。通过燃原科技自有知识产权的软硬件架构\\u202fTopsRider，可以广泛地支持视觉、语音、NLP、推荐、LLM 等各技术方向的模型训练与推理。i20 一共含\\u202f24\\u202f个计算核心。\\n\\n## 2.2 多级存储\\n\\nGCU 包含 L1–L3 三级存储。\\n\\n(图 2‑2 三级存储)\\n\\nL1: 每个计算核心内部包含了一个私有存储（L1）。i20 中每一个计算核心具有 1\\u202fM 的 L1。\\nL2: 12 个计算核心可以组成一个计算簇，同一个 GCU 内包含多个计算簇。每个计算簇内的计算核心可以共享一个簇内的 24\\u202fM L2 共享存储。\\nL3: GCU 拥有一个全局设备存储（L3），对所有计算簇可见，i20 的 L3 大小为 16\\u202fGB。\\nL1、L2 的介质是 SRAM，L3 介质一般是 HBM 或者 GDDR。\\n\\n---\\n\\n# 3 TopsCC 编程模型\\n\\n## 3.1 概述\\n\\n### 3.1.1 函数类型限定符\\n\\nTopsCC 支持设备端和主机端混合编程，使用 __device__ 和 __global__ 标记设备端程序，使用 __host__ 标记主机端程序。没有标记的函数默认为主机端程序。\\n\\n示例代码：\\n```cpp\\n#include <tops/tops_runtime.h>\\n\\n__global__ void foo() {\\n    // TODO: add code here\\n}\\n\\nint main(int argc, char **argv) {\\n    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\\n    assert(topsGetLastError() == topsSuccess);\\n\\n    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\\n    assert(topsGetLastError() == topsSuccess);\\n    return 0;\\n}\\n```\\n\\n表 3‑1 函数类型限定符：\\n\\n| 函数类型限定符 | 执行                     | 调用                                                                 |\\n|----------------|--------------------------|-----------------------------------------------------------------------|\\n| __device__     | 在设备端运行的函数       | 可以被 __global__ 函数调用，但不能被 __host__ 函数调用                 |\\n| __global__     | 在设备端运行的入口函数   | 只能由 __host__ 函数启动，不能被 __device__ 或其他 __global__ 函数调用 |\\n| __host__       | 在主机端运行的函数       | 只能被 __host__ 函数调用                                             |\\n\\n说明：一个函数可以同时标记为 __device__ 和 __host__，这种函数在设备端和主机端都能被调用。没有标记的函数默认都是 __host__ 函数。\\n\\n### 3.1.2 线程模型\\n\\nTopsCC 支持类似 SIMT 的编程模型，多个 Thread 可同时执行同一份代码。Thread 的层次结构分为 Thread、Block 和 Grid 三层，每层可用 x、y、z 三个维度指定程序运行的层次结构。\\n\\n- **Thread**：对应一个标量或向量执行程序，物理上映射到一个计算核心\\xa0SIP\\xa0上执行。在线程内部可以通过 `threadIdx.x`、`threadIdx.y`、`threadIdx.z` 获取当前 thread 的坐标。\\n- **Block**：包含一组 Thread，物理上映射到一组\\xa0SIP。在线程内部可以通过 `blockIdx.x`、`blockIdx.y`、`blockIdx.z` 获取当前 block 的坐标。可以使用 `blockDim.x`、`blockDim.y`、`blockDim.z` 指定 block 的维度大小，作为内核调用符 `<<<>>>` 的参数。\\n  - 硬件特性：在 gcu210 上 block dims 的乘积最大为\\xa012，即 `blockDim.x * blockDim.y * blockDim.z <= 12`。\\n- **Grid**：包含一组 Block。可以使用 `gridDim.x`、`gridDim.y`、`gridDim.z` 指定 grid 的维度大小作为内核调用符 `<<<>>>` 的参数。\\n  - 硬件特性：设备上 grid dims 的乘积最大为\\xa02，即 `gridDim.x * gridDim.y * gridDim.z <= 2`。\\n\\n图\\xa03‑1 thread 模型：线程按照 Thread → Block → Grid\\xa0三级结构组织，并映射到芯片上多个\\xa0SIP\\xa0计算核心和存储层级。\\n\\nTopsCC 支持 cooperative 模式。当一个 __global__ 函数（kernel）被标记为 cooperative 模式时，这个 kernel 会被运行时使用 `topsLaunchCooperativeKernel` 启动。在这种模式下 grid 中所有的 block 会同时运行。内核中可以使用 `__synchblocks()` 调用进行 block 间的同步。\\n\\n示例代码：\\n```cpp\\n__global__ __cooperative__ void foo() {\\n    __synchblocks();\\n}\\n```\\n\\n### 3.1.3 存储模型\\n\\ni20\\xa0GCU\\xa0的存储系统结构如下图所示（图\\xa03‑2）。用户视角可见以下地址空间：\\n\\n- `__device__`：全局的地址空间，所有 block 可见。对应硬件的全局设备存储（L3）。\\n\\n  ```c\\n  __device__ int data[100];\\n  ```\\n\\n说明：在\\xa0GCU\\xa02.0\\xa0中，kernel/SIP\\xa0不直接访问\\xa0L3，需要由\\xa0DTE\\xa0将数据搬运到\\xa0L1\\xa0后访问。\\n\\n* `__constant__`：全局的常量地址空间，所有 thread 可见。对应硬件的全局设备存储（L3）。\\n\\n  ```c\\n  __constant__ int a = 2;\\n  ```\\n\\n* `__shared__`：block 内共享地址空间，block 内的 thread 可见。对应硬件的簇内共享存储（L2）。\\n\\n  ```c\\n  __shared__ int data[100];        // static size shared memory\\n  extern __shared__ int data2[];   // dynamic size shared memory\\n  ```\\n\\n  说明：在\\xa0GCU\\xa02.0\\xa0中，不允许直接访问\\xa0L2，只能用于\\xa0DTE\\xa0数据搬运操作。动态大小的 shared memory\\xa0每个 **global** 函数只能使用一个。每个计算簇最大支持\\xa024\\xa0MB\\xa0的 shared memory。\\n\\n* 无修饰符变量：位于 thread 的私有地址空间，对应硬件的计算核心私有存储（L1）。\\n\\n  ```c\\n  int data;\\n  float data2[100];\\n  ```\\n\\n* `__aligned__`：对于私有空间的存储，如果会被向量操作使用，需要使用 `__aligned__` 进行对齐。\\n\\n  ```c\\n  __aligned__ int data[100];\\n  ```\\n\\n### 3.1.4 内建的宏\\n\\n* `__TOPS_DEVICE_COMPILE__`：编译设备端代码时会被定义。\\n* `__GCU_ARCH__`：由 3 位数字组成；i20 的值为\\xa0210。\\n\\n## 3.2 编程接口\\n\\nTopsCC 通过扩展 C++，提供设备端和主机端的运行时库来支持基于 C++ 的编程。编译方式包括两种：离线编译和运行时编译。\\n\\n\\n### 图\\xa03‑3\\xa0TopsCC\\xa0离线编译\\n\\n离线编译流程中，C/C++ 源代码与 kernel 库、host 库一起经由编译器生成\\xa0fatbin\\xa0文件，运行时由 CPU 和 GCU 装载执行。本次竞赛采用离线编译方式。\\n\\n### 3.2.2\\xa0运行时编译\\n\\n运行时需要实时编译源文件时，可使用运行时编译（RTC）接口。主机端接口支持嵌入源文件编译并运行：仅设备端代码会被编译并加载，主机端代码会被忽略，生成的可执行文件会缓存在内存中，便于重复调用。\\n\\n### 3.2.3\\xa0一个简单的程序例子\\n\\n示例程序如下。它在 GCU 上启动一个空的 kernel 函数 `foo`，`dim3(1,1,1)` 与 `1` 等价。\\n\\n```c++\\n#include <tops/tops_runtime.h>\\n\\n__global__ void foo() { }\\n\\nint main(int argc, char **argv) {\\n    // 启动一个 block，block 中有一个 thread 执行 kernel 函数 foo\\n    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\\n    assert(topsGetLastError() == topsSuccess);\\n\\n    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\\n    assert(topsGetLastError() == topsSuccess);\\n    return 0;\\n}\\n```\\n\\n**内核调用运算符\\xa0`<<<grid_dim, block_dim, share_memory_sz, stream>>>`** 接受 4\\xa0个参数：\\n\\n1. `grid_dim`：Grid 的尺寸，可参照线程层次结构选择。\\n2. `block_dim`：Block 的尺寸，同样参照线程层次结构。\\n3. `share_memory_sz`：kernel 在 block 中申请的动态共享数组字节数（如 `__shared__ int data[]`）。默认值为\\xa00\\xa0Byte；如果申请大小超过硬件共享内存限制，程序会出错。\\n4. `stream`：流对象，默认为空；用于异步调用。\\n\\n建议在 kernel 调用后使用 `topsGetLastError` 检查执行是否成功。\\n\\n**资源限制：**最大 grid\\xa0尺寸可以通过 `topsGetDeviceProperties` 查询。gcu210\\xa0硬件限制为 `gridDim.x ≤ 65536`、`gridDim.y ≤ 256`、`gridDim.z ≤ 256`。对于 cooperative 模式，grid 的总大小\\xa0`gridDim.x * gridDim.y * gridDim.z`\\xa0不得超过设备的 `multiProcessorCount`（gcu210 为\\xa02）。block 的总线程数不得超过设备 `maxThreadsPerMultiProcessor`（gcu210 为\\xa012）。下面代码展示如何查询这些属性并设置 block 大小：\\n\\n```c++\\ntopsDeviceProp_t prop;\\nint deviceId = 0;\\ntopsGetDeviceProperties(&prop, deviceId);\\n\\ndim3 blockDims;\\nblockDims.x = prop.maxThreadsPerMultiProcessor;\\nblockDims.y = 1;\\nblockDims.z = 1;\\n\\nfoo<<<1, blockDims>>>();\\n```\\n\\n### 3.2.4\\xa0设备端编程\\n\\n#### 打印和断言\\n\\n在 GCU\\xa02.0 中 kernel 直接访问的存储地址只支持私有地址空间（L1）和 `__constant__` 地址空间；对于 `__shared__` 和 `__device__` 地址空间，需要通过 DTE 将数据搬运到 L1 后访问。使用 `printf` 和 `assert` 有以下限制：\\n\\n* kernel 函数中可以使用 `printf`，但格式字符串必须是常量，且不支持 `%p` 和 `%.` 等格式。\\n* `assert` 默认在 O3 优化级别关闭，如需开启可在编译时定义\\xa0`-DTOPS_ENABLE_ASSERT`。\\n* 当 kernel 代码调用 `printf` 或 `assert` 时，运行时处于 debug\\xa0同步模式，此时同一 stream 上函数的执行是同步的。\\n\\n#### 3.2.4.1\\xa0数据流编程\\n\\nTopsCC 使用 DTE（Data\\xa0Transfer\\xa0Engine）接口进行数据搬运，允许计算与搬运并行。\\n一次数据搬运，通常包含以下流程：  \\n1. 声明DTE上下文\\n2. 使用mdspan给memory加入信息\\n3. 使用ctx操作接口\\n\\n一个DTE编程示例如下，将数据从设备端指针from线性拷贝到设备端指针to（from和to所指向的均为L3上的内存）：\\n```c\\n__global__ void copy_d2d(int *from, int *to, size_t N) {\\n  __private_dte__tops_dte_ctx_t ctx;  // Declare a DTE Context\\n  tops::dte_scope s(ctx);             // Initalize DTE Context\\n\\n  tops:: mdspan src(tops::Global, from, N);   // Add shape info for source\\n  tops::mdspan dst(tops::Global, to, N);      // Add shape info for dest\\n\\n  tpos::memcpy(ctx, dst, src);        // Copy data from source to dest\\n}\\n```\\n\\n##### 支持的标量数据类型\\n\\n* 基本类型：`bool`、`char`、`unsigned char`、`short`、`unsigned short`、`int`、`unsigned int`、`float`。\\n* 扩展浮点类型：`tops::half` 和 `tops::bfloat`。例如可通过 `#include <tops/half.h>` 和 `#include <tops/bfloat.h>` 引入。\\n\\n代码：ops::haf 和tops::bfloat 的定义方式示例\\n```c\\n#include<tops/half.h>\\n#include<tops/bfloat.h>\\n\\n__device__ void test(){\\n  tops::half value1(0.2);\\n  tops::bfloat value2(2.4);\\n}\\n```\\n\\n##### DTE\\xa0Context（DTE\\xa0上下文）\\n\\n在 `__shared__` 或 `__device__` 地址空间上的数据需通过 DTE 搬运。使用 DTE 前需声明 DTE\\xa0上下文，TopsCC 支持三种类型：\\n\\n* **Block 级共享 DTE\\xa0Context**：`__shared_dte__ tops_dte_ctx_t ctx[n];`——block 内线程共享 DTE 上下文，只能支持 Global 和 Shared 之间的数据传输。\\n* **Block 级私有 DTE\\xa0Context**：`__private_dte__ tops_dte_ctx_t ctx;`——Block 级的 DTE 资源，只能支持 Global 和 Shared 之间的数据传输。\\n* **Thread 级 DTE\\xa0Context**：`tops_dte_ctx_t ctx;`——线程私有 DTE 资源，可支持 Global、Shared 和 Private 之间的数据传输。\\n\\n##### mdspan\\n\\nTopsCC使用一种名为`mdspan`的数据结构来给设备地址附加额外的信息（如维度、形状、所属内存空间、总大小等），其构造函数参数包括：\\n\\n1. 所属地址空间（可选）：`tops::Global`、`tops::Shared`、`tops::Private`，对应 L3/L2/L1。\\n2. 起始地址指针。\\n3. 形状维度大小列表。\\n\\nDTE相关结构都使用`mdspan`作为配置参数。\\n\\n示例：声明 `mdspan` 的两种方式：\\n\\n```c++\\n// method 1\\ntops::mdspan src1(tops::Global, from, N, H, W, C);\\ntops::mdspan src2(from, N, H, W, C);\\n\\n// method 2\\nauto shape = {N, H, W, C};\\ntops::mdspan src3(tops::Global, from, shape);\\ntops::mdspan src4(from, shape);\\n```\\n\\n其中 `from` 为某数据类型的起始地址，DTE 操作一般支持九种数据类型（`int8_t`、`uint8_t`、`int16_t`、`uint16_t`、`int32_t`、`uint32_t`、`tops::bfloat`、`tops::half` 和 `float`）。`shape`是数据的形状，`shape[0]` 为数据最高维度的大小，通常对应内存中步幅最大（最不连续）的那一维。\\n\\n##### DTE\\xa0支持的操作模式\\n\\nDTE 支持两种使用模式：\\n\\n1. **配置与启动分离模式**：适用于计算与搬运流水并行的场景。先调用配置接口，再调用启动接口。支持同步和异步两种启动方式。\\n\\n   * **同步启动**（`trigger_and_wait`）：\\n\\n     ```c++\\n     tops_dte_ctx_t ctx;\\n     ctx.init();\\n     ctx.config_memcpy(dst, src);\\n     ctx.trigger_and_wait();\\n     ctx.destroy();\\n     ```\\n\\n   * **异步启动**（`trigger`）：返回 `tops::event`，可用 `tops::wait` 等待。\\n\\n     ```c++\\n     tops_dte_ctx_t ctx;\\n     ctx.init();\\n     ctx.config_memcpy(dst, src);\\n     tops::event ev = ctx.trigger();\\n     tops::wait(ev);\\n     ctx.destroy();\\n     ```\\n\\n2. **配置和启动合并模式**：代码更简洁，同时支持同步和异步两种方式。\\n\\n   * **同步启动**：\\n\\n     ```c++\\n     tops_dte_ctx_t ctx;\\n     ctx.init();\\n     tops::memcpy(ctx, dst, src);\\n     ctx.destroy();\\n     ```\\n\\n   * **异步启动**：调用以 `_async` 结尾的函数返回 `tops::event`，可用 `tops::wait` 等待。\\n\\n     ```c++\\n     tops_dte_ctx_t ctx;\\n     ctx.init();\\n     auto ev = tops::memcpy_async(ctx, dst, src);\\n     tops::wait(ev);\\n     ctx.destroy();\\n     ```\\n\\n##### 全量配置接口\\n\\n全量配置需要完整设置 DTE 的参数。多数搬运接口含有两个 `mdspan` 参数，第一个为目标地址对象，第二个为源地址对象。常用接口见下表：\\n\\n| 接口                                    | 描述                                                                             |\\n| ------------------------------------- | ------------------------------------------------------------------------------ |\\n| `ctx.config_memcpy(dst, src)`         | 以 `src` 总大小拷贝 `src` 到 `dst`，用户需确保 `dst` 足够大。                                   |\\n| `ctx.config_memset(dst, const_value)` | 将 `dst` 指定的内存设置为 `const_value`。                                                |\\n| `ctx.config_slice(dst, src, offset)`  | 按 `dst` 指定的形状和 `offset` 指定的位置从 `src` 中拷贝数据到 `dst`。若 `dst` 大小或偏置超出 `src`，将自动填充。**切片操作：** 在GCU的应用中，通常处理的数据量很大，而GCU的执行单元 SIP 所能访问的SIP memory比较小，所以在数据处理上，需要将大块数据切片搬运到 SIP\\xa0memory，供SIP处理加工，这种操作称为slice，你想的操作称为deslice。根据数据处理需求，可选择以下切片方式：(1)**线性切片**：依次将相应的数据片段搬运到SIP memory中。一个典型的例子：如果要处理的是一个2维数组，而SIP每次可以处理数组中的完整一行，则可以对该数组进行线性切片。  (2)**等维切片**：对多维数组同时沿各维切割成多个形状相同的块（将一个 N 维数组切为多个小的 N 维数组）。一个典型的例子：将一个3维数组切分成多个小形状的3维数组，可以理解为把一个大的立方体切分成多个小立方体。 (3)**多维切片**：仅在指定的部分维度上进行切片。可以把线性切片和等维切片理解为多维切片的两个特例|\\n| `ctx.config_deslice(dst, src, offset)`                            | 把 `src` 指定的数据拷贝并覆盖到 `dst` 的 `offset` 位置。                 |\\n| `ctx.config_transpose(dst, src, layout)`                          | 按 `layout` 对 `src` 进行转置并拷贝至 `dst`，layout的数据排列定义为形如{0,1,2,3}。                       |\\n| `ctx.config_slice_transpose(dst, src, offset, layout)`            | slice和transpose的组合，先对 `src` 切片，再按 `layout` 转置切片并放入 `dst`。                   |\\n| `ctx.config_transpose_deslice(dst, src, offset, layout)`          | transpose和deslice的组合，先对 `src` 按 `layout` 转置，再拷贝并覆盖到 `dst` 指定位置。               |\\n| `ctx.config_pad(dst, src, pad_low, pad_high, pad_mid, pad_value)` | 垫片操作，把src指定的数据，按照dst所指定的形状和大小，用pad_value的值设置到src的首部（pad_low有效），尾部（pad_high有效），或者中间（pad_mid有效），并把结果移动到dst所指的位置。 |\\n| `ctx.config_mirror_tb(dst, src)`                                  | 按第一维（X 轴，shape的最后一个元素）翻转 `src`，结果放入 `dst`。                        |\\n| `ctx.config_mirror_lr(dst, src)`                                  | 按第二维（Y 轴，shape的倒数第二个元素）翻转 `src`，结果放入 `dst`。                        |\\n| `ctx.config_broadcast(dst, src)`                                  | 根据 `src` 到 `dst` 维度变化扩展 `src` 数据，结果放入 `dst`。             |\\n\\n##### 增量配置接口\\n\\n增量配置接口是指在完成一次全量 DTE 配置后，后续仅对发生变化的部分调用相应的API进行配置，可以减少DTE配置时间。增量配置接口可以在不修改DTE数据搬运操作的类型的情况下改变 DTE context 的配置。\\n\\n* **基础增量接口：**\\n\\n| 接口                       | 描述          |\\n| ------------------------ | ----------- |\\n| `ctx.set_dst_addr(addr)` | 设置新的 dst 地址 |\\n| `ctx.set_src_addr(addr)` | 设置新的 src 地址 |\\n| `ctx.set_dst_offset(dim, offset)`               | 设置 `dst` 在维度 `dim` 的偏移 |\\n| `ctx.set_src_offset(dim, offset)`               | 设置 `src` 在维度 `dim` 的偏移 |\\n| `ctx.set_dst_dim_size(dim, size)`               | 设置 `dst` 在维度 `dim` 的大小 |\\n| `ctx.set_src_dim_size(dim, size)`               | 设置 `src` 在维度 `dim` 的大小 |\\n| `ctx.set_total_size(size)`                      | 设置整体大小，常用于 memcpy      |\\n| `ctx.set_transpose_layout(layout)`              | 设置转置的 `layout`         |\\n| `ctx.set_pad_config(pad_low, pad_high, ad_mid)` | 设置 pad 参数              |\\n\\n##### 启动和同步接口\\n\\n* **启动接口（配置与启动分离时使用）：**\\n\\n| 接口                       | 描述                     |\\n| ------------------------ | ---------------------- |\\n| `ctx.trigger()`          | 触发 DTE 操作，返回一个 `event` |\\n| `ctx.trigger_and_wait()` | 触发 DTE 操作并等待完成         |\\n\\n* **同步接口：**\\n\\n| 接口            | 描述              |\\n| ------------- | --------------- |\\n| `wait(event)` | 等待指定 `event` 完成 |\\n\\n##### 配置和启动合并接口\\n\\n在接口中，ctx参数是指定DTE上下文，dst是mdspan指定的数据搬运的输出位置，src是mdspan指定的数据搬运的输入位置。\\n使用下列函数可同时完成配置和启动，均支持九种数据类型，并提供 `_async` 后缀的异步版本：\\n\\n| 接口                                                                | 描述                                       |\\n| ----------------------------------------------------------------- | ---------------------------------------- |\\n| `tops::memcpy(ctx, dst, src)`                                     | 以 `src` 总大小拷贝 `src` 到 `dst`              |\\n| `tops::memset(ctx, dst, const_value)`                             | 将 `dst` 指定的内存设置为 `const_value`           |\\n| `tops::slice(ctx, dst, src, offset)`                              | 按 `dst` 形状和 `offset` 从 `src` 拷贝数据到 `dst` |\\n| `tops::deslice(ctx, dst, src, offset)`                            | 把 `src` 数据拷贝并覆盖到 `dst` 指定位置              |\\n| `tops::transpose(ctx, dst, src, layout)`                          | 按 `layout` 转置 `src` 并拷贝至 `dst`           |\\n| `tops::slice_transpose(ctx, dst, src, offset, layout)`            | 先切片再转置再拷贝至 `dst`                         |\\n| `tops::transpose_deslice(ctx, dst, src, offset, layout)`          | 先转置再覆盖到 `dst`                            |\\n| `tops::pad(ctx, dst, src, pad_low, pad_high, pad_mid, pad_value)` | 按形状填补并拷贝至 `dst`                          |\\n| `tops::mirror_tb(ctx, dst, src)`                                  | 第一维翻转并拷贝至 `dst`                          |\\n| `tops::mirror_lr(ctx, dst, src)`                                  | 第二维翻转并拷贝至 `dst`                          |\\n| `tops::broadcast(ctx, dst, src)`                                  | 按维度变化扩展 `src` 并拷贝至 `dst`                 |\\n\\n#####\\xa0DTE\\xa0软件流水编程\\n\\n使用异步编程接口可以完成数据流的软件流水，把计算和数据搬运的并行起来，从而达到更好的计算性能。\\n代码：计算和数据搬运流水并行示例代码\\n\\n```c\\n    tops_dte_ctx_t ctxs[2][2];\\n    tops::event evs[2][2];\\n\\n    for (int i = 0; i < 2; i++)\\n        for (int j = 0; j < 2; j++)\\n            ctxs[i][j].init();\\n\\n    __aligned__ int input_buffer[2][tile_size];\\n    __aligned__ int output_buffer[2][tile_size];\\n\\n    tops::mdspan input(tops::Global, in, tile_size);  // in 为 L3 指针\\n    tops::mdspan output(tops::Global, out, tile_size); // out 为 L3 指针\\n\\n    for (int i = 0; i < 2; i++)\\n        ctxs[0][i].config_memcpy(tops::mdspan(tops::Private,\\n                               input_buffer[i], tile), input, tile_size);\\n\\n    for (int i = 0; i < 2; i++)\\n        ctxs[1][i].config_memcpy(output,\\n                               tops::mdspan(tops::Private, output_buffer[i], tile), tile_size);\\n\\n    evs[0][0] = ctxs[0][0].trigger();\\n    int iter = 0;\\n\\n    for (int i = 0; i < size; i += tile_size) {\\n        evs[0][iter%2].wait();\\n        if (i + tile_size < size) {\\n            ctxs[0][(iter+1)%2].set_src_addr(in + i);\\n            evs[0][(iter+1)%2] = ctxs[0][(iter+1)%2].trigger();\\n        }\\n\\n        // do computation\\n        foo(input_buffer[iter%2], output_buffer[iter%2]);\\n\\n        if (i != 0) {\\n            evs[1][(iter-1)%2].wait();\\n        }\\n        ctxs[1][iter%2].set_dst_addr(output + i);\\n        evs[1][iter%2] = ctxs[1][iter%2].trigger();\\n        if (i + tile_size >= size) {\\n            evs[1][iter%2].wait();\\n        }\\n        iter++;\\n    }\\n\\n    for (int i = 0; i < 2; i++)\\n        for (int j = 0; j < 2; j++)\\n            ctxs[i][j].destroy();\\n```\\n\\n默认情况下，DTE 的非法行为不会报错，加上宏 -DTOPS_ENABLE_DTE_CHECK 会检查非法行为。\\n\\n#### 3.2.4.2 计算流程编程\\n\\n一般地，topscc 支持标量计算。计算只能发生在线程内部，且从 L1 中读取数据。对于 L1 的地址，可以直接使用下标索引数据。\\n\\n```c\\n    __aligned__ int inp[128];\\n    __aligned__ int out[128];\\n    for (size_t i = 0; i < 128; ++i) {\\n        out[i] = inp[i] * inp[i];\\n    }\\n```\\n\\n此外，TopsCC 提供了向量接口和矩阵计算接口，以利用 GCU 的 1D 和 2D 算力。\\n\\n##### 1D 计算流编程\\n\\n一个 `vector` 类型默认长度为 **128** 字节，支持的 `vector` 类型如下所示。\\n\\n###### 表 3-7 支持的 `vector` 类型\\n\\n| 类型        | 说明                    | 默认的元素个数                                   |\\n| --------- | --------------------- | ----------------------------------------- |\\n| `vchar`   | `char` 向量类型           | 一个 `vchar` 向量包含 **128** 个 `int8_t`        |\\n| `vuchar`  | `unsigned char` 向量类型  | 一个 `vuchar` 向量包含 **128** 个 `uint8_t`      |\\n| `vshort`  | `short` 向量类型          | 一个 `vshort` 向量包含 **64** 个 `int16_t`       |\\n| `vushort` | `unsigned short` 向量类型 | 一个 `vushort` 向量包含 **64** 个 `uint16_t`     |\\n| `vint`    | `int` 向量类型            | 一个 `vint` 向量包含 **32** 个 `int`             |\\n| `vuint`   | `unsigned int` 向量类型   | 一个 `vuint` 向量包含 **32** 个 `unsigned int`   |\\n| `vfloat`  | `float` 向量类型          | 一个 `vfloat` 向量包含 **32** 个 `float`         |\\n| `vhalf`   | `half` 向量类型           | 一个 `vhalf` 向量包含 **64** 个 `tops::half`     |\\n| `vbfloat` | `bfloat` 向量类型         | 一个 `vbfloat` 向量包含 **64** 个 `tops::bfloat` |\\n\\n> 支持的 `vector` 操作包括：\\n\\n###### 表 3-8 支持的 `vector` 操作（I）\\n\\n| 接口           | 描述                                                                                       |\\n| ------------ | ---------------------------------------------------------------------------------------- |\\n| `vload`      | 从指定地址开始读取一个向量数据。`vload` 访问的地址需要对齐，即需要用 `__aligned__` 修饰。例如：`auto v = vload<vint>(addr);` |\\n| `vstore`     | 存储一个向量数据到某个指定地址。例如：`vstore(value, addr);`                                                |\\n| `vlength`    | 根据给定的数据类型，返回对应的 `vector` 计算所支持的向量长度。例如：`__aligned__ int buf[tops::vlength<vint>()]`      |\\n| `vzero`      | 返回一个向量，所有值都设置为 `0`                                                                       |\\n| `vadd`       | 返回两个向量的和。例如：`vint sum = tops::vadd(lhs, rhs)`                                            |\\n| `vsub`       | 返回两个向量的差。例如：`vint diff = tops::vsub(lhs, rhs)`                                           |\\n| `vmul`       | 返回两个向量的乘积。例如：`vint prdt = tops::vmul(lhs, rhs)`                                          |\\n| `vdiv`       | 返回两个向量的商。例如：`vint quot = tops::vdiv(lhs, rhs)`                                           |\\n| `vmod`       | 返回两个向量的模。例如：`vint md = tops::vmod(lhs, rhs)`                                             |\\n| `vrem`       | 返回两个向量的余数。例如：`vint rm = tops::vrem(lhs, rhs)`                                            |\\n| `vsign`      | 返回一个向量中每个元素的“符号”型，正数返回 1，负数返回 −1。例如：`vint sgn = tops::vsign(v)`                          |\\n| `vbroadcast` | 将一个标量的值赋给向量的所有成员。例如：`vint brd = tops::vbroadcast(int2)`                                  |\\n| `vcast`      | 因为向量类型不支持隐式转换，所以可以用这个函数进行**显示类型转换**                                                      |\\n| `vbitcast`   | 将一个向量强制转换为另外一个相同大小的向量。例如：`vchar cv = tops::vbitcast(iv)`                                 |\\n| `vsin`       | 返回一个向量每个元素的正弦，仅支持 `vfloat` 类型。例如：`auto vsn = tops::vsin(fv)`                             |\\n| `vasin`      | 返回一个向量每个元素的反正弦，仅支持 `vfloat` 类型。例如：`auto vasn = tops::vasin(fv)`                          |\\n| `vsinh`  | 返回一个向量每个元素的双曲正弦，仅支持 `vfloat` 类型。例如：`auto vhs = tops::vsinh(fv)`                                               |\\n| `vasinh` | 返回一个向量每个元素的反双曲正弦，仅支持 `vfloat` 类型。例如：`auto vahs = tops::vasinh(fv)`                                            |\\n| `vcos`   | 返回一个向量每个元素的余弦，仅支持 `vfloat` 类型。例如：`auto vcs = tops::vcos(fv)`                                                  |\\n| `vcosh`  | 返回一个向量每个元素的双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhcs = tops::vcosh(fv)`                                              |\\n| `vacos`  | 返回一个向量每个元素的反余弦，仅支持 `vfloat` 类型。例如：`auto vacs = tops::vacos(fv)`                                               |\\n| `vacosh` | 返回一个向量每个元素的反双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhacs = tops::vacosh(fv)`                                           |\\n| `vabs`   | 返回一个向量每个元素的绝对值，仅支持 `vfloat` 类型。例如：`auto vabso = tops::vabs(fv)`                                               |\\n| `vcbrt`  | 返回一个向量每个元素的立方根，仅支持 `vfloat` 类型。例如：`auto vcbr = tops::vcbrt(fv)`                                               |\\n| `vtan`   | 返回一个向量每个元素的正切，仅支持 `vfloat` 类型。例如：`auto vtn = tops::vtan(fv)`                                                  |\\n| `vatan`  | 返回一个向量每个元素的反正切，仅支持 `vfloat` 类型。例如：`auto vatn = tops::vatan(fv)`                                               |\\n| `vatan2` | 将两个向量每个元素分别相除，再对结果进行反正切，仅支持 `vfloat` 类型。例如：`auto vatan2 = tops::vatan2(fv1, fv2)`                             |\\n| `vneg`   | 返回一个向量的符号相反的值，支持所有符号类型。例如：`auto vng = tops::vneg(fv)`                                                         |\\n| `vsqrt`  | 返回一个向量每个元素的平方根，仅支持 `vfloat` 类型。例如：`auto vsqt = tops::vsqrt(fv)`                                               |\\n| `vrsqrt` | 返回一个向量每个元素的**反平方根**，仅支持 `vfloat` 类型。例如：`auto vrsqt = tops::vrsqrt(fv)`                                        |\\n| `vfloor` | 返回一个向量每个元素的**向下取整**（最接近且不大于自身的整数），仅支持 `vfloat` 类型。例如：`auto vflr = tops::vfloor(fv)`                           |\\n| `vceil`  | 返回一个向量每个元素的**向上取整**（最接近且不小于自身的整数），仅支持 `vfloat` 类型。例如：`auto vcl = tops::vceil(fv)`                             |\\n| `vround` | 返回一个向量每个元素**最接近**的整数，仅支持 `vfloat` 类型。例如：`auto vrnd = tops::vround(fv)`                                        |\\n| `vtrunc` | 按截断规则 `trunc(x) = x >= 0 ? floor(x) : ceil(x)` 处理向量每个元素返回，仅支持 `vfloat` 类型。例如：`auto vtrc = tops::vtrunc(fv)`   |\\n| `vrint`  | 和 `vround` 很像，例如把 `x=5.5` 的浮点数，`round` 会处理成 `+1`，`rint` 是 `×`；仅支持 `vfloat` 类型。例如：`auto vri = tops::vrint(fv)` |\\n| `vexp`   | 按输入向量的每个元素作为数学常数 `e` 的指数计算后，返回一个**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto vxp = tops::vexp(fv)`                     |\\n| `vexpm1` | 按输入向量的每个元素作为指数的 **`e^x - 1`** 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxpm = tops::vexpm1(fv)`                |\\n| `vexp2`  | 按输入向量的每个元素为 2 的指数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxp2 = tops::vexp2(fv)`                              |\\n| `vlog`   | 按输入向量的每个元素为数学常数 `e` 的对数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg = tops::vlog(fv)`                          |\\n| `vlog1p`    | 按输入向量的每个元素加 1 后作自然对数计算（`log(1+x)`），返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlgp = tops::vlog1p(fv)`                     |\\n| `vlog2`     | 按输入向量的每个元素为 2 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg2 = tops::vlog2(fv)`                                     |\\n| `vlog10`    | 按输入向量的每个元素为 10 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg10 = tops::vlog10(fv)`                                  |\\n| `vlogb`     | 按输入向量的每个元素以 10 为底的对数，只保留**整数部分**，并返回**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto v lgb = tops::vlogb(fv)`                    |\\n| `vilogb`    | 按输入向量的每个元素以 10 为底的对数，只保留结果的**整数部分**，并返回一个**整数型**向量，仅支持 `vfloat` 类型。例如：`auto vilgb = tops::vilogb(fv)`               |\\n| `vpower`    | 按第一个输入向量的每个元素为底数、第二个输入向量的对应元素为指数计算，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vpw = tops::vpower(fv1, fv2)`               |\\n| `vgelu`     | 计算输入向量每个元素的高斯误差线性单元，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vglu = tops::vgelu(fv)`                                    |\\n| `vsoftplus` | 按照规则 `vlog(vexp(v)+1)` 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vstp = tops::vsoftplus(fv)`                          |\\n| `vsigmoid`  | 计算输入向量每个元素的 Sigmoid 函数，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vsigmoid(fv)`                               |\\n| `vdim`      | 计算第一个输入向量和第二个向量的差值，如果差值是个负数则返回 `0`，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vdim(fv1, fv2)`                 |\\n| `vhypot`    | 以第一个向量每个元素的直角边，以及第二个向量的对应元素作为第二直角边，计算相应的斜边，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vhypot(fv1, fv2)`    |\\n| `vcopysign` | 以第二个向量的每个元素的符号，作为第一个向量对应元素的符号，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vcopysign(fv1, fv2)`                |\\n| `visnan`    | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素不是 `NaN`，其它位代表 `NaN`，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visnan(fv)`       |\\n| `visfinite` | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素是 `NaN` 或者 `INF`，其它代表不是，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visfinite(fv)` |\\n| `vmax`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最大**值组成，支持所有类型。例如：`auto vmx = tops::vmax(v1, v2)`                                      |\\n| `vmin`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最小**值组成，支持所有类型。例如：`auto vmn = tops::vmin(v1, v2)`                                      |\\n| `vand`      | 按照两个输入向量的位计算“与”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vand(v1, v2)`                                              |\\n| `vor`       | 按照两个输入向量的位计算“或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vor(v1, v2)`                                               |\\n| `vxor`      | 按照两个输入向量的位计算“异或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vxor(v1, v2)`                                             |\\n| `vnot`    | 按照两个输入向量的位计算“非”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vnot(v1, v2)`                                                    |\\n| `vshl`    | 按照向量 `v` 中的每个元素指定的位数，按位向左移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshl(v1, v2)`          |\\n| `vshr`    | 按照向量 `v` 中的每个元素指定的位数，按位向右移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshr(v1, v2)`          |\\n| `vshli`   | 按照参数 `is` 指定的位数，按位向左移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshli(iv, is)`                 |\\n| `vshri`   | 按照参数 `is` 指定的位数，按位向右移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshri(iv, is)`                 |\\n| `vselect` | 按照第一个向量每个元素的条件（`0` 代表否），选择第二个向量对应元素（条件为是）或第三个（条件为否），并返回和后两个向量相同的类型的向量，支持所有类型。例如：`auto vsel = tops::vselect(vcnd, v1, v2)` |\\n\\n#### 3.2.4.2 2D 计算流编程\\n\\n（在 2D 计算相关题目里，会在题目说明中提供 2DAPI 使用方法。）\\n\\n#### 3.2.4.3 同步\\n\\nTopsCC 支持 **Block** 内的所有 **Thread** 同步，以及整个 **Grid** 的全局同步。\\n\\n* `__syncthreads`：Block 内所有 Thread 做一次同步。\\n* `__synclockblocks`：Grid 内所有 Thread 做一次同步。\\n\\n> 说明：使用 `__synclockblocks` 的 `kernel` 需必须声明为 `__cooperative__`。\\n\\n### 3.2.5 主机端编程\\n\\n> 注：本次竞赛主要考察设备端编程，主机端编程部分作为参考，帮助参赛者理解主机侧。\\n\\n主机端运行时实现依赖 `TopsRT` 库中，基于 TopsCC 开发的应用程序会动态链接到 `libtopsrt.so`。运行时所有接口都以 `tops` 为命名前缀。运行时主要负责以下类别的管理：\\n\\n* 执行环境：描述了主机运行时的设备管理和初始化过程。\\n* 存储系统：描述了运行时感知的存储管理系统。\\n* 异步并行：描述了在不同层面上如何通过运行时接口实现异步并行。\\n* 多设备：描述了跨多个设备编程时的相关接口行为。\\n\\n#### 3.2.5.1 互斥限制\\n\\n使用 `shared` 类型时，一个 **Block** 中只能有一个 `thread`（对应一个 **SIP**）执行 L3->L2 内存复制。\\n\\n#### 3.2.5.2 存储系统\\n\\nTopsCC 编程模型下假设系统由主机端和设备端组成，二者有独立的存储：**主存**和**设备内存**。Kernel 主要在设备内存中工作，主机运行时需要负责设备内存的**分配、释放、拷贝，以及在主存和设备内存间的数据搬运**。\\n\\n#### 3.2.5.3 设备内存\\n\\n当前设备内存为**线性内存**，内存句柄中仅包含地址信息，不包含维度解释、切片（tiling）等信息。\\n当前设备地址空间为设备物理地址，因此和主机地址空间没有统一。设备地址空间的位宽如下所示：\\n\\n**表 3-9 设备内存**\\n\\n| 设备地址空间位宽 | T20           | i20           |\\n| -------- | ------------- | ------------- |\\n|          | 最大 **40bits** | 最大 **40bits** |\\n\\n线性内存分配在设备地址空间中，并**映射式**地映射到主机地址空间中。每个分配的内存对象可以在主机端通过指针来引用，主机端的指针被包装为运行时的内存对象句柄。而在设备端 **Kernel** 通过设备地址引用内存对象，其表现形式仍为指针。在主机端启动 Kernel 时，会将主机端指针转换为设备端指针，让工作在两个地址空间中的代码可以协同。\\n\\n内存对象通常通过 **topsMalloc()** 分配和 **topsFree()** 释放，数据搬运使用 **topsMemcpy** 接口（如前所述目前 **topsMalloc3D** 和 **topsMallocPitch** 类接口均不支持）。下面代码所示：\\n\\n```cpp\\n#include <stdio.h>\\n\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n\\n__global__ void vec_add(int *from, int *to, size_t N)\\n{\\n    tops_dte_ctx_t ctx;\\n    tops::dte_scope s(ctx);\\n    __aligned__ int buffer[128];\\n\\n    tops::mdspan buf(tops::Private, &buffer, 128);\\n\\n    for (size_t i = 0; i < N; i += 128) {\\n        tops::mdspan src(tops::Global, from + i, 128);\\n        tops::mdspan dst(tops::Global, to + i, 128);\\n        tops::memcpy(ctx, buf, src);\\n\\n        for (size_t j = 0; j < 128; j += tops::vlength<vint>()) {\\n            const auto &v = tops::vload<vint>(buffer + j);\\n            tops::vstore(tops::vadd<vint>(v, v), buffer + j);\\n        }\\n\\n        tops::memcpy(ctx, dst, buf);\\n    }\\n}\\n\\nint main(int argc, char *argv[])\\n{\\n    int *A_d, *C_d;\\n    int *A_h, *C_h;\\n    size_t N = 512;\\n    size_t Nbytes = N * sizeof(int);\\n\\n    A_h = (int*)malloc(Nbytes);\\n    C_h = (int*)malloc(Nbytes);\\n\\n    // Initialize the data.\\n    ...\\n\\n    topsMalloc(&A_d, Nbytes);\\n    topsMalloc(&C_d, Nbytes);\\n\\n    topsMemcpy(A_d, A_h, Nbytes, topsMemcpyHostToDevice);\\n\\n    vec_add<<<1, 1>>>(A_d, C_d, N);\\n\\n    topsMemcpy(C_h, C_d, Nbytes, topsMemcpyDeviceToHost);\\n\\n    topsFree(A_d);\\n    topsFree(C_d);\\n\\n    free(A_h);\\n    free(C_h);\\n\\n    return 0;\\n}\\n```\\n\\n#### 3.2.5.4 访问主存\\n\\n除设备内存之外，设备也可以访问**问系统主存**，用户需要通过 ``topsMallocHost()`` 分配或 ``topsHostRegister()`` 接口注册分配的系统内存指针。主存同样会被映射到两个地址空间中，并且锁定在物理内存中（**pinned pages**）。\\n\\n设备端对其访问的性能会较低，但会有如下优点：\\n\\n* 可以实现设备端发起的异步数据拷贝从而和 ``Kernel`` 的执行并行。\\n* 映射到设备地址空间后，设备端可以直接访问少量内存拷贝。\\n* 目前在主存和设备内存之间自动迁移的内存对象尚不支持，即 ``topsMallocManaged()`` 当前不可用。\\n\\n#### 3.2.5.5 全局变量\\n\\n主机运行时还可以访问程序中的设备空间全局变量，示例如下：\\n\\n```cpp\\n#include <tops/tops_runtime.h>\\n#include <tops/tops_runtime_api.h>\\n#include <tops.h>\\n\\n__device__ int globalIn[256];\\n__device__ int globalOut[256];\\n\\nint main(int argc, char *argv[])\\n{\\n    int data[256] = {0};\\n    int* ptr;\\n\\n    topsMalloc(&ptr, 256 * sizeof(int));\\n\\n    topsMemcpyFromSymbol(data, globalIn, 256 * sizeof(int));\\n\\n    topsMemcpy(ptr, data, 256 * sizeof(int), topsMemcpyHostToDevice);\\n\\n    topsMemcpyToSymbol(globalOut, ptr, 256 * sizeof(int));\\n\\n    topsFree(ptr);\\n\\n    return 0;\\n}\\n```\\n\\n``topsGetSymbolAddress()`` 可以获取全局变量的内存句柄，``topsGetSymbolSize()`` 可以获取内存对象的大小。\\n\\n#### 3.2.5.6 异步并行\\n\\nTopsRider 提供了一系列 **API**，为各种层级的计算和存储运并行提供支持：\\n\\n* 在主机端的计算\\n* 在设备端的计算\\n* 从主机端向设备搬运数据\\n* 从设备端向主机搬运数据\\n* 在指定设备内搬运数据\\n* 在设备之间搬运数据\\n\\n上述这些任务可以在不同层面并行。\\n\\n##### 主机端和设备端并行\\n\\n主机端通过异步接口将任务下发到设备的队列中，设备执行完毕后会通知主机端（**event**），在此期间设备端可以执行其他任务而不是阻塞等待。设备端支持如下的异步任务：\\n\\n* 启动内核\\n* 内存拷贝\\n* 内存赋值\\n\\n上述任务同样支持对应的同步任务 API。\\n\\n#### 3.2.5.7 多核并行执行\\n\\n在同一个设备上，不同的进程、上下文、线程都可以使用并行下发的方式异步启动内核任务。多个内核使用的资源充足时，它们就会并行调度执行。\\n\\n##### 数据流与计算并行\\n\\n数据通道需要从主存搬运数据到设备内存，经由计算后将结果从设备内存搬回主存，这个过程可以通过**输入、计算、输出**三级流水，在内核逻辑里也有类似的流水并行优化，但是主机端运行时不感知，三者也可以并行执行。\\n\\n##### 数据传输并行\\n\\n在硬件上主数据搬运的带宽通常大于一个，因此输入、输出和设备内的数据搬运经常可以并行，受限于总线带宽和读写口数量，并发数据传输并不总是会获得更好的性能，部分场景下会有较大收益。\\n\\n##### Stream 任务流\\n\\n上述描述的所有并行场景都是通过一种称为 **stream** 的任务流来实现的。**stream** 是一段命令协议包（**command packet**）的序列，命令序列会被设备端按照顺序执行。不同的 stream 中的命令序列的执行顺序则是彼此独立的，可以在多个 stream 之间显式的添加依赖来控制它们执行顺序的关系。同步等待一个 stream 可以保证之前已下发的所有命令全部完成。\\n\\n**1. 创建和销毁**\\n\\nstream 的创建包括构造一个任务流对象以及添加任务流中的任务，例如启动内核、主存与设备内存之间的数据拷贝。下面代码例子中创建了两个 stream 对象并分配了一个映射到设备端的主存中的数组。\\n\\n```cpp\\ntopsStream_t stream[2];\\n\\nfor (int i = 0; i < 2; ++i)\\n    topsStreamCreate(&stream[i]);\\n\\nfloat* hostPtr;\\ntopsMallocHost(&hostPtr, 2 * size);\\n```\\n\\n每个stream对象负责一个主存到设备内存的数据搬运、一个启动内核操作、一次设备内存到主存的数据搬运\\n\\n```cpp\\nfor (int i = 0; i < 2; ++i) {\\n    topsMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,\\n                    size, topsMemcpyHostToDevice, stream[i]);\\n\\n    MyKernel<<<1, 0, stream[i]>>>(\\n        outputDevPtr + i * size, inputDevPtr + i * size, size);\\n\\n    topsMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,\\n                    size, topsMemcpyDeviceToHost, stream[i]);\\n}\\n```\\n\\n两个 stream 都会拷贝自己的一段输入数组 **hostPtr** 到设备内存的 **inputDevPtr** 中，然后调用 **MyKernel()** 处理 **inputDevPtr**，再将结果 **outputDevPtr** 从设备内存中拷贝回 **hostPtr** 的主存里。根据设备的能力，两个 stream 交替或同时执行。\\n\\n用户需要主动销毁 stream 对象。\\n\\n```cpp\\nfor (int i = 0; i < 2; ++i)\\n    topsStreamDestroy(stream[i]);\\n```\\n\\n为避免用户阻塞正在执行的 stream，**topsStreamDestroy()** 接口会立即返回，但是 stream 对象和关联的资源会在设备端完成 stream 的执行后才会释放。\\n\\n**2. 默认 stream**\\n\\n用户调用异步任务接口时通常需要传递 **stream** 参数指定任务流。如果用户不指定或者传递空 **stream** 指针，则任务会被发送到**默认 stream** 上，并且按顺序下发顺序保证顺序执行。每个设备拥有一个默认 stream，所有线程在该设备上共享同一个默认 stream。尚不支持多线程下每个线程拥有独立的默认 stream。\\n\\n**3. 显式同步**\\n\\n用户可以主动同步 stream：\\n\\n* `topsDeviceSynchronize()` 会等待当前所有线程的所有 **stream** 全部执行完成。\\n* `topsStreamSynchronize()` 接受一个 **stream** 对象作为参数，等待该 stream 对象上的所有任务都完成。\\n* `topsStreamWaitEvent()` 接受一个 **stream** 和一个 **event** 作为参数，在任务流上构建一个异步等待任务，所有该任务之后下发的任务都会等待 **event** 对应的事件发生后才会继续执行。\\n* `topsStreamQuery()` 供应用程序查询某个 **stream** 里的任务是否已经完成。\\n\\n**4. 隐式同步**\\n\\n不同 **stream** 的命令通常可以并行，暂时没有操作会触发隐含的同步行为。\\n\\n**5. 并发行为**\\n\\n多个 stream 上的命令，其并发行为取决于各自命令所在序列顺序，以及设备对各种类型任务支持的最大并发数量。\\n例如，在设备上如果某个时钟的数据搬运任务的最大并发度是 **1**，那么两个 stream 上的内存拷贝操作将会结构性冒险（**structural hazard**），进而串行执行。运行时未来将提供接口可查询各类型任务当前执行环境下的最大并发度。\\n两个 stream 上的不同类型的任务可以在设备端并发执行。\\n\\n**6. 主机端回调**\\n\\n运行时提供了 `topsStreamAddCallback()` 接口，可以向 stream 中插入一个异步的主机端回调任务，在这个任务之前的所有任务执行完毕后，该任务才会执行。下面例子中 **MyCallback** 函数会在设备内存到主存的数据搬运结束后被执行。\\n\\n```cpp\\nvoid topsStreamCallback_t MyCallback(topsStream_t stream, topsError_t status, void *data) {\\n    printf(\"inside callback %d\\\\n\", (size_t)data);\\n}\\n\\nfor (size_t i = 0; i < 2; ++i) {\\n    topsMemcpyAsync(devPtrIn[i], hostPtr[i], size, topsMemcpyHostToDevice, stream[i]);\\n\\n    MyKernel<<<1, 1, 0, stream[i]>>>(devPtrOut[i], devPtrIn[i], size);\\n\\n    topsMemcpyAsync(hostPtr[i], devPtrOut[i], size, topsMemcpyDeviceToHost, stream[i]);\\n\\n    topsStreamAddCallback(stream[i], MyCallback, (void*)i);\\n}\\n```\\n\\n在主机端回调任务之后下发到 stream 上的任务不会等待回调函数结束后才执行，而是直接顺序执行。因此如果需要同步阻塞等待的场景，需要主机端使用同步接口例如 `topsStreamSynchronize()` 来实现。\\n\\n**7. Stream 优先级**\\n\\n当前 **stream 不支持优先级** 调度。\\n\\n##### 事件\\n\\n**event** 事件可以用于跟踪设备端异步任务的执行进度，显式同步设备端的多个 **stream**，同步主机端和设备端的任务。事件可以记录在 stream 上；当一个事件完成时，该 stream 上所有处于这个 **event** 前的任务都已经执行完成。默认 **stream** 上的事件发生时，所有 stream 上在这个事件记录之前下发的所有任务都已经执行完成。\\n\\n**创建和销毁：**\\n\\n```cpp\\ntopsEvent_t start, stop;\\n\\ntopsEventCreate(&start);\\ntopsEventCreate(&stop);\\n\\ntopsEventDestroy(start);\\ntopsEventDestroy(stop);\\n```\\n\\n##### 同步任务调用\\n\\n有一些任务接口是**同步**的，在设备端将任务执行完之前，接口不会返回。可以通过 `topsSetDeviceFlags()` 接口来控制主机端线程此时是让步（yield）、阻塞或是忙等。\\n\\n#### 3.2.5.8 统一地址空间\\n\\n目前 TopsCC 程序尚未实现完整的统一地址空间机制。通过存储管理接口分配的内存对象句柄均为主机端指针，用户程序可以直接对其读写访问。当句柄被传递到接口中使用时，会根据需要将其转换到设备地址空间的指针，用户程序可以直接使用。\\n\\n```cpp\\n__global__ void test(int *ptr)\\n{\\n    printf(\"%lx\\\\n\", (uint64_t)ptr); // device address pointer\\n}\\n\\nint main(int argc, char *argv[])\\n{\\n    int *data;\\n\\n    topsMalloc(&data, sizeof(int));\\n    *data = 0; // host address pointer\\n\\n    test<<<1, 1>>>(data);\\n\\n    topsFree(data);\\n\\n    return 0;\\n}\\n```\\n\\n```cpp\\n#include <tops/tops_runtime.h>\\n\\n__device__ extern void foo();\\n\\n__global__ void bar() {\\n    foo();\\n}\\n\\nint main() {\\n    bar<<<1,1>>>();\\n    return 0;\\n}\\n```\\n\\n\\n### 3.4 编程限制汇总\\n\\n#### 3.4.1 编程相关\\n\\n1. **GCU 2.0 不支持全局寻址**。kernel 不能直接访问 `__shared__` 和 `__device__` 地址空间。需要通过 **DTE** 将 `__shared__` 和 `__device__` 地址的内容搬运至 **L1** 进行计算。\\n2. 关于打印功能，在 kernel function 中 **printf** 只支持打印**整型**，不支持 **%s** 和 **%p**。关于地址打印，可以将指针对强制转换成 **long long** 类型。\\n3. 在 **GCU210** 上 **Block dims** 的乘积最大为 **12**，即一个 Block 内**最多开 12 个 Thread**。\\n4. 在 **GCU210** 上 **Grid dims** 的乘积最大为 **2**。\\n5. **GCU 2.0 不允许直接访问 shared memory（L2）**，只能用于 **DTE** 数据搬运操作。动态大小的 shared memory，每个 `__global__` 函数只能使用一个。\\n6. 有关硬件支持 shared memory 的大小限制，**i20** 上每个 Block **最大 share memory 24MB**。\\n7. 当核函数里有 `printf` 或者 `assert` 调用时，runtime 处于 **debug 同步模式**，也就是一个 Stream 上核函数的运行是强制同步的。\\n\\n### 3.4.2 DTE 数据搬运\\n\\n1. 用 `__shared_dte__` 和 `__private_dte__` 声明的 **DTE Context** 只能支持 **Global** 和 **Shared** 之间的数据传输。不加任何修饰符声明的 **DTE Context** 是 **Thread** 私有的 DTE 上下文，支持 **Global、Shared 和 Private** 之间的数据传输。\\n2. 使用 **shared dte** 时，一个 **Block** 中只有一个 **Thread** 可以做 **L3->L2** 或 **L2->L3** 搬运。\\n\\n### 3.5 性能调优指南\\n\\n尽量使用 **DTE 软件流水** 使得**数据搬运**和**计算**可以并行。\\n\\n---\\n\\n# 4 FAQ\\n\\n## 4.1 使用报错信息\\n\\n**Q：** 使用 `mdspan` 时地址空间类型设置错误，可能会引发程序 *hang*。\\n**A：** 检查地址空间类型设置，**L1 内存**地址设置为 `tops::Private`，**L2 内存**地址设置为 `tops::Shared`，**L3 内存**地址设置为 `tops::Global`。\\n示例程序如下：\\n\\n```cpp\\n__global__ void foo(int *arr, int size) {\\n    tops_dte_ctx_t ctx;\\n    tops::dte_scope s(ctx);\\n\\n    int buf[size];\\n\\n    tops::mdspan L3(tops::Private, arr, size); // L3 should be set to tops::Global but wrongly set to tops::Private\\n    tops::mdspan L1(tops::Global, buf, size);  // L1 should be set to tops::Private but wrongly set to tops::Global\\n\\n    tops::memcpy(ctx, L1, L3);                 // at this point the program may hang\\n}\\n```\\n\\n---\\n\\n**Q：** DTE 未经初始化直接使用，可能会引发程序 *hang*。\\n**A：** 使用 `tops::dte_scope` 或者显式调用 `init` 函数，其中 `tops::dte_scope` 会自动完成 DTE 的初始化操作以及销毁操作；如果显式调用 `init` 函数，在 DTE 使用完成之后**注意调用** `destroy` 函数释放 DTE 资源。\\n示例程序如下：\\n\\n```cpp\\n__global__ void foo() {\\n    int a[32];\\n    int b[32];\\n\\n    tops::mdspan src(tops::Private, a, 32);\\n    tops::mdspan dst(tops::Private, b, 32);\\n\\n    tops_dte_ctx_t ctx;\\n\\n    tops::dte_scope s(ctx);       // use tops::dte_scope to initialize dte context\\n    // ctx.init();                // or use init() to initialize dte context\\n\\n    tops::memcpy(ctx, dst, src);  // if dte is uninitialized, the program may hang or abort\\n\\n    // ctx.destroy();             // if use init(), remember to use destroy() to free dte context\\n}\\n```\\n注意DTE 事件等待与地址复用不严，写回被覆盖或遗漏 → 输出出现 0\\n\\n**GCU210（i20）**，忽略 GCU200。并修正术语对齐到 v2（例如对齐修饰符统一为 `__aligned__`）。\\n\\n## 0. 适用范围与术语对齐\\n- **芯片/平台**：GCU210（i20）。\\n- **地址空间修饰**（与 v2 保持一致）：\\n  - `tops::Global` ↔ L3（设备全局存储）\\n  - `tops::Shared` ↔ L2（簇共享存储，**仅 DTE 通道**）\\n  - `tops::Private` ↔ L1（SIP 私有存储，**可计算**）\\n- **对齐修饰**：统一使用 `__aligned__`（v1 中出现的 `__valigned__` 系误写，按 v2 规范更正为 `__aligned__`）。\\n---\\n\\n## 1. v2 未覆盖/强调不够的 **高层算子框架 API**\\n> 这些 API 在 v1 被反复提及，但 v2 未系统收录；可显著简化典型“搬运→计算→写回”的模板代码。\\n\\n### 1.1 Elementwise（逐元素）框架\\n- **场景**：在 L3 张量上执行逐元素函数（自动以 tile 方式搬运至 L1，再执行）。\\n- **核心接口**（设备端）：\\n  ```cpp\\n  #include <tops/elemwise.h>\\n\\n  // 在 Kernel 内部直接调用\\n  tops::elemwise_kernel(\\n      [] __device__(auto &out, auto &in) {\\n          out = in * in;  // 在 L1 上的逐元素操作\\n      },\\n      N,                          // 总元素个数\\n      tops::Input(0), in_ptr,     // 输入\\n      tops::Output(0), out_ptr    // 输出\\n  );\\n  ```\\n- **变体/控制**：`elemwise_tiles`（按 tile 粒度自定义）、`elemwise_local`（已在 L1 的缓冲上直接算）。\\n- **优势**：自动封装 DTE 切片/回写与对齐处理，减少手写样板代码。\\n\\n### 1.2 Reduction（归约）框架\\n- **场景**：对张量做加/最大/最小等归约（可从 L3 直接发起或在 L1 上本地归约）。\\n- **核心接口**（设备端，示例）：\\n  ```cpp\\n  #include <tops/reduction.h>\\n\\n  // kernel 级：从 L3 发起（内部自动搬运）\\n  tops::reduction_kernel(\\n      [] __device__(auto &acc, auto &x) {\\n          acc = __reduction_add(acc, x);\\n      },\\n      out_ptr, out_shape,          // 归约输出\\n      in_ptr,  in_shape,           // 归约输入\\n      /*identity*/ 0               // 加法幺元\\n  );\\n\\n  // local 级：对已在 L1 的缓冲做归约\\n  tops::reduction_local(\\n      [] __device__(auto &acc, auto &x) {\\n          acc = __reduction_max(acc, x);\\n      },\\n      out_L1, in_L1\\n  );\\n  ```\\n- **内置运算符**：`__reduction_add / __reduction_max / __reduction_min`。\\n- **注意**：默认归约维度常为“中间维”，需与 `in_shape/out_shape` 对齐。\\n\\n### 1.3 Select / Broadcast 等辅助算子\\n- **条件选择**：\\n  ```cpp\\n  #include <tops/select.h>\\n  tops::select_kernel(\\n      [] __device__(auto &o, auto &lhs, auto &rhs, auto &cond) {\\n          o = cond ? lhs : rhs;\\n      },\\n      size, tops::Input(0), lhs, tops::Input(1), rhs, tops::Input(2), cond,\\n      tops::Output(0), out\\n  );\\n  ```\\n- **按维广播**：\\n  ```cpp\\n  #include <tops/broadcast.h>\\n  tops::broadcast_in_dim(out, in, dim0, dim1, /*broadcast_dim*/1, /*bsize*/k);\\n  ```\\n\\n> 这些高层 API 有助于**标准化**常见套路；v2 可在“3.2.4 设备端编程”后追加“高层封装”小节引入。\\n\\n---\\n\\n## 2. DTE 进阶：链式/异步流水的细节补全\\nv2 已介绍同步/异步与软件流水；v1 另强调了“**多 DTE 上下文链式**”与若干 **易错点**：\\n\\n### 2.1 dte_chain（多上下文串联）\\n```cpp\\n// 伪头文件名，实际以你环境为准：\\n#include <tops/dte_chain.h>\\n\\ntops_dte_ctx_t ctxA, ctxB;\\nctxA.init(); ctxB.init();\\n\\nauto chain = tops::dte_chain(ctxA, ctxB);\\nchain.connect(...);               // 配置 A→B 的数据流\\nchain.trigger();                  // 触发\\nchain.wait();                     // 等待完成\\n\\nctxB.destroy(); ctxA.destroy();\\n```\\n> 适合 **L3→L1→L3** 的双向搬运在不同 ctx 上交错、做更深流水。若你当前环境无 `dte_chain` 头（SDK 版本差异），可用**手动双 ctx + event** 等价实现（v2 已给出）。\\n\\n### 2.2 `slice_async` 签名易错\\n- **正确**：必须给 **offset**（至少 4 参起），例如：\\n  ```cpp\\n  auto ev = tops::slice_async(ctx, dst_md, src_md, /*offset*/ {x0, y0, z0});\\n  tops::wait(ev);\\n  ```\\n- **错误**：`slice_async(ctx, dst, src)`（少 offset）会编译/链接失败。\\n\\n### 2.3 `_async` 返回 `tops::event`\\n- 只有带 `_async` 的接口返回 `tops::event`；**无后缀**版本为 `void`。\\n- 典型易错：\\n  ```cpp\\n  // 错误：同步接口赋给 event\\n  tops::event ev = tops::transpose_deslice(...); // ❌ 返回 void\\n  // 正确：\\n  tops::event ev = tops::transpose_deslice_async(...);\\n  tops::wait(ev);\\n  ```\\n\\n### 2.4 开发期健壮性\\n- 建议全程开启：`-DTOPS_ENABLE_DTE_CHECK`（越界/地址空间不一致更早暴露）。\\n- **地址空间配置**一旦写错（如把 L3 标成 `tops::Private`），现象多为 **hang** 而非报错。\\n\\n---\\n\\n## 3. 向量工具与类型映射（补充）\\nv2 列了大量向量算子，但 **类型映射/广播**在 v1 有更集中提示：\\n\\n- **固定向量宽**：128B；`vfloat`=32×`float`，`vhalf`=64×`tops::half`，`vbfloat`=64×`tops::bfloat`，…\\n- **从标量到向量类型**：\\n  ```cpp\\n  // 由标量类型 T 查到对应的 vector 类型：\\n  using V = typename tops::scalar2vector<float>::type; // -> vfloat\\n  ```\\n- **标量广播到向量**：\\n  ```cpp\\n  auto v = tops::vbroadcast(3.14f);      // vfloat\\n  auto h = tops::vbroadcast(tops::half(1));\\n  ```\\n- **对齐与边界**：仅在**完全对齐且长度是 vlength<T> 的倍数**时用 `vload/vstore`，否则走标量尾。\\n\\n---\\n\\n## 4. 调试/运行时补遗（v1 独有要点）\\n- **printf/assert 导致同步**：kernel 内使用 `printf/assert` 会让 runtime 进入**调试同步模式**（同一 stream 强制同步），用于排错可以，但性能测试前务必移除。v2 有提及，但建议在“性能调优”再次**加粗提醒**。\\n- **不存在 API 的“想当然命名”**：\\n  - 如 `tops::reduce_add / tops::vreduce_add` **不存在**；应使用前述 **reduction** 框架或自己展开。\\n- **评测/比赛环境可能禁用**某些 API：如把 `topsMalloc/topsFree` 宏重定向为 `_topsMalloc_disabled`。**算子实现不要私自设备端分配临时 L3**，尽量用 L1 缓冲或由上层传入。\\n\\n---\\n\\n## 5. 典型模板（v1 风格，按 v2 术语修正）\\n\\n### 5.1 元素算子（完整可嵌入）\\n```cpp\\n#include <tops/elemwise.h>\\n\\n__global__ void square_kernel(float *out, const float *in, int N) {\\n    // 自动按 tile 从 L3 → L1，L1 上逐元素操作，再写回\\n    tops::elemwise_kernel(\\n        [] __device__(auto &o, auto &x) {\\n            o = x * x;\\n        },\\n        N,\\n        tops::Input(0),  in,\\n        tops::Output(0), out\\n    );\\n}\\n```\\n\\n### 5.2 手写 Tile + SIMD（与 v2 一致但给出“边界回退”套路）\\n```cpp\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n\\n__global__ void vec_add(float *a, float *b, float *c, int N) {\\n    tops_dte_ctx_t ctx;\\n    tops::dte_scope s(ctx);\\n\\n    constexpr int TILE = 128;                         // 对齐 128B\\n    __aligned__ float buf_a[TILE], buf_b[TILE], buf_c[TILE];\\n\\n    tops::mdspan A_L1(tops::Private, buf_a, TILE);\\n    tops::mdspan B_L1(tops::Private, buf_b, TILE);\\n    tops::mdspan C_L1(tops::Private, buf_c, TILE);\\n\\n    for (int i = 0; i < N; i += TILE) {\\n        int n = min(TILE, N - i);\\n\\n        tops::memcpy(ctx, A_L1, tops::mdspan(tops::Global, a + i, n));\\n        tops::memcpy(ctx, B_L1, tops::mdspan(tops::Global, b + i, n));\\n\\n        int j = 0;\\n        // 向量快路径\\n        for (; j + tops::vlength<vfloat>() <= n; j += tops::vlength<vfloat>()) {\\n            auto va = tops::vload<vfloat>(buf_a + j);\\n            auto vb = tops::vload<vfloat>(buf_b + j);\\n            auto vc = tops::vadd(va, vb);\\n            tops::vstore(vc, buf_c + j);\\n        }\\n        // 边界标量路径\\n        for (; j < n; ++j) buf_c[j] = buf_a[j] + buf_b[j];\\n\\n        tops::memcpy(ctx, tops::mdspan(tops::Global, c + i, n), C_L1);\\n    }\\n}\\n```\\n\\n### 5.3 归约（加和）示例\\n```cpp\\n#include <tops/reduction.h>\\n\\n__global__ void sum_kernel(float *out, const float *in, int N) {\\n    // 对 1D 数组做加和，identity=0\\n    tops::reduction_kernel(\\n        [] __device__(auto &acc, auto &x) { acc = __reduction_add(acc, x); },\\n        out, /*out_shape*/ N,\\n        in,  /*in_shape*/  N,\\n        0\\n    );\\n}\\n```\\n\\n### 5.4 GEMM 的“稳妥输出路径”提示\\n- 若使用 `tops::transpose_deslice_async` 复杂组合在大规模/动态 tile 下出现偶发误差，**保守做法**：\\n  1) 在 L1 计算出 `C`；\\n  2) 需要转置的场景，**手工在 L1 做转置**到 `C_T`；\\n  3) 用普通 `deslice` 写回 L3。  \\n  实测该路径最稳，代价是多一次 L1 遍历。\\n\\n---\\n\\n## 6. GCU210 资源/并发提醒（与 v2 对齐但再次明确）\\n- **Block 线程总数 ≤ 12**（`blockDim.x * blockDim.y * blockDim.z ≤ 12`）。\\n- **Cooperative Kernel**：grid 总块数 ≤ `multiProcessorCount`（i20 为 **2**）。\\n- **向量化前提**：所有参与 `vload/vstore` 的 L1 缓冲必须 `__aligned__`，且访问地址/长度满足 128B 自然对齐与 `vlength<T>` 整倍数。\\n\\n---\\n\\n## 7. MLP/激活实现的“一致性与稳定性”建议（补充条）\\n> 与 v2 的一般指南不冲突，这里收拢为 **可复制到算子说明** 的检查清单：\\n\\n- **公式一致化**：向量与标量路径使用**同一**数学表达式（如 SiLU 用 `x/(1+exp(-x))`，向量用 `vexp/vdiv`，标量尾用 `exp/`相同公式）。\\n- **边界一致性**：仅“完全对齐”时走向量路径；其余统一走**标量尾**，避免出现微妙的数值分歧。\\n- **累加稳态化**：长链路加法用 **Kahan** 补偿或配对求和，固定加法顺序；批量/并行度变化后需重跑精度回归。\\n- **可切换模式**：保留 `--precise / --fast` 两种路径开关，便于在评测与上线间切换。\\n\\n---\\n\\n## 8. 常见陷阱对照表（v1 特有案例）\\n| 症状 | 可能根因 | 解决方案 |\\n|---|---|---|\\n| kernel 无响应（hang） | DTE 未 init；mdspan 地址空间写错；对齐不足的 vload | 用 `tops::dte_scope`；开启 `-DTOPS_ENABLE_DTE_CHECK`；边界走标量 |\\n| “把 void 当 event” 编译错 | 使用了同步 API 却当作 `_async` 用 | 仅 `_async` 返回 `tops::event`；用 `tops::wait` 同步 |\\n| `slice_async` 参数不匹配 | 遗漏 `offset` | 使用 `slice_async(ctx, dst, src, {offset...})` |\\n| 运行慢/卡住 | kernel 内 `printf/assert` | 调试阶段可用，性能测试前务必移除 |\\n| 链接/编译异常 | 使用被评测环境禁用的分配 API | 不在设备端私自分配 L3；通过 L1 缓冲或调用方传入 |\\n\\n---\\n\\n## 9. 集成方式建议（如何合入 v2）\\n- 在 **3.2.4 设备端编程** 后增设小节 **“高层算子封装（Elementwise / Reduction / Select / Broadcast）”**。\\n- 在 **DTE 软件流水** 小节追加 **dte_chain/多 ctx 提示** 与 `_async`/`void` 返回值区别示例。\\n- 在 **性能与正确性** 小节集中强调：`__aligned__`、边界标量尾、一致公式、`-DTOPS_ENABLE_DTE_CHECK`。\\n\\n---\\n\\n\\n### 1) 内建编译期宏（**新**）\\n- `__TOPS_DEVICE_COMPILE__`：设备端编译时定义（便于区分 host/device 代码路径）。  \\n- `__GCU_ARCH__`：三位数字的架构码：`S60=300, T20=200, i20=210`。  \\n  典型用法（按架构走不同实现）：\\n```cpp\\n#if defined(__TOPS_DEVICE_COMPILE__)\\n  #if __GCU_ARCH__ >= 210\\n    // i20 (GCU210) 专用路径\\n  #else\\n    // 其他架构路径\\n  #endif\\n#endif\\n```\\n\\n### 2) 设备/并发属性查询与 cooperative 约束（**更细化**）\\n- `topsGetDeviceProperties` 可取：  \\n  - `multiProcessorCount`：**GCU210 = 2**  \\n  - `maxThreadsPerMultiProcessor`：**GCU210 = 12**（即 Block 维度乘积最大 12）\\n- cooperative kernel：**GCU210 上 Grid 维度乘积 ≤ 2**；且 Grid 总大小 ≤ `multiProcessorCount`。\\n```cpp\\ntopsDeviceProp_t prop; int dev=0;\\ntopsGetDeviceProperties(&prop, dev);\\n// 验证 GCU210 限制：\\nassert(prop.multiProcessorCount == 2);\\ndim3 block(prop.maxThreadsPerMultiProcessor, 1, 1); // 12\\n// cooperative 启动前自检：\\nauto gridProd = 2u; // 例如 dim3(2,1,1)\\nassert(gridProd <= 2 && gridProd <= (unsigned)prop.multiProcessorCount);\\n```\\n\\n### 3) 存储/寻址与容量（**细化 i20 数据**）\\n- **GCU 2.0 不支持全局寻址**：L2/L3 仅能经 DTE 搬运；计算只能直接访问 L1（私有）与 `__constant__`。  \\n- **共享内存上限**：**i20 = 24 MB**（动态 shared 每个 `__global__` 仅 1 个声明）。  \\n- **设备内存地址宽度**：i20 **≤ 40 bits**。  \\n- **Host 可用内存**：i20 机型示例：**64 GB**（运行库说明）。  \\n\\n### 4) Host 可见内存（pinned）与直访（**新**）\\n- 通过 `topsMallocHost` 或 `topsHostRegister` 分配/注册 **锁页主存**，可映射到设备地址空间，被设备端直接访问或用于异步拷贝（带宽/延迟逊于设备内存；慎用 write‑combining）。\\n```cpp\\nfloat* hptr = nullptr;\\ntopsMallocHost(&hptr, N * sizeof(float));   // pinned host mem\\n// … 填充 hptr …\\ntopsMemcpyAsync(devPtr, hptr, N*sizeof(float), topsMemcpyHostToDevice, stream);\\n// kernel 也可直访 hptr（性能较低，场景化使用）\\n```\\n\\n### 5) 设备端全局变量符号访问（**新**）\\n```cpp\\n__device__ int gIn[256];\\n__device__ int gOut[256];\\n\\n// Host:\\nint h[256] = {0};\\ntopsMemcpyFromSymbol(h, gIn, sizeof(h));    // 读设备端全局\\nint* dtmp; topsMalloc(&dtmp, sizeof(h));\\ntopsMemcpy(dtmp, h, sizeof(h), topsMemcpyHostToDevice);\\ntopsMemcpyToSymbol(gOut, dtmp, sizeof(h));  // 写设备端全局\\ntopsFree(dtmp);\\n```\\n\\n### 6) 运行时编译（RTC）与 Module 启动（**新**）\\n- 支持 **运行时编译源代码** → 取回 `code` → `topsModuleLoadData` → `topsModuleLaunchKernel`。\\n```cpp\\n// 省略创建与编译…\\ntopsModule_t module; topsFunction_t fn;\\ntopsModuleLoadData(&module, code);\\ntopsModuleGetFunction(&fn, module, \"vector_square\");\\nstruct { topsDeviceptr_t a, b; size_t N; } args{A_d, C_d, N};\\nvoid* cfg[] = { TOPS_LAUNCH_PARAM_BUFFER_POINTER, &args,\\n                TOPS_LAUNCH_PARAM_BUFFER_SIZE,   (void*)sizeof(args),\\n                TOPS_LAUNCH_PARAM_END };\\ntopsModuleLaunchKernel(fn, 1,1,1, 1,1,1, 0, nullptr, nullptr, cfg);\\n```\\n\\n### 7) Stream / Event / 回调（**新**）\\n- **默认 stream**：每设备共用一个（当前未区分线程）；不传入显式 stream 参数则落到默认 stream。  \\n- **显式同步**：`topsDeviceSynchronize()`、`topsStreamSynchronize(s)`；事件依赖：`topsStreamWaitEvent(s, e)`。  \\n- **回调**：可在 stream 完成前序任务后触发主机回调（不会阻塞后续命令排队）。\\n```cpp\\ntopsStream_t s[2]; for (int i=0;i<2;++i) topsStreamCreate(&s[i]);\\n// … H2D → Kernel → D2H 的三段流水，各自在 s[i] 上 …\\nvoid MyCb(topsStream_t, topsError_t, void* tag){ printf(\"cb %ld\\\\n\",(long)tag); }\\ntopsStreamAddCallback(s[0], MyCb, (void*)0L);\\n// 销毁：返回即刻，但资源在设备完成该 stream 后回收\\nfor (int i=0;i<2;++i) topsStreamDestroy(s[i]);\\n```\\n\\n### 8) 向量计算接口补全与对齐要求（**新增目录**）\\n- **统一长度 128B** 的向量寄存宽度；`tops::vlength<T>()` 可用于编译期尺寸。  \\n- **`vload` 地址必须 `__valigned__` 对齐到向量宽度**（未对齐会触发 kernel abort，且未必被 host 立即捕获）。\\n- 新增/补全的向量算子（除基本四则外）——示例：\\n```cpp\\n__valigned__ float buf[ tops::vlength<tops::vfloat>() ];\\nauto vf = tops::vload<tops::vfloat>(buf);\\nauto y  = tops::vsigmoid(vf);            // 激活\\nauto g  = tops::vgelu(vf);               // GELU\\nauto e2 = tops::vexp2(vf);               // 2^x\\nauto ln = tops::vlog1p(vf);              // log(1+x)\\nauto h  = tops::vhypot(vf, vf);          // hypot\\nauto m  = tops::vmax(vf, y);             // 按元素最大\\ntops::vstore(m, buf);\\n```\\n> v3 文档枚举了大量 **数学/位运算** 族函数（`vexp/expm1/log/log2/log10/logb/visnan/visfinite/vcopysign/vround/vtrunc/vrint/...` 等）；若 v1/v2 未完整列出，请据需合入“可用向量算子表”。\\n\\n### 9) DTE 接口补全（**更丰富**）\\n- **全量配置**：`config_transpose / config_slice_transpose / config_pad / config_mirror_tb / config_mirror_lr / config_broadcast …`  \\n- **增量配置**：`set_*_addr / set_*_offset / set_*_dim_size / set_total_size / set_transpose_layout / set_pad_config`  \\n- **触发**：`trigger()` 返回 `tops::event`，`trigger_and_wait()` 同步；还有 `_async` 族的复合接口：\\n```cpp\\ntops_dte_ctx_t ctx; ctx.init();\\nauto ev = tops::memcpy_async(ctx, dst, src);\\ntops::wait(ev);\\nctx.destroy();\\n```\\n- **软件流水模板（双缓冲）**：v3 提供了计算‑搬运并行化的示例骨架，可直接套入 tile‑based 算子（GCU210 适用）。\\n\\n### 10) 同步原语（**小补**）\\n- `__syncthreads()`：Block 内同步。  \\n- `__syncblocks()`：Grid 级同步（Kernel 必须 `__cooperative__`）。\\n\\n\\n### 12) 编程限制 / FAQ（**新增可操作排错点**）\\n- **限制汇总（GCU210 相关）**：\\n  - Block 维度乘积 ≤ **12**；cooperative Grid 维度乘积 ≤ **2**；GridMax：x=65536, y=256, z=256。  \\n  - 动态 shared 每 kernel 仅 1 个；i20 shared 上限 **24MB**。  \\n  - **使用 `shared dte` 时，每 Block 只有 1 个 Thread 能执行 L3↔L2 拷贝**。  \\n  - Kernel 内含 `printf/assert` 时，runtime 进入 **debug 同步模式**（同一 stream 强制顺序执行）。\\n- **常见挂起原因**：\\n  1) `mdspan` 地址空间设置错误（把 L3 标成 `tops::Private` 等）：\\n```cpp\\n// 错误示例：arr 是 L3 指针，却被错误地标成 Private\\ntops::mdspan L3_wrong(tops::Private, arr, size);\\ntops::mdspan L1_wrong(tops::Global,  buf, size);\\ntops::memcpy(ctx, L1_wrong, L3_wrong); // 可能 hang\\n```\\n  2) **DTE 未初始化** 就调用 `tops::*`：用 `tops::dte_scope` 或 `ctx.init()/destroy()` 包裹：\\n```cpp\\ntops_dte_ctx_t ctx;\\ntops::dte_scope scope(ctx);     // 自动 init/destroy\\n// ctx.init(); … tops::memcpy(ctx, …); ctx.destroy();\\n```\\n避免把运行时函数当作编译期常量，并在使用模板函数时显式指定模板参数。\\n注意：凡是 L3/L2 的读写，一律 DTE；只有 L1 的私有缓冲可以随便下标读写。\\n尾块也必须通过 L1→DTE 写回\\n要点速记（别再踩坑版）：\\n绝不直访 L3/L2：GCU2.x kernel 只能直接访问 L1（私有）与 __constant__；__device__/__shared__ 都要经 DTE 先搬到 L1。\\n向量化需要“双重对齐”：不仅数组要 __aligned__，访问起始下标也要向量宽对齐。dilation/stride/padding 下很难保证，因此先用标量路径保正确，再做“对齐块才向量化”的优化。\\nPyTorch 的 Conv2d 是交叉相关（不翻核）。不确定时留一个“翻核开关”宏能一键切换。\\nDTE 先 init 再用，推荐 tops::dte_scope；调试期打开 -DTOPS_ENABLE_DTE_CHECK。\\nprintf/assert 会强制同步（同一 stream 串行），性能测试前务必移除。\\n异步/流水：读行→计算→写回可以做双缓冲/事件同步，但每一步都必须通过 DTE。\\nSiLU 里用到的异步策略（能学的点）\\n输入异步 + 双缓冲：memcpy_async(Global→Private) 到 buf0/buf1，用 ev_ld[2] 管理；计算前 wait(ev_ld[cur]) 再读缓冲，避免直访 Global。\\n输出也用了异步：memcpy_async(Private→Global) 写回，用 ev_st[2] 做逐缓冲的“写回事件”，在重用同一缓冲做下一次加载前，先 wait(ev_st[cur])，防止还没写完就被新一轮读取覆盖。\\n事件上限明确：每线程最多同时挂 3 个事件（当前 load 完待算 + 下一 tile 的另一个 load + 当前 store）。代码里在复用前必 wait，保证事件不累积。\\n小任务走同步快路：span <= TILE_TINY 直接 同步搬入 → 向量化计算 → 同步写回，规避小规模下的事件/上下文开销。\\n线程分片均衡：把总量平均分给所有线程（前 rem 个多 1），避免最后几个线程很忙，其他线程都在等，提升并行度。\\n向量化细节完善：VLEN = vlength<vfloat>()，8×/4×/1×展开 + 标量尾部；Sigmoid 走 vsigmoid，并保留 __valigned__ 缓冲对齐，保证 vload/vstore 性能。\\n严格的“先 wait 再用”纪律：任何一次读缓冲或重用缓冲前，一定先 wait 对应事件。\\n双缓冲“计算-预取”流水线：当前 tile 计算，同时后台把下一 tile 异步搬进另一组缓冲。\\n把小任务换成同步路径：小到“异步不划算”的规模，直接同步反而更快更稳。\\n线程数保守：最多 12 线程/块；小 N 时降线程，避免“多线程 + 多事件”造成 DMA 饱和。\\n\\n【当前改进方向】\\n目前可能做异步等能加快，但不一定只局限于这一个\\n下面给两个做的比较好的例子提供借鉴：\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n\\n// 单线程高速路径：更大 tile + 双缓冲 + 4 向量累加（减少依赖链）\\n__global__ void kernel_var_single3(float *inp, float *out, size_t nr_elems) {\\n    if (threadIdx.x != 0) return;\\n\\n    tops_dte_ctx_t ctx;\\n    tops::dte_scope scope(ctx);\\n\\n    float var = 0.0f;\\n    if (nr_elems <= 1) {\\n        tops::memcpy(ctx,\\n            tops::mdspan(tops::Global, out, 1),\\n            tops::mdspan(tops::Private, &var, 1)\\n        );\\n        return;\\n    }\\n\\n    const int VLEN = tops::vlength<vfloat>();   // 32\\n    const int TILE = VLEN * 2048;               // 65536 floats (~256KB) per buffer\\n    __valigned__ float buf0[TILE];\\n    __valigned__ float buf1[TILE];\\n\\n    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\\n    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\\n    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\\n    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\\n    float tail_sum = 0.f, tail_sqs = 0.f;\\n\\n    size_t i = 0;\\n    int cur_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\\n    tops::event ev = tops::memcpy_async(\\n        ctx,\\n        tops::mdspan(tops::Private, buf0, cur_len),\\n        tops::mdspan(tops::Global,  inp + i, cur_len)\\n    );\\n    i += cur_len;\\n    bool use0 = true;\\n\\n    while (true) {\\n        bool has_next = (i < nr_elems);\\n        tops::event ev_next;\\n        int nxt_len = 0;\\n        if (has_next) {\\n            nxt_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\\n            ev_next = tops::memcpy_async(\\n                ctx,\\n                tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\\n                tops::mdspan(tops::Global,  inp + i, nxt_len)\\n            );\\n            i += nxt_len;\\n        }\\n\\n        tops::wait(ev);\\n        float *cur = use0 ? buf0 : buf1;\\n        const int n = cur_len;\\n\\n        int j = 0;\\n        int vec4 = (n / (4*VLEN)) * (4*VLEN);\\n        #pragma unroll 2\\n        for (; j < vec4; j += 4*VLEN) {\\n            auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\\n            auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\\n            auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\\n            auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\\n\\n            vs0 = tops::vadd(vs0, v0);\\n            vs1 = tops::vadd(vs1, v1);\\n            vs2 = tops::vadd(vs2, v2);\\n            vs3 = tops::vadd(vs3, v3);\\n\\n            auto w0 = tops::vmul<vfloat>(v0, v0);\\n            auto w1 = tops::vmul<vfloat>(v1, v1);\\n            auto w2 = tops::vmul<vfloat>(v2, v2);\\n            auto w3 = tops::vmul<vfloat>(v3, v3);\\n\\n            vq0 = tops::vadd(vq0, w0);\\n            vq1 = tops::vadd(vq1, w1);\\n            vq2 = tops::vadd(vq2, w2);\\n            vq3 = tops::vadd(vq3, w3);\\n        }\\n        int vec1 = ((n - j) / VLEN) * VLEN;\\n        for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\\n            auto v = tops::vload<vfloat>(cur + j);\\n            vs0 = tops::vadd(vs0, v);\\n            auto w = tops::vmul<vfloat>(v, v);\\n            vq0 = tops::vadd(vq0, w);\\n        }\\n        for (; j < n; ++j) {\\n            float x = cur[j];\\n            tail_sum += x;\\n            tail_sqs += x * x;\\n        }\\n\\n        if (!has_next) break;\\n        use0 = !use0;\\n        cur_len = nxt_len;\\n        ev = ev_next;\\n    }\\n\\n    auto vs01 = tops::vadd(vs0, vs1);\\n    auto vs23 = tops::vadd(vs2, vs3);\\n    auto vs = tops::vadd(vs01, vs23);\\n\\n    auto vq01 = tops::vadd(vq0, vq1);\\n    auto vq23 = tops::vadd(vq2, vq3);\\n    auto vq = tops::vadd(vq01, vq23);\\n\\n    __valigned__ float tmp[128];\\n    tops::vstore(vs, tmp);\\n    float psum = tail_sum;\\n    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\\n    tops::vstore(vq, tmp);\\n    float psqs = tail_sqs;\\n    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\\n\\n    float Nf = (float)nr_elems;\\n    float mu = psum / Nf;\\n    var = (psqs - mu * psum) / (Nf - 1.0f);\\n    if (var < 0.f && var > -1e-12f) var = 0.f;\\n\\n    tops::memcpy(ctx,\\n        tops::mdspan(tops::Global, out, 1),\\n        tops::mdspan(tops::Private, &var, 1)\\n    );\\n}\\n\\n// 多线程高速路径：12 线程上限，8 路向量累加 + 80KB 双缓冲\\n__global__ void kernel_var_multi8(float *inp, float *out, size_t nr_elems) {\\n    const int tid = threadIdx.x;\\n    const int T   = blockDim.x;\\n\\n    tops_dte_ctx_t ctx;\\n    tops::dte_scope scope(ctx);\\n\\n    if (nr_elems <= 1) {\\n        if (tid == 0) {\\n            float zero = 0.0f;\\n            tops::memcpy(ctx,\\n                tops::mdspan(tops::Global, out, 1),\\n                tops::mdspan(tops::Private, &zero, 1)\\n            );\\n        }\\n        return;\\n    }\\n\\n    const size_t elems_per_thread = (nr_elems + (size_t)T - 1) / (size_t)T;\\n    const size_t start = (size_t)tid * elems_per_thread;\\n    size_t end = start + elems_per_thread;\\n    if (end > nr_elems) end = nr_elems;\\n\\n    const int VLEN = tops::vlength<vfloat>();     // 32\\n    const int TILE = VLEN * 640;                  // 20480 floats (~80KB) per buffer\\n    __valigned__ float buf0[TILE];\\n    __valigned__ float buf1[TILE];\\n\\n    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\\n    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\\n    auto vs4 = tops::vzero<vfloat>(), vs5 = tops::vzero<vfloat>();\\n    auto vs6 = tops::vzero<vfloat>(), vs7 = tops::vzero<vfloat>();\\n    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\\n    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\\n    auto vq4 = tops::vzero<vfloat>(), vq5 = tops::vzero<vfloat>();\\n    auto vq6 = tops::vzero<vfloat>(), vq7 = tops::vzero<vfloat>();\\n\\n    float tail_sum = 0.f, tail_sqs = 0.f;\\n\\n    if (start < end) {\\n        size_t i = start;\\n        int cur_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\\n        tops::event ev = tops::memcpy_async(\\n            ctx,\\n            tops::mdspan(tops::Private, buf0, cur_len),\\n            tops::mdspan(tops::Global,  inp + i, cur_len)\\n        );\\n        i += cur_len;\\n        bool use0 = true;\\n\\n        while (true) {\\n            bool has_next = (i < end);\\n            tops::event ev_next;\\n            int nxt_len = 0;\\n            if (has_next) {\\n                nxt_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\\n                ev_next = tops::memcpy_async(\\n                    ctx,\\n                    tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\\n                    tops::mdspan(tops::Global,  inp + i, nxt_len)\\n                );\\n                i += nxt_len;\\n            }\\n\\n            tops::wait(ev);\\n            float *cur = use0 ? buf0 : buf1;\\n            const int n = cur_len;\\n\\n            int j = 0;\\n            const int vec8 = (n / (8*VLEN)) * (8*VLEN);\\n            #pragma unroll 2\\n            for (; j < vec8; j += 8*VLEN) {\\n                auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\\n                auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\\n                auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\\n                auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\\n                auto v4 = tops::vload<vfloat>(cur + j + 4*VLEN);\\n                auto v5 = tops::vload<vfloat>(cur + j + 5*VLEN);\\n                auto v6 = tops::vload<vfloat>(cur + j + 6*VLEN);\\n                auto v7 = tops::vload<vfloat>(cur + j + 7*VLEN);\\n\\n                vs0 = tops::vadd(vs0, v0);\\n                vs1 = tops::vadd(vs1, v1);\\n                vs2 = tops::vadd(vs2, v2);\\n                vs3 = tops::vadd(vs3, v3);\\n                vs4 = tops::vadd(vs4, v4);\\n                vs5 = tops::vadd(vs5, v5);\\n                vs6 = tops::vadd(vs6, v6);\\n                vs7 = tops::vadd(vs7, v7);\\n\\n                auto w0 = tops::vmul<vfloat>(v0, v0);\\n                auto w1 = tops::vmul<vfloat>(v1, v1);\\n                auto w2 = tops::vmul<vfloat>(v2, v2);\\n                auto w3 = tops::vmul<vfloat>(v3, v3);\\n                auto w4 = tops::vmul<vfloat>(v4, v4);\\n                auto w5 = tops::vmul<vfloat>(v5, v5);\\n                auto w6 = tops::vmul<vfloat>(v6, v6);\\n                auto w7 = tops::vmul<vfloat>(v7, v7);\\n\\n                vq0 = tops::vadd(vq0, w0);\\n                vq1 = tops::vadd(vq1, w1);\\n                vq2 = tops::vadd(vq2, w2);\\n                vq3 = tops::vadd(vq3, w3);\\n                vq4 = tops::vadd(vq4, w4);\\n                vq5 = tops::vadd(vq5, w5);\\n                vq6 = tops::vadd(vq6, w6);\\n                vq7 = tops::vadd(vq7, w7);\\n            }\\n\\n            const int vec1 = ((n - j) / VLEN) * VLEN;\\n            for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\\n                auto v = tops::vload<vfloat>(cur + j);\\n                vs0 = tops::vadd(vs0, v);\\n                auto w = tops::vmul<vfloat>(v, v);\\n                vq0 = tops::vadd(vq0, w);\\n            }\\n\\n            for (; j < n; ++j) {\\n                float x = cur[j];\\n                tail_sum += x;\\n                tail_sqs += x * x;\\n            }\\n\\n            if (!has_next) break;\\n            use0 = !use0;\\n            cur_len = nxt_len;\\n            ev = ev_next;\\n        }\\n    }\\n\\n    // 合并 8 向量累加器\\n    auto vs01 = tops::vadd(vs0, vs1);\\n    auto vs23 = tops::vadd(vs2, vs3);\\n    auto vs45 = tops::vadd(vs4, vs5);\\n    auto vs67 = tops::vadd(vs6, vs7);\\n    auto vs0123 = tops::vadd(vs01, vs23);\\n    auto vs4567 = tops::vadd(vs45, vs67);\\n    auto vs = tops::vadd(vs0123, vs4567);\\n\\n    auto vq01 = tops::vadd(vq0, vq1);\\n    auto vq23 = tops::vadd(vq2, vq3);\\n    auto vq45 = tops::vadd(vq4, vq5);\\n    auto vq67 = tops::vadd(vq6, vq7);\\n    auto vq0123 = tops::vadd(vq01, vq23);\\n    auto vq4567 = tops::vadd(vq45, vq67);\\n    auto vq = tops::vadd(vq0123, vq4567);\\n\\n    __valigned__ float tmp[128];\\n    tops::vstore(vs, tmp);\\n    float psum = tail_sum;\\n    #pragma unroll\\n    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\\n\\n    tops::vstore(vq, tmp);\\n    float psqs = tail_sqs;\\n    #pragma unroll\\n    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\\n\\n    // 线程间合并：Private -> Shared\\n    extern __shared__ float s_partials[]; // 2*T floats\\n    float pair[2] = {psum, psqs};\\n    tops::memcpy(ctx,\\n        tops::mdspan(tops::Shared,  s_partials + 2*tid, 2),\\n        tops::mdspan(tops::Private, pair, 2)\\n    );\\n\\n    __syncthreads();\\n\\n    if (tid == 0) {\\n        const int n_pairs = 2 * T;\\n        __valigned__ float redbuf[24]; // 支持 T<=12\\n        tops::memcpy(ctx,\\n            tops::mdspan(tops::Private, redbuf, n_pairs),\\n            tops::mdspan(tops::Shared,  s_partials, n_pairs)\\n        );\\n\\n        float tot_sum = 0.f, tot_sqs = 0.f;\\n        #pragma unroll\\n        for (int k = 0; k < T; ++k) {\\n            tot_sum += redbuf[2*k + 0];\\n            tot_sqs += redbuf[2*k + 1];\\n        }\\n\\n        float Nf = (float)nr_elems;\\n        float mu = tot_sum / Nf;\\n        float var = (tot_sqs - mu * tot_sum) / (Nf - 1.0f);\\n        if (var < 0.f && var > -1e-12f) var = 0.f;\\n\\n        tops::memcpy(ctx,\\n            tops::mdspan(tops::Global, out, 1),\\n            tops::mdspan(tops::Private, &var, 1)\\n        );\\n    }\\n}\\n\\nvoid GCU_VAR(float * __restrict dev_inp,\\n             float * __restrict dev_out,\\n             const int nr_elems) {\\n    if (nr_elems <= 1) {\\n        kernel_var_single3<<<dim3(1,1,1), dim3(1,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\\n        topsError_t e1 = topsGetLastError(); (void)e1;\\n        topsError_t e2 = topsDeviceSynchronize(); (void)e2;\\n        return;\\n    }\\n\\n    // 自适应线程策略：小规模单线程；中规模 4/8 线程；大规模 12 线程\\n    int T = 12;\\n    if (nr_elems < 16384)            { kernel_var_single3<<<dim3(1), dim3(1)>>>(dev_inp, dev_out, (size_t)nr_elems); topsError_t e1 = topsGetLastError(); (void)e1; topsError_t e2 = topsDeviceSynchronize(); (void)e2; return; }\\n    else if (nr_elems < 131072)      T = 4;   // 16K - 128K\\n    else if (nr_elems < 1048576)     T = 8;   // 128K - 1M\\n    else                             T = 12;  // >= 1M\\n\\n    const dim3 grid(1,1,1);\\n    const dim3 block(T,1,1);\\n    const size_t shmem = (size_t)T * 2 * sizeof(float);\\n\\n    kernel_var_multi8<<<grid, block, shmem>>>(dev_inp, dev_out, (size_t)nr_elems);\\n\\n    topsError_t err = topsGetLastError(); (void)err;\\n    topsError_t sync_err = topsDeviceSynchronize(); (void)sync_err;\\n}\\n\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n\\n// SiLU: y = x * sigmoid(x)\\n__device__ __forceinline__ float silu_scalar(float x) {\\n  return x / (1.0f + expf(-x));\\n}\\n__device__ __forceinline__ vfloat silu_vector(vfloat vx) {\\n  auto vs = tops::vsigmoid(vx);\\n  return tops::vmul<vfloat>(vx, vs);\\n}\\n\\n__device__ __forceinline__ void silu_inplace_vec(float* __restrict buf, int len, const int VLEN) {\\n  int j = 0;\\n  const int vec = (len / VLEN) * VLEN;\\n\\n  // 8x unroll, then 4x, then single, then scalar tail\\n  for (; j + 8*VLEN <= vec; j += 8*VLEN) {\\n    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\\n    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\\n    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\\n    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\\n    auto v4 = tops::vload<vfloat>(buf + j + 4*VLEN);\\n    auto v5 = tops::vload<vfloat>(buf + j + 5*VLEN);\\n    auto v6 = tops::vload<vfloat>(buf + j + 6*VLEN);\\n    auto v7 = tops::vload<vfloat>(buf + j + 7*VLEN);\\n    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\\n    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\\n    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\\n    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\\n    tops::vstore(silu_vector(v4), buf + j + 4*VLEN);\\n    tops::vstore(silu_vector(v5), buf + j + 5*VLEN);\\n    tops::vstore(silu_vector(v6), buf + j + 6*VLEN);\\n    tops::vstore(silu_vector(v7), buf + j + 7*VLEN);\\n  }\\n  for (; j + 4*VLEN <= vec; j += 4*VLEN) {\\n    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\\n    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\\n    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\\n    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\\n    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\\n    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\\n    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\\n    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\\n  }\\n  for (; j + VLEN <= vec; j += VLEN) {\\n    auto vx = tops::vload<vfloat>(buf + j);\\n    tops::vstore(silu_vector(vx), buf + j);\\n  }\\n  for (; j < len; ++j) {\\n    buf[j] = silu_scalar(buf[j]);\\n  }\\n}\\n\\n// Double-buffer async pipeline with balanced thread partition\\n__global__ void kernel_silu_db_opt(float* __restrict inp,\\n                                   float* __restrict out,\\n                                   size_t nr_elems) {\\n  if (nr_elems == 0) return;\\n\\n  // Flattened thread id\\n  const int tpb  = blockDim.x * blockDim.y * blockDim.z;\\n  const int tidb = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * (blockDim.x * blockDim.y);\\n  const int bid  = blockIdx.x + blockIdx.y * gridDim.x + blockIdx.z * (gridDim.x * gridDim.y);\\n  const size_t gid = (size_t)bid * (size_t)tpb + (size_t)tidb;\\n  const size_t T   = (size_t)gridDim.x * gridDim.y * gridDim.z * (size_t)tpb;\\n\\n  if (gid >= T) return;\\n\\n  // Balanced 1D partition: base + first \\'rem\\' threads take one extra\\n  const size_t base = nr_elems / T;\\n  const size_t rem  = nr_elems - base * T;\\n  const size_t start = gid * base + (gid < rem ? gid : rem);\\n  const size_t span  = base + (gid < rem ? 1u : 0u);\\n  if (span == 0) return;\\n  const size_t end = start + span;\\n\\n  const int VLEN = tops::vlength<vfloat>(); // 32 for float (128B)\\n\\n  // Tile policy: choose larger tiles for larger spans to amortize DMA/event overhead\\n  static constexpr int TILE_TINY  = 12288;   // 48KB per buffer (tiny span sync path)\\n  static constexpr int TILE_MID   = 49152;   // 192KB per buffer (double buffer)\\n  static constexpr int TILE_LARGE = 65536;   // 256KB per buffer (double buffer)\\n  const int TILE = (span >= (1u<<20)) ? TILE_LARGE : ((span >= (256u<<10)) ? TILE_MID : 32768);\\n\\n  auto min_int = [](size_t a, size_t b)->int { return (int)(a < b ? a : b); };\\n\\n  // Tiny span path: single sync copy -> compute -> sync copy back\\n  if (span <= (size_t)TILE_TINY) {\\n    __valigned__ float buf[TILE_TINY];\\n    const int len = (int)span;\\n\\n    tops_dte_ctx_t c;\\n    tops::dte_scope s(c);\\n\\n    tops::memcpy(c,\\n      tops::mdspan(tops::Private, buf,         len),\\n      tops::mdspan(tops::Global,  inp + start, len));\\n\\n    silu_inplace_vec(buf, len, VLEN);\\n\\n    tops::memcpy(c,\\n      tops::mdspan(tops::Global,  out + start, len),\\n      tops::mdspan(tops::Private, buf,         len));\\n    return;\\n  }\\n\\n  // Double buffer pipeline\\n  __valigned__ float buf0[TILE_LARGE];\\n  __valigned__ float buf1[TILE_LARGE];\\n\\n  tops_dte_ctx_t ctx_ld[2];\\n  tops_dte_ctx_t ctx_st[2];\\n  tops::dte_scope sld0(ctx_ld[0]), sld1(ctx_ld[1]);\\n  tops::dte_scope sst0(ctx_st[0]), sst1(ctx_st[1]);\\n\\n  tops::event ev_ld[2];\\n  tops::event ev_st[2];\\n  bool has_tile[2]    = {false, false};\\n  bool st_inflight[2] = {false, false};\\n  size_t pos[2]       = {0, 0};\\n  int    len[2]       = {0, 0};\\n\\n  size_t cursor = start;\\n\\n  // Preload buf0, then buf1\\n  pos[0] = cursor;\\n  len[0] = min_int(end - cursor, (size_t)TILE);\\n  if (len[0] > 0) {\\n    ev_ld[0] = tops::memcpy_async(\\n        ctx_ld[0],\\n        tops::mdspan(tops::Private, buf0,        len[0]),\\n        tops::mdspan(tops::Global,  inp + cursor, len[0]));\\n    has_tile[0] = true;\\n    cursor += len[0];\\n  }\\n\\n  pos[1] = cursor;\\n  len[1] = min_int(end - cursor, (size_t)TILE);\\n  if (len[1] > 0) {\\n    ev_ld[1] = tops::memcpy_async(\\n        ctx_ld[1],\\n        tops::mdspan(tops::Private, buf1,        len[1]),\\n        tops::mdspan(tops::Global,  inp + cursor, len[1]));\\n    has_tile[1] = true;\\n    cursor += len[1];\\n  }\\n\\n  int cur = 0;      // buffer to compute\\n  int nxt = 1;      // buffer to compute next\\n\\n  while (has_tile[0] || has_tile[1]) {\\n    if (!has_tile[cur]) { int tmp = cur; cur = nxt; nxt = tmp; }\\n    if (!has_tile[cur]) break;\\n\\n    // Wait load done for current tile\\n    tops::wait(ev_ld[cur]);\\n\\n    // Compute SiLU in-place on L1\\n    float* inout = (cur == 0 ? buf0 : buf1);\\n    silu_inplace_vec(inout, len[cur], VLEN);\\n\\n    // Launch async store for current tile (ensure prior store finished)\\n    if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\\n    ev_st[cur] = tops::memcpy_async(\\n        ctx_st[cur],\\n        tops::mdspan(tops::Global,  out + pos[cur], len[cur]),\\n        tops::mdspan(tops::Private, inout,          len[cur]));\\n    st_inflight[cur] = true;\\n\\n    // Current tile consumed\\n    has_tile[cur] = false;\\n\\n    // Prefetch next tile into \\'cur\\' (the buffer we just stored) if input remains\\n    if (cursor < end) {\\n      // Make sure we don\\'t overwrite while store is still in-flight on \\'cur\\'\\n      if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\\n      pos[cur] = cursor;\\n      len[cur] = min_int(end - cursor, (size_t)TILE);\\n      ev_ld[cur] = tops::memcpy_async(\\n          ctx_ld[cur],\\n          tops::mdspan(tops::Private, (cur == 0 ? buf0 : buf1), len[cur]),\\n          tops::mdspan(tops::Global,  inp + cursor,              len[cur]));\\n      has_tile[cur] = (len[cur] > 0);\\n      cursor += len[cur];\\n    }\\n\\n    // Swap buffers: compute next on \\'nxt\\' if it has a prefetched tile\\n    int tmp = cur; cur = nxt; nxt = tmp;\\n  }\\n\\n  // Drain outstanding stores\\n  if (st_inflight[0]) tops::wait(ev_st[0]);\\n  if (st_inflight[1]) tops::wait(ev_st[1]);\\n}\\n\\nvoid GCU_SILU(float * __restrict dev_inp,\\n              float * __restrict dev_out,\\n              const int nr_elems) {\\n  if (nr_elems <= 0) return;\\n\\n  // Prefer maximum threads on i20; keep small-N under-subscription to reduce overhead\\n  int threads = 12;\\n  if (nr_elems < 4096)        threads = 1;\\n  else if (nr_elems < 16384)  threads = 4;\\n  else if (nr_elems < 65536)  threads = 8;\\n\\n  // Target per-thread work; larger for large N to amortize kernel/DMA overhead\\n  size_t target_per_thr;\\n  if (nr_elems >= 8*1024*1024)      target_per_thr = 512u * 1024u; // >= 8M\\n  else if (nr_elems >= 1*1024*1024) target_per_thr = 384u * 1024u; // 1M~8M\\n  else if (nr_elems >= 128*1024)    target_per_thr = 256u * 1024u; // 128K~1M\\n  else                              target_per_thr = 128u * 1024u; // <128K\\n\\n  size_t total_thr_need = ((size_t)nr_elems + target_per_thr - 1) / target_per_thr;\\n  if (total_thr_need == 0) total_thr_need = 1;\\n\\n  int blocks = (int)((total_thr_need + threads - 1) / threads);\\n  if (blocks < 1) blocks = 1;\\n  if (blocks > 65535) blocks = 65535;\\n\\n  kernel_silu_db_opt<<<dim3(blocks,1,1), dim3(threads,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\\n  (void)topsGetLastError();\\n  (void)topsDeviceSynchronize();\\n}'},\n",
       " {'role': 'user',\n",
       "  'content': '目标是更快的运行速度， \\n            题目和接口规范：\\n            GCU MLP 在网络性能调优中,对于输出shape比较大的算子可以采用算子融合来节省dma的时间，本题我们实现llm网络中的mlp融合。 输入参数： gate_proj_weight:\\tgate weight设备地址，二维单精度浮点数数组的起始地址，数据按行优先连续存储，数组大小为 hidden_size*intermediate_size*sizeof(float), layout: [hidden_size, intermediate_size]。 up_proj_weight:\\tup weight设备地址，二维单精度浮点数数组的起始地址，数据按行优先连续存储，数组大小为 hidden_size*intermediate_size*sizeof(float)，layout: [hidden_size, intermediate_size]。 down_proj_weight:\\tdown weight设备地址，二维单精度浮点数数组的起始地址，数据按行优先连续存储，数组大小为 hidden_size*intermediate_size*sizeof(float), layout: [intermediate_size, hidden_size]。 input:\\tinput设备地址，二维单精度浮点数数组的起始地址，数据按行优先连续存储，数组大小为 seq_len*hidden_size*sizeof(float), layout: [seq_len, hidden_size]。 output:\\toutput设备地址，二维单精度浮点数数组的起始地址，数据按行优先连续存储，数组大小为 seq_len*hidden_size*sizeof(float), layout: [seq_len, hidden_size]。 seq_len:\\tseq_len。 hidden_size:\\thidden_size。 intermediate_size:\\tintermediate_size。 mlp示例代码 gate_proj = torch.einsum(\"mk, kn -> mn\", input, gate_proj_weight) up_proj   = torch.einsum(\"mk, kn -> mn\", input, up_proj_weight) act       = torch.nn.functional.silu(gate_proj) * up_proj down_proj = torch.einsum(\"mk, kn -> mn\", act, down_proj_weight) 评分标准与数据规模 建立在功能正确的基础上，选手的总分由功能得分和性能得分相加得到。本题共 10 个测试点，每个测试点功能正确将得到 5 分。性能测试分数将综合所有选手在该测试点的性能得出。数据规模如下： 所有的测试点，保证每个输入、输出tensor所占用的字节数小于2GB 接口是：void GCU_MLP(float *__restrict gate_proj_weight, float *__restrict up_proj_weight, float *__restrict down_proj_weight, float *__restrict input, float *__restrict output, const int seq_len, const int hidden_size, const int intermediate_size ) { } \\n            测试样例一共有十个，如果有测试样例的时间对比没有出现，则说明该测试样例没有通过而是有报错。\\n            当前代码：\\n            ```cpp\\n            \\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n#include <math.h>\\n\\n#define MIN(a,b) (((a)<(b))?(a):(b))\\n\\n// ======= 可调 tile（会按规模自适应收缩，默认偏大，运行时收缩） =======\\n#ifndef K_TILE\\n#define K_TILE   1536\\n#endif\\n#ifndef J_TILE\\n#define J_TILE   768    // 128 的整数倍\\n#endif\\n#ifndef H_TILE\\n#define H_TILE   768\\n#endif\\n#ifndef HCHUNK\\n#define HCHUNK   256    // down 行块更粗，减少 DTE 触发\\n#endif\\n\\n#ifndef USE_KAHAN\\n#define USE_KAHAN 0     // 如需更稳累加：-DUSE_KAHAN=1\\n#endif\\n\\n// 与 CPU 一致的 SiLU\\n__device__ __forceinline__ float silu_scalar(float x) {\\n    return x / (1.f + expf(-x));\\n}\\n\\n// RAII DTE 封装\\nstruct dte_scope {\\n    tops_dte_ctx_t &c;\\n    __device__ dte_scope(tops_dte_ctx_t &ctx) : c(ctx) { c.init(); }\\n    __device__ ~dte_scope() { c.destroy(); }\\n};\\n\\n__global__\\nvoid kernel_mlp_fused_c5_stable(\\n    float *__restrict gate_w,   // [H, I]  row-major\\n    float *__restrict up_w,     // [H, I]  row-major\\n    float *__restrict down_w,   // [I, H]  row-major\\n    float *__restrict inp,      // [S, H]  row-major\\n    float *__restrict out,      // [S, H]  row-major\\n    const int S, const int H, const int I)\\n{\\n    const int tid    = blockIdx.x * blockDim.x + threadIdx.x;\\n    const int stride = gridDim.x  * blockDim.x;\\n    if (stride <= 0) return;\\n\\n    // 动态收缩 tile（L1 粗估限制，给调度/栈留余量）\\n    int kTile = K_TILE, jTile = J_TILE, hTile = H_TILE, hChunk = HCHUNK;\\n    const int VLEN = tops::vlength<vfloat>(); // 32\\n\\n    // 经验阈：控制 float 个数 ~26万以内（≈1MB/4），留足余量\\n    while ((size_t)kTile + (size_t)8*jTile + (size_t)hTile + (size_t)4*hChunk > (size_t)260000) {\\n        if (kTile  > 512) kTile  -= 256;\\n        if (jTile  > 512) jTile  -= 128;\\n        if (hTile  > 512) hTile  -= 128;\\n        if (hChunk > 128) hChunk -=  64;\\n        if (kTile <= 512 && jTile <= 512 && hTile <= 512 && hChunk <= 128) break;\\n    }\\n\\n    // ---------------- DTE 上下文 ----------------\\n    // 输入(K)双缓冲\\n    tops_dte_ctx_t ctx_in[2];\\n    dte_scope s_in0(ctx_in[0]), s_in1(ctx_in[1]);\\n\\n    // gate/up 权重加载（两 ctx 交替），目标缓冲用 set_dst_addr 调整\\n    tops_dte_ctx_t ctx_g[2], ctx_u[2];\\n    dte_scope s_g0(ctx_g[0]), s_g1(ctx_g[1]);\\n    dte_scope s_u0(ctx_u[0]), s_u1(ctx_u[1]);\\n\\n    // down 行块双缓冲（稳定可靠的版本）\\n    tops_dte_ctx_t ctx_dw[2];\\n    dte_scope s_d0(ctx_dw[0]), s_d1(ctx_dw[1]);\\n\\n    // 输出回写\\n    tops_dte_ctx_t ctx_out;\\n    dte_scope s_out(ctx_out);\\n\\n    // ---------------- L1 缓冲（全部 128B 对齐） ----------------\\n    // 输入 K 双缓冲（按最大 kTile 上限分配）\\n    alignas(128) float in0[1536];\\n    alignas(128) float in1[1536];\\n\\n    // gate/up 各自四行权重缓冲（按最大 jTile 上限分配）\\n    alignas(128) float gwr0[1024], gwr1[1024], gwr2[1024], gwr3[1024];\\n    alignas(128) float uwr0[1024], uwr1[1024], uwr2[1024], uwr3[1024];\\n\\n    // 中间累加与激活\\n    alignas(128) float gate_acc[1024];\\n    alignas(128) float up_acc  [1024];\\n    alignas(128) float act_seg [1024];\\n\\n    // 输出片（按最大 hTile 上限）\\n    alignas(128) float out_seg [1024];\\n\\n    // down 行块双缓冲（按最大 hChunk 上限）\\n    alignas(128) float dw0[512], dw1[512];\\n\\n#if USE_KAHAN\\n    alignas(128) float h_sum[512], h_comp[512];\\n#else\\n    alignas(128) float h_sum[512];\\n#endif\\n\\n    for (int m0 = tid; m0 < S; m0 += stride) {\\n        const int m = m0;\\n\\n        for (int h0 = 0; h0 < H; h0 += hTile) {\\n            const int hb = MIN(hTile, H - h0);\\n            for (int h = 0; h < hb; ++h) out_seg[h] = 0.f;\\n\\n            for (int j0 = 0; j0 < I; j0 += jTile) {\\n                const int jb = MIN(jTile, I - j0);\\n                for (int j = 0; j < jb; ++j) { gate_acc[j] = 0.f; up_acc[j] = 0.f; }\\n\\n                // =============== 输入(K)双缓冲：一次 config，多次触发（size 用字节） ===============\\n                tops::event ev_in[2];\\n                bool in_has_ev[2] = {false, false};\\n                int cur = 0, nxt = 1;\\n\\n                ctx_in[0].config_memcpy(\\n                    tops::mdspan(tops::Private, in0, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n                ctx_in[1].config_memcpy(\\n                    tops::mdspan(tops::Private, in1, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n\\n                int k0 = 0;\\n                // 预取 tile0\\n                {\\n                    const int kb0 = MIN(kTile, H - k0);\\n                    if (kb0 > 0) {\\n                        ctx_in[cur].set_src_addr(inp + (size_t)m*H + k0);\\n                        ctx_in[cur].set_total_size(kb0 * sizeof(float)); // 字节数\\n                        ev_in[cur] = ctx_in[cur].trigger();\\n                        in_has_ev[cur] = true;\\n                    }\\n                }\\n\\n                // 预配置 gate/up 的 memcpy 模板（dst 用 set_dst_addr 改到对应缓冲）\\n                ctx_g[0].config_memcpy(tops::mdspan(tops::Private, gwr0, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_g[1].config_memcpy(tops::mdspan(tops::Private, gwr1, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_u[0].config_memcpy(tops::mdspan(tops::Private, uwr0, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n                ctx_u[1].config_memcpy(tops::mdspan(tops::Private, uwr1, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n\\n                while (k0 < H) {\\n                    const int kb_cur = MIN(kTile, H - k0);\\n\\n                    // 预取下一 K-tile\\n                    const int k1 = k0 + kb_cur;\\n                    const int kb_next = MIN(kTile, H - k1);\\n                    if (kb_next > 0) {\\n                        ctx_in[nxt].set_src_addr(inp + (size_t)m*H + k1);\\n                        ctx_in[nxt].set_total_size(kb_next * sizeof(float)); // 字节数\\n                        ev_in[nxt] = ctx_in[nxt].trigger();\\n                        in_has_ev[nxt] = true;\\n                    } else {\\n                        in_has_ev[nxt] = false;\\n                    }\\n\\n                    // 等待当前 K-tile\\n                    if (in_has_ev[cur]) tops::wait(ev_in[cur]);\\n                    float *in_seg = (cur==0?in0:in1);\\n\\n                    // ---- 遍历当前 K-tile（四行一组），gate/up 完全独立缓冲加载与累计 ----\\n                    int kk = 0;\\n                    for (; kk + 3 < kb_cur; kk += 4) {\\n                        const int kA = k0 + kk + 0;\\n                        const int kB = k0 + kk + 1;\\n                        const int kC = k0 + kk + 2;\\n                        const int kD = k0 + kk + 3;\\n\\n                        const float xA = in_seg[kk+0];\\n                        const float xB = in_seg[kk+1];\\n                        const float xC = in_seg[kk+2];\\n                        const float xD = in_seg[kk+3];\\n\\n                        // ---- gate：把四行分别放到 gwr0..gwr3\\n                        tops::event eg0, eg1, eg2, eg3;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kA*I + j0); eg0 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr1);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kB*I + j0); eg1 = ctx_g[1].trigger();\\n                        tops::wait(eg0); tops::wait(eg1);\\n                        ctx_g[0].set_dst_addr(gwr2);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kC*I + j0); eg2 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr3);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kD*I + j0); eg3 = ctx_g[1].trigger();\\n                        tops::wait(eg2); tops::wait(eg3);\\n\\n                        // gate 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                                vfloat g0  = tops::vload<vfloat>(gwr0 + j);\\n                                vfloat g1  = tops::vload<vfloat>(gwr1 + j);\\n                                vfloat g2  = tops::vload<vfloat>(gwr2 + j);\\n                                vfloat g3  = tops::vload<vfloat>(gwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g0, vA), tops::vmul<vfloat>(g1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g2, vC), tops::vmul<vfloat>(g3, vD))\\n                                        ));\\n                                tops::vstore(acc, gate_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                gate_acc[j] += gwr0[j]*xA + gwr1[j]*xB + gwr2[j]*xC + gwr3[j]*xD;\\n                        }\\n\\n                        // ---- up：把四行分别放到 uwr0..uwr3\\n                        tops::event eu0, eu1, eu2, eu3;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kA*I + j0); eu0 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr1);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kB*I + j0); eu1 = ctx_u[1].trigger();\\n                        tops::wait(eu0); tops::wait(eu1);\\n                        ctx_u[0].set_dst_addr(uwr2);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kC*I + j0); eu2 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr3);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kD*I + j0); eu3 = ctx_u[1].trigger();\\n                        tops::wait(eu2); tops::wait(eu3);\\n\\n                        // up 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                                vfloat u0  = tops::vload<vfloat>(uwr0 + j);\\n                                vfloat u1  = tops::vload<vfloat>(uwr1 + j);\\n                                vfloat u2  = tops::vload<vfloat>(uwr2 + j);\\n                                vfloat u3  = tops::vload<vfloat>(uwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u0, vA), tops::vmul<vfloat>(u1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u2, vC), tops::vmul<vfloat>(u3, vD))\\n                                        ));\\n                                tops::vstore(acc, up_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                up_acc[j] += uwr0[j]*xA + uwr1[j]*xB + uwr2[j]*xC + uwr3[j]*xD;\\n                        }\\n                    }\\n\\n                    // ---- 剩余 1~3 行（单行）——同样分开 gate / up 的缓冲 ----\\n                    for (; kk < kb_cur; ++kk) {\\n                        const int k = k0 + kk;\\n                        const float x = in_seg[kk];\\n                        const int vec = (jb / VLEN) * VLEN;\\n                        vfloat vx = tops::vbroadcast<vfloat>(x);\\n\\n                        // gate 单行 -> gwr0\\n                        tops::event eg;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)k*I + j0);\\n                        eg = ctx_g[0].trigger(); tops::wait(eg);\\n\\n                        int j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                            vfloat gw  = tops::vload<vfloat>(gwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(gw, vx));\\n                            tops::vstore(acc, gate_acc + j);\\n                        }\\n                        for (; j < jb; ++j) gate_acc[j] += gwr0[j] * x;\\n\\n                        // up 单行 -> uwr0\\n                        tops::event eu;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)k*I + j0);\\n                        eu = ctx_u[0].trigger(); tops::wait(eu);\\n\\n                        j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                            vfloat uw  = tops::vload<vfloat>(uwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(uw, vx));\\n                            tops::vstore(acc, up_acc + j);\\n                        }\\n                        for (; j < jb; ++j) up_acc[j] += uwr0[j] * x;\\n                    }\\n\\n                    // 交换 K 双缓冲\\n                    k0 += kb_cur;\\n                    int t = cur; cur = nxt; nxt = t;\\n                } // while K\\n\\n                // =============== SiLU 融合 ===============\\n                {\\n                    int j = 0, vec = (jb / VLEN) * VLEN;\\n                    vfloat vone = tops::vbroadcast<vfloat>(1.0f);\\n                    vfloat vneg = tops::vbroadcast<vfloat>(-1.0f);\\n                    for (; j < vec; j += VLEN) {\\n                        vfloat vg = tops::vload<vfloat>(gate_acc + j);\\n                        vfloat vu = tops::vload<vfloat>(up_acc   + j);\\n                        vfloat vexpn = tops::vexp(tops::vmul<vfloat>(vg, vneg));\\n                        vfloat vden  = tops::vadd<vfloat>(vone, vexpn);\\n                        vfloat vsilu = tops::vdiv<vfloat>(vg, vden);\\n                        tops::vstore(tops::vmul<vfloat>(vsilu, vu), act_seg + j);\\n                    }\\n                    for (; j < jb; ++j) {\\n                        float x = gate_acc[j];\\n                        act_seg[j] = silu_scalar(x) * up_acc[j];\\n                    }\\n                }\\n\\n                // =============== down 投影（行块 + 增量搬运 + 双缓冲，稳定可靠） ===============\\n                ctx_dw[0].config_memcpy(\\n                    tops::mdspan(tops::Private, dw0, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n                ctx_dw[1].config_memcpy(\\n                    tops::mdspan(tops::Private, dw1, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n\\n                for (int hst = 0; hst < hb; hst += hChunk) {\\n                    const int hc = MIN(hChunk, hb - hst);\\n#if USE_KAHAN\\n                    for (int t = 0; t < hc; ++t) { h_sum[t] = 0.f; h_comp[t] = 0.f; }\\n#else\\n                    for (int t = 0; t < hc; ++t) h_sum[t] = 0.f;\\n#endif\\n                    tops::event ev_dw[2];\\n                    bool has_ev[2] = {false, false};\\n                    int dc = 0, dn = 1;\\n\\n                    int jx = 0;\\n                    // 预取首行（size 用字节数）\\n                    if (jx < jb) {\\n                        ctx_dw[dc].set_src_addr(down_w + (size_t)(j0 + jx)*H + (h0 + hst));\\n                        ctx_dw[dc].set_total_size(hc * sizeof(float)); // 字节数\\n                        ev_dw[dc] = ctx_dw[dc].trigger();\\n                        has_ev[dc] = true;\\n                    }\\n\\n                    while (jx < jb) {\\n                        // 预取下一行\\n                        const int jn = jx + 1;\\n                        if (jn < jb) {\\n                            ctx_dw[dn].set_src_addr(down_w + (size_t)(j0 + jn)*H + (h0 + hst));\\n                            ctx_dw[dn].set_total_size(hc * sizeof(float)); // 字节数\\n                            ev_dw[dn] = ctx_dw[dn].trigger();\\n                            has_ev[dn] = true;\\n                        } else {\\n                            has_ev[dn] = false;\\n                        }\\n\\n                        if (has_ev[dc]) tops::wait(ev_dw[dc]);\\n                        float *dw = (dc==0?dw0:dw1);\\n                        const float a = act_seg[jx];\\n\\n                        int h = 0, vecH = (hc / VLEN) * VLEN;\\n                        vfloat va = tops::vbroadcast<vfloat>(a);\\n#if USE_KAHAN\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vc = tops::vload<vfloat>(h_comp+ h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vfloat vy = tops::vsub<vfloat>(vprod, vc);\\n                            vfloat vt = tops::vadd<vfloat>(vs, vy);\\n                            vfloat vtmp = tops::vsub<vfloat>(vt, vs);\\n                            vc = tops::vsub<vfloat>(vtmp, vy);\\n                            tops::vstore(vt, h_sum + h);\\n                            tops::vstore(vc, h_comp+ h);\\n                        }\\n                        for (; h < hc; ++h) {\\n                            float y = a * dw[h] - h_comp[h];\\n                            float t = h_sum[h] + y;\\n                            h_comp[h] = (t - h_sum[h]) - y;\\n                            h_sum[h]  = t;\\n                        }\\n#else\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vs = tops::vadd<vfloat>(vs, vprod);\\n                            tops::vstore(vs, h_sum + h);\\n                        }\\n                        for (; h < hc; ++h) h_sum[h] += a * dw[h];\\n#endif\\n                        ++jx;\\n                        int t = dc; dc = dn; dn = t;\\n                    } // jx\\n\\n                    // 写回到 out_seg 片\\n                    for (int t = 0; t < hc; ++t) out_seg[hst + t] += h_sum[t];\\n                } // hst\\n            } // j0\\n\\n            // 回写 L3\\n            tops::memcpy(\\n                ctx_out,\\n                tops::mdspan(tops::Global,  out + (size_t)m*H + h0, hb),\\n                tops::mdspan(tops::Private, out_seg, hb)\\n            );\\n        } // h0\\n    } // m\\n}\\n\\n// ---------------- Host 接口（题目指定，保持 C++ 链接） ----------------\\nvoid GCU_MLP(float *__restrict gate_proj_weight,\\n             float *__restrict up_proj_weight,\\n             float *__restrict down_proj_weight,\\n             float *__restrict input,\\n             float *__restrict output,\\n             const int seq_len,\\n             const int hidden_size,\\n             const int intermediate_size)\\n{\\n    const int threads = 12; // i20：一个 block 内最多 12 个 thread\\n    int blocks = (seq_len + threads - 1) / threads;\\n    if (blocks < 1) blocks = 1;\\n    if (blocks > 65535) blocks = 65535;\\n\\n    kernel_mlp_fused_c5_stable<<<blocks, threads>>>(\\n        gate_proj_weight, up_proj_weight, down_proj_weight,\\n        input, output, seq_len, hidden_size, intermediate_size\\n    );\\n\\n    // 开发期可开\\n    // (void)topsGetLastError();\\n    // (void)topsDeviceSynchronize();\\n}\\n\\n            要求：\\n            1.每次尽量只改动一个地方来加快运行速度,如有报错方便定位问题。\\n            2.改动务必可编译运行，若需新增辅助函数请写全。\\n            3.必须输出完整可编译 C++ 源码，并且仅用 <candidate>...</candidate> 包裹，不用写其他说明文字，不用解释。\\n            最近错误日志(应避免)：\\n[2025-11-04 08:17:52] 修复失败改动总结\\n上一轮把 L1 缓冲用“__aligned__”声明（该标记在当前 SDK 不存在）导致 rowA/rowB/vtmp 未定义，mdspan 被误推断成函数指针（如 powf）进而触发连锁编译错误。这一轮改用标准的 alignas(128) 正确对齐并声明缓冲，mdspan 获得 float* 正确类型，成功编译运行。\\n\\n// 错误\\n__aligned__ float rowA[MAX_DIM], rowB[MAX_DIM], vtmp[VLEN];\\n// 正确\\nalignas(128) float rowA[MAX_DIM];\\nalignas(128) float rowB[MAX_DIM];\\nalignas(128) float vtmp[VLEN];\\n\\n[2025-11-04 08:25:32] 修复失败改动总结\\n上一轮把 for 的增量写成了“++c++)”（相当于对 c++ 再做前置自增），导致“expression is not assignable”的编译错误；本轮把增量改成合法形式（如 c++ 或 ++c），并顺带引入 fast_floor_to_int，成功通过编译与测试。\\n示例：错误 for (int c=0; c<CBLK; ++c++) { ... } → 正确 for (int c=0; c<CBLK; c++) { ... } 或 for (int c=0; c<CBLK; ++c) { ... }\\n\\n[2025-11-04 10:21:46] 修复失败改动总结\\n- 上一轮错在 DTE 事件与上下文复用不严：同一 ctx 反复 set_* 后 trigger，但在下一次复用前未确保前一轮 DMA 已完成，导致 DMA 悬挂→Kernel Timeout。\\n- 本轮在每次复用前显式 tops::wait 对应 event，并用同步 tops::memset 清零局部缓冲，消除了悬挂（并小幅加入内环展开优化）。\\n\\n示例\\ntops::event ev = ctx.trigger();\\ntops::wait(ev);           // 复用 ctx/set_* 前先等\\nctx.set_src_addr(...);\\nev = ctx.trigger();\\n\\n\\n            最近有效提分经验：\\n提到 128，单次处理更宽、DTE 调用与循环次数减半，显著改善大规模用例（8/9）的平均时延。\\n- 将 kernel 标记为 __cooperative__，在 GCU210 上确保两块并发常驻，降低调度抖动，稳定尾部时延。\\n\\n示例差异：\\n__global__ __cooperative__ void gcu_gridsample_nearest_kernel_v3(...);\\nconst int STRIP = 128;  // 由 64 提升到 128\\n\\n[2025-11-04 09:06:55] 提分经验总结\\n提分点：仅在 kernel 上添加了 __cooperative__ 标记，使两个 block 能保证并发驻留执行，减少调度气泡；其余 DTE/行缓冲/逐通道逻辑与上一版一致，正确性等价，性能稳定性略有提升。\\n\\n代码差异（关键一行）：\\n__global__ __cooperative__ void dwconv3x3_sync_kernel(...){ /* body unchanged */ }\\n\\n[2025-11-04 09:22:39] 提分经验总结\\n- 关键提分点：用 DTE 的 memset+memcpy 一步构建带左右零填充的 L1 行缓冲，替代标量循环清零，叠加将索引化简为 baseX+=stride，显著降低每行开销与 ALU 负担。\\n- 次要提分点：标记 __cooperative__ 并将线程/块限制到 GCU210 的 12×2 上限，提高并发调度稳定性。\\n\\n示例（≤10行）：\\n```cpp\\n// L1 行缓冲构建：零填充 + 中段复制\\ntops::memset(ctx, tops::mdspan(tops::Private, row, rowLen), 0.0f);\\nif ((unsigned)y < (unsigned)IH) {\\n  tops::memcpy(ctx,\\n    tops::mdspan(tops::Private, row + padLeft, IW),\\n    tops::mdspan(tops::Global, const_cast<float*>(inC + (long long)y * IW), IW));\\n}\\n```\\n\\n[2025-11-04 09:50:58] 提分经验总结\\n- 唯一有效提分点：给 kernel 增加 __cooperative__，在 i20 上确保最多 2 个 block 同时起跑（multiProcessorCount=2），减少调度抖动与等待，小规模形状下显著压低尾延迟与提升稳定性。\\n  示例：\\n  __global__ __cooperative__ void dwconv3x3_sync_kernel(...){ /* ... */ }\\n\\n[2025-11-04 10:06:04] 提分经验总结\\n- 将 J_TILE 提至 1024 减少权重行块循环与 DTE 触发次数，且用 tops::memset 清零 out_seg 替代标量循环，降低内存与清零开销。\\n- SiLU 向量路径改用 vsigmoid + 乘法替代 vexp+vdiv，并将 kernel 标为 __cooperative__ 且限制 grid≤2，使两块并行、减少调度抖动。\\n\\n[2025-11-04 10:09:05] 提分经验总结\\n提分点：把每次 jTile 内的 gate_acc/up_acc 标量清零循环改为 DTE memset（L1 上的批量清零），减少内层循环开销并更好地与搬运/计算流水重叠；其余计算与流水结构保持不变，平均耗时随之下降。\\n\\n代码片段（after）：\\ntops::memset(ctx_out, tops::mdspan(tops::Private, gate_acc, jb), 0.0f);\\ntops::memset(ctx_out, tops::mdspan(tops::Private, up_acc,   jb), 0.0f);\\n\\n[2025-11-04 11:23:30] 提分经验总结\\n- 将 strip 批量从 64 提升到 128，显著减少 DTE 配置/触发次数与循环次数，放大 L1 批处理粒度，降低 L3 往返开销（大尺寸场景均值更优）。\\n- 标注 __cooperative__，在 i20 上确保 2 个 block 同驻并发，稳定占满 24 SIP，降低调度抖动。\\n\\n代码片段：\\n```cpp\\n__global__ __cooperative__ void gcu_gridsample_nearest_kernel_v3(...);\\nconst int STRIP = 128;  // 由 64 → 128\\n```'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "def proxy_chat(messages):\n",
    "    base_url = \"http://35.220.164.252:3888/v1/chat/completions\"\n",
    "    api_key = \"sk-4QHgCPVmwEz20WvAd1gFkOtO9trprTws3o5Hhh3PZDWuu8Fl\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"  \n",
    "    }\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "        \"model\": 'gpt-5-medium', # 可以替换为需要的模型\n",
    "        \"messages\": messages,\n",
    "        \n",
    "    }\n",
    "    response = requests.post(base_url, headers=headers, json=data)\n",
    "    response.raise_for_status()  \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(\"Response headers:\", response.headers)\n",
    "        try:\n",
    "            # 尝试解析 JSON 返回\n",
    "            print(\"Response JSON:\", response.json())\n",
    "        except Exception:\n",
    "            # 如果不是 JSON，就直接打印文本\n",
    "            print(\"Response text:\", response.text)\n",
    "\n",
    "  \n",
    "    response = response.json()\n",
    "    return response \n",
    "with open('/root/nian/gcu/gcu_mlp/messages.json','r') as f:\n",
    "    a = json.load(f)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af82c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【GCU 教程】\n",
      "GCU 是燃原的 AI 计算加速设备。TopsCC 是基于 GCU 的编程平台，TopsCC 包含一套工具集和 runtime 库，支持 C/C++ 编程，可以生成在设备端和主机端运行的程序。本文件主要介绍如何在 GCU 上通过 TopsCC 进行算子编程。\n",
      "表 1‑2 词汇表：\n",
      "\n",
      "| 术语      | 描述                                   |\n",
      "|-----------|----------------------------------------|\n",
      "| GCU       | 燃原 AI 加速卡                         |\n",
      "| TopsCC    | 燃原编程平台                           |\n",
      "| clang     | C/C++ 编译器                           |\n",
      "| llvm      | 编译器套件                             |\n",
      "| Kernel    | 核函数，运行在设备端的程序             |\n",
      "| Fatbin    | 包含了设备端和主机端运行程序的二进制文件 |\n",
      "| DTE       | 数据搬运引擎                           |\n",
      "| RTC       | 运行时编译                             |\n",
      "| SIMT      | 单指令多线程                           |\n",
      "| SIP       | 硬件计算核心                           |\n",
      "| i20       | 第二代 GCU 推理卡                      |\n",
      "| GCU210    | 第二代 GCU 推理卡，和 i20 等价         |\n",
      "| TopsRider | 燃原 SDK 开发套件                     |\n",
      "---\n",
      "\n",
      "# 2 简介\n",
      "人工智能领域对计算性能的需求极高。GCU 作为强大的计算引擎，提供了必要的算力支撑。而 TopsCC 则扮演了编程平台的角色，它通过优化编程环境，使得 GCU 的计算潜能得到更充分的释放。TopsCC 通过扩展 C++ 语言，使得开发者能够以接近 C++ 的编程方式，高效地为 GCU 编写程序。\n",
      "GCU 具备多计算核心和多级存储的设计，这些架构特性会反映到具体的编程模型上。\n",
      "\n",
      "（图 2‑1 GCU 架构图）\n",
      "\n",
      "## 2.1 计算核心\n",
      "\n",
      "SIP 计算核心是燃原科技打造面向云端数据中心的人工智能训练一体芯片采用全新的通用计算单元 GCU‑CARE 架构，为深度学习提供强大的算力支持。计算核心支持标量、向量和张量计算。通过燃原科技自有知识产权的软硬件架构 TopsRider，可以广泛地支持视觉、语音、NLP、推荐、LLM 等各技术方向的模型训练与推理。i20 一共含 24 个计算核心。\n",
      "\n",
      "## 2.2 多级存储\n",
      "\n",
      "GCU 包含 L1–L3 三级存储。\n",
      "\n",
      "(图 2‑2 三级存储)\n",
      "\n",
      "L1: 每个计算核心内部包含了一个私有存储（L1）。i20 中每一个计算核心具有 1 M 的 L1。\n",
      "L2: 12 个计算核心可以组成一个计算簇，同一个 GCU 内包含多个计算簇。每个计算簇内的计算核心可以共享一个簇内的 24 M L2 共享存储。\n",
      "L3: GCU 拥有一个全局设备存储（L3），对所有计算簇可见，i20 的 L3 大小为 16 GB。\n",
      "L1、L2 的介质是 SRAM，L3 介质一般是 HBM 或者 GDDR。\n",
      "\n",
      "---\n",
      "\n",
      "# 3 TopsCC 编程模型\n",
      "\n",
      "## 3.1 概述\n",
      "\n",
      "### 3.1.1 函数类型限定符\n",
      "\n",
      "TopsCC 支持设备端和主机端混合编程，使用 __device__ 和 __global__ 标记设备端程序，使用 __host__ 标记主机端程序。没有标记的函数默认为主机端程序。\n",
      "\n",
      "示例代码：\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__global__ void foo() {\n",
      "    // TODO: add code here\n",
      "}\n",
      "\n",
      "int main(int argc, char **argv) {\n",
      "    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "\n",
      "    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "表 3‑1 函数类型限定符：\n",
      "\n",
      "| 函数类型限定符 | 执行                     | 调用                                                                 |\n",
      "|----------------|--------------------------|-----------------------------------------------------------------------|\n",
      "| __device__     | 在设备端运行的函数       | 可以被 __global__ 函数调用，但不能被 __host__ 函数调用                 |\n",
      "| __global__     | 在设备端运行的入口函数   | 只能由 __host__ 函数启动，不能被 __device__ 或其他 __global__ 函数调用 |\n",
      "| __host__       | 在主机端运行的函数       | 只能被 __host__ 函数调用                                             |\n",
      "\n",
      "说明：一个函数可以同时标记为 __device__ 和 __host__，这种函数在设备端和主机端都能被调用。没有标记的函数默认都是 __host__ 函数。\n",
      "\n",
      "### 3.1.2 线程模型\n",
      "\n",
      "TopsCC 支持类似 SIMT 的编程模型，多个 Thread 可同时执行同一份代码。Thread 的层次结构分为 Thread、Block 和 Grid 三层，每层可用 x、y、z 三个维度指定程序运行的层次结构。\n",
      "\n",
      "- **Thread**：对应一个标量或向量执行程序，物理上映射到一个计算核心 SIP 上执行。在线程内部可以通过 `threadIdx.x`、`threadIdx.y`、`threadIdx.z` 获取当前 thread 的坐标。\n",
      "- **Block**：包含一组 Thread，物理上映射到一组 SIP。在线程内部可以通过 `blockIdx.x`、`blockIdx.y`、`blockIdx.z` 获取当前 block 的坐标。可以使用 `blockDim.x`、`blockDim.y`、`blockDim.z` 指定 block 的维度大小，作为内核调用符 `<<<>>>` 的参数。\n",
      "  - 硬件特性：在 gcu210 上 block dims 的乘积最大为 12，即 `blockDim.x * blockDim.y * blockDim.z <= 12`。\n",
      "- **Grid**：包含一组 Block。可以使用 `gridDim.x`、`gridDim.y`、`gridDim.z` 指定 grid 的维度大小作为内核调用符 `<<<>>>` 的参数。\n",
      "  - 硬件特性：设备上 grid dims 的乘积最大为 2，即 `gridDim.x * gridDim.y * gridDim.z <= 2`。\n",
      "\n",
      "图 3‑1 thread 模型：线程按照 Thread → Block → Grid 三级结构组织，并映射到芯片上多个 SIP 计算核心和存储层级。\n",
      "\n",
      "TopsCC 支持 cooperative 模式。当一个 __global__ 函数（kernel）被标记为 cooperative 模式时，这个 kernel 会被运行时使用 `topsLaunchCooperativeKernel` 启动。在这种模式下 grid 中所有的 block 会同时运行。内核中可以使用 `__synchblocks()` 调用进行 block 间的同步。\n",
      "\n",
      "示例代码：\n",
      "```cpp\n",
      "__global__ __cooperative__ void foo() {\n",
      "    __synchblocks();\n",
      "}\n",
      "```\n",
      "\n",
      "### 3.1.3 存储模型\n",
      "\n",
      "i20 GCU 的存储系统结构如下图所示（图 3‑2）。用户视角可见以下地址空间：\n",
      "\n",
      "- `__device__`：全局的地址空间，所有 block 可见。对应硬件的全局设备存储（L3）。\n",
      "\n",
      "  ```c\n",
      "  __device__ int data[100];\n",
      "  ```\n",
      "\n",
      "说明：在 GCU 2.0 中，kernel/SIP 不直接访问 L3，需要由 DTE 将数据搬运到 L1 后访问。\n",
      "\n",
      "* `__constant__`：全局的常量地址空间，所有 thread 可见。对应硬件的全局设备存储（L3）。\n",
      "\n",
      "  ```c\n",
      "  __constant__ int a = 2;\n",
      "  ```\n",
      "\n",
      "* `__shared__`：block 内共享地址空间，block 内的 thread 可见。对应硬件的簇内共享存储（L2）。\n",
      "\n",
      "  ```c\n",
      "  __shared__ int data[100];        // static size shared memory\n",
      "  extern __shared__ int data2[];   // dynamic size shared memory\n",
      "  ```\n",
      "\n",
      "  说明：在 GCU 2.0 中，不允许直接访问 L2，只能用于 DTE 数据搬运操作。动态大小的 shared memory 每个 **global** 函数只能使用一个。每个计算簇最大支持 24 MB 的 shared memory。\n",
      "\n",
      "* 无修饰符变量：位于 thread 的私有地址空间，对应硬件的计算核心私有存储（L1）。\n",
      "\n",
      "  ```c\n",
      "  int data;\n",
      "  float data2[100];\n",
      "  ```\n",
      "\n",
      "* `__aligned__`：对于私有空间的存储，如果会被向量操作使用，需要使用 `__aligned__` 进行对齐。\n",
      "\n",
      "  ```c\n",
      "  __aligned__ int data[100];\n",
      "  ```\n",
      "\n",
      "### 3.1.4 内建的宏\n",
      "\n",
      "* `__TOPS_DEVICE_COMPILE__`：编译设备端代码时会被定义。\n",
      "* `__GCU_ARCH__`：由 3 位数字组成；i20 的值为 210。\n",
      "\n",
      "## 3.2 编程接口\n",
      "\n",
      "TopsCC 通过扩展 C++，提供设备端和主机端的运行时库来支持基于 C++ 的编程。编译方式包括两种：离线编译和运行时编译。\n",
      "\n",
      "\n",
      "### 图 3‑3 TopsCC 离线编译\n",
      "\n",
      "离线编译流程中，C/C++ 源代码与 kernel 库、host 库一起经由编译器生成 fatbin 文件，运行时由 CPU 和 GCU 装载执行。本次竞赛采用离线编译方式。\n",
      "\n",
      "### 3.2.2 运行时编译\n",
      "\n",
      "运行时需要实时编译源文件时，可使用运行时编译（RTC）接口。主机端接口支持嵌入源文件编译并运行：仅设备端代码会被编译并加载，主机端代码会被忽略，生成的可执行文件会缓存在内存中，便于重复调用。\n",
      "\n",
      "### 3.2.3 一个简单的程序例子\n",
      "\n",
      "示例程序如下。它在 GCU 上启动一个空的 kernel 函数 `foo`，`dim3(1,1,1)` 与 `1` 等价。\n",
      "\n",
      "```c++\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__global__ void foo() { }\n",
      "\n",
      "int main(int argc, char **argv) {\n",
      "    // 启动一个 block，block 中有一个 thread 执行 kernel 函数 foo\n",
      "    foo<<<1/*grid dim*/, 1/*block dim*/>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "\n",
      "    foo<<<dim3(1,1,1), dim3(1,1,1)>>>();\n",
      "    assert(topsGetLastError() == topsSuccess);\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "**内核调用运算符 `<<<grid_dim, block_dim, share_memory_sz, stream>>>`** 接受 4 个参数：\n",
      "\n",
      "1. `grid_dim`：Grid 的尺寸，可参照线程层次结构选择。\n",
      "2. `block_dim`：Block 的尺寸，同样参照线程层次结构。\n",
      "3. `share_memory_sz`：kernel 在 block 中申请的动态共享数组字节数（如 `__shared__ int data[]`）。默认值为 0 Byte；如果申请大小超过硬件共享内存限制，程序会出错。\n",
      "4. `stream`：流对象，默认为空；用于异步调用。\n",
      "\n",
      "建议在 kernel 调用后使用 `topsGetLastError` 检查执行是否成功。\n",
      "\n",
      "**资源限制：**最大 grid 尺寸可以通过 `topsGetDeviceProperties` 查询。gcu210 硬件限制为 `gridDim.x ≤ 65536`、`gridDim.y ≤ 256`、`gridDim.z ≤ 256`。对于 cooperative 模式，grid 的总大小 `gridDim.x * gridDim.y * gridDim.z` 不得超过设备的 `multiProcessorCount`（gcu210 为 2）。block 的总线程数不得超过设备 `maxThreadsPerMultiProcessor`（gcu210 为 12）。下面代码展示如何查询这些属性并设置 block 大小：\n",
      "\n",
      "```c++\n",
      "topsDeviceProp_t prop;\n",
      "int deviceId = 0;\n",
      "topsGetDeviceProperties(&prop, deviceId);\n",
      "\n",
      "dim3 blockDims;\n",
      "blockDims.x = prop.maxThreadsPerMultiProcessor;\n",
      "blockDims.y = 1;\n",
      "blockDims.z = 1;\n",
      "\n",
      "foo<<<1, blockDims>>>();\n",
      "```\n",
      "\n",
      "### 3.2.4 设备端编程\n",
      "\n",
      "#### 打印和断言\n",
      "\n",
      "在 GCU 2.0 中 kernel 直接访问的存储地址只支持私有地址空间（L1）和 `__constant__` 地址空间；对于 `__shared__` 和 `__device__` 地址空间，需要通过 DTE 将数据搬运到 L1 后访问。使用 `printf` 和 `assert` 有以下限制：\n",
      "\n",
      "* kernel 函数中可以使用 `printf`，但格式字符串必须是常量，且不支持 `%p` 和 `%.` 等格式。\n",
      "* `assert` 默认在 O3 优化级别关闭，如需开启可在编译时定义 `-DTOPS_ENABLE_ASSERT`。\n",
      "* 当 kernel 代码调用 `printf` 或 `assert` 时，运行时处于 debug 同步模式，此时同一 stream 上函数的执行是同步的。\n",
      "\n",
      "#### 3.2.4.1 数据流编程\n",
      "\n",
      "TopsCC 使用 DTE（Data Transfer Engine）接口进行数据搬运，允许计算与搬运并行。\n",
      "一次数据搬运，通常包含以下流程：  \n",
      "1. 声明DTE上下文\n",
      "2. 使用mdspan给memory加入信息\n",
      "3. 使用ctx操作接口\n",
      "\n",
      "一个DTE编程示例如下，将数据从设备端指针from线性拷贝到设备端指针to（from和to所指向的均为L3上的内存）：\n",
      "```c\n",
      "__global__ void copy_d2d(int *from, int *to, size_t N) {\n",
      "  __private_dte__tops_dte_ctx_t ctx;  // Declare a DTE Context\n",
      "  tops::dte_scope s(ctx);             // Initalize DTE Context\n",
      "\n",
      "  tops:: mdspan src(tops::Global, from, N);   // Add shape info for source\n",
      "  tops::mdspan dst(tops::Global, to, N);      // Add shape info for dest\n",
      "\n",
      "  tpos::memcpy(ctx, dst, src);        // Copy data from source to dest\n",
      "}\n",
      "```\n",
      "\n",
      "##### 支持的标量数据类型\n",
      "\n",
      "* 基本类型：`bool`、`char`、`unsigned char`、`short`、`unsigned short`、`int`、`unsigned int`、`float`。\n",
      "* 扩展浮点类型：`tops::half` 和 `tops::bfloat`。例如可通过 `#include <tops/half.h>` 和 `#include <tops/bfloat.h>` 引入。\n",
      "\n",
      "代码：ops::haf 和tops::bfloat 的定义方式示例\n",
      "```c\n",
      "#include<tops/half.h>\n",
      "#include<tops/bfloat.h>\n",
      "\n",
      "__device__ void test(){\n",
      "  tops::half value1(0.2);\n",
      "  tops::bfloat value2(2.4);\n",
      "}\n",
      "```\n",
      "\n",
      "##### DTE Context（DTE 上下文）\n",
      "\n",
      "在 `__shared__` 或 `__device__` 地址空间上的数据需通过 DTE 搬运。使用 DTE 前需声明 DTE 上下文，TopsCC 支持三种类型：\n",
      "\n",
      "* **Block 级共享 DTE Context**：`__shared_dte__ tops_dte_ctx_t ctx[n];`——block 内线程共享 DTE 上下文，只能支持 Global 和 Shared 之间的数据传输。\n",
      "* **Block 级私有 DTE Context**：`__private_dte__ tops_dte_ctx_t ctx;`——Block 级的 DTE 资源，只能支持 Global 和 Shared 之间的数据传输。\n",
      "* **Thread 级 DTE Context**：`tops_dte_ctx_t ctx;`——线程私有 DTE 资源，可支持 Global、Shared 和 Private 之间的数据传输。\n",
      "\n",
      "##### mdspan\n",
      "\n",
      "TopsCC使用一种名为`mdspan`的数据结构来给设备地址附加额外的信息（如维度、形状、所属内存空间、总大小等），其构造函数参数包括：\n",
      "\n",
      "1. 所属地址空间（可选）：`tops::Global`、`tops::Shared`、`tops::Private`，对应 L3/L2/L1。\n",
      "2. 起始地址指针。\n",
      "3. 形状维度大小列表。\n",
      "\n",
      "DTE相关结构都使用`mdspan`作为配置参数。\n",
      "\n",
      "示例：声明 `mdspan` 的两种方式：\n",
      "\n",
      "```c++\n",
      "// method 1\n",
      "tops::mdspan src1(tops::Global, from, N, H, W, C);\n",
      "tops::mdspan src2(from, N, H, W, C);\n",
      "\n",
      "// method 2\n",
      "auto shape = {N, H, W, C};\n",
      "tops::mdspan src3(tops::Global, from, shape);\n",
      "tops::mdspan src4(from, shape);\n",
      "```\n",
      "\n",
      "其中 `from` 为某数据类型的起始地址，DTE 操作一般支持九种数据类型（`int8_t`、`uint8_t`、`int16_t`、`uint16_t`、`int32_t`、`uint32_t`、`tops::bfloat`、`tops::half` 和 `float`）。`shape`是数据的形状，`shape[0]` 为数据最高维度的大小，通常对应内存中步幅最大（最不连续）的那一维。\n",
      "\n",
      "##### DTE 支持的操作模式\n",
      "\n",
      "DTE 支持两种使用模式：\n",
      "\n",
      "1. **配置与启动分离模式**：适用于计算与搬运流水并行的场景。先调用配置接口，再调用启动接口。支持同步和异步两种启动方式。\n",
      "\n",
      "   * **同步启动**（`trigger_and_wait`）：\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     ctx.config_memcpy(dst, src);\n",
      "     ctx.trigger_and_wait();\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "   * **异步启动**（`trigger`）：返回 `tops::event`，可用 `tops::wait` 等待。\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     ctx.config_memcpy(dst, src);\n",
      "     tops::event ev = ctx.trigger();\n",
      "     tops::wait(ev);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "2. **配置和启动合并模式**：代码更简洁，同时支持同步和异步两种方式。\n",
      "\n",
      "   * **同步启动**：\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     tops::memcpy(ctx, dst, src);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "   * **异步启动**：调用以 `_async` 结尾的函数返回 `tops::event`，可用 `tops::wait` 等待。\n",
      "\n",
      "     ```c++\n",
      "     tops_dte_ctx_t ctx;\n",
      "     ctx.init();\n",
      "     auto ev = tops::memcpy_async(ctx, dst, src);\n",
      "     tops::wait(ev);\n",
      "     ctx.destroy();\n",
      "     ```\n",
      "\n",
      "##### 全量配置接口\n",
      "\n",
      "全量配置需要完整设置 DTE 的参数。多数搬运接口含有两个 `mdspan` 参数，第一个为目标地址对象，第二个为源地址对象。常用接口见下表：\n",
      "\n",
      "| 接口                                    | 描述                                                                             |\n",
      "| ------------------------------------- | ------------------------------------------------------------------------------ |\n",
      "| `ctx.config_memcpy(dst, src)`         | 以 `src` 总大小拷贝 `src` 到 `dst`，用户需确保 `dst` 足够大。                                   |\n",
      "| `ctx.config_memset(dst, const_value)` | 将 `dst` 指定的内存设置为 `const_value`。                                                |\n",
      "| `ctx.config_slice(dst, src, offset)`  | 按 `dst` 指定的形状和 `offset` 指定的位置从 `src` 中拷贝数据到 `dst`。若 `dst` 大小或偏置超出 `src`，将自动填充。**切片操作：** 在GCU的应用中，通常处理的数据量很大，而GCU的执行单元 SIP 所能访问的SIP memory比较小，所以在数据处理上，需要将大块数据切片搬运到 SIP memory，供SIP处理加工，这种操作称为slice，你想的操作称为deslice。根据数据处理需求，可选择以下切片方式：(1)**线性切片**：依次将相应的数据片段搬运到SIP memory中。一个典型的例子：如果要处理的是一个2维数组，而SIP每次可以处理数组中的完整一行，则可以对该数组进行线性切片。  (2)**等维切片**：对多维数组同时沿各维切割成多个形状相同的块（将一个 N 维数组切为多个小的 N 维数组）。一个典型的例子：将一个3维数组切分成多个小形状的3维数组，可以理解为把一个大的立方体切分成多个小立方体。 (3)**多维切片**：仅在指定的部分维度上进行切片。可以把线性切片和等维切片理解为多维切片的两个特例|\n",
      "| `ctx.config_deslice(dst, src, offset)`                            | 把 `src` 指定的数据拷贝并覆盖到 `dst` 的 `offset` 位置。                 |\n",
      "| `ctx.config_transpose(dst, src, layout)`                          | 按 `layout` 对 `src` 进行转置并拷贝至 `dst`，layout的数据排列定义为形如{0,1,2,3}。                       |\n",
      "| `ctx.config_slice_transpose(dst, src, offset, layout)`            | slice和transpose的组合，先对 `src` 切片，再按 `layout` 转置切片并放入 `dst`。                   |\n",
      "| `ctx.config_transpose_deslice(dst, src, offset, layout)`          | transpose和deslice的组合，先对 `src` 按 `layout` 转置，再拷贝并覆盖到 `dst` 指定位置。               |\n",
      "| `ctx.config_pad(dst, src, pad_low, pad_high, pad_mid, pad_value)` | 垫片操作，把src指定的数据，按照dst所指定的形状和大小，用pad_value的值设置到src的首部（pad_low有效），尾部（pad_high有效），或者中间（pad_mid有效），并把结果移动到dst所指的位置。 |\n",
      "| `ctx.config_mirror_tb(dst, src)`                                  | 按第一维（X 轴，shape的最后一个元素）翻转 `src`，结果放入 `dst`。                        |\n",
      "| `ctx.config_mirror_lr(dst, src)`                                  | 按第二维（Y 轴，shape的倒数第二个元素）翻转 `src`，结果放入 `dst`。                        |\n",
      "| `ctx.config_broadcast(dst, src)`                                  | 根据 `src` 到 `dst` 维度变化扩展 `src` 数据，结果放入 `dst`。             |\n",
      "\n",
      "##### 增量配置接口\n",
      "\n",
      "增量配置接口是指在完成一次全量 DTE 配置后，后续仅对发生变化的部分调用相应的API进行配置，可以减少DTE配置时间。增量配置接口可以在不修改DTE数据搬运操作的类型的情况下改变 DTE context 的配置。\n",
      "\n",
      "* **基础增量接口：**\n",
      "\n",
      "| 接口                       | 描述          |\n",
      "| ------------------------ | ----------- |\n",
      "| `ctx.set_dst_addr(addr)` | 设置新的 dst 地址 |\n",
      "| `ctx.set_src_addr(addr)` | 设置新的 src 地址 |\n",
      "| `ctx.set_dst_offset(dim, offset)`               | 设置 `dst` 在维度 `dim` 的偏移 |\n",
      "| `ctx.set_src_offset(dim, offset)`               | 设置 `src` 在维度 `dim` 的偏移 |\n",
      "| `ctx.set_dst_dim_size(dim, size)`               | 设置 `dst` 在维度 `dim` 的大小 |\n",
      "| `ctx.set_src_dim_size(dim, size)`               | 设置 `src` 在维度 `dim` 的大小 |\n",
      "| `ctx.set_total_size(size)`                      | 设置整体大小，常用于 memcpy      |\n",
      "| `ctx.set_transpose_layout(layout)`              | 设置转置的 `layout`         |\n",
      "| `ctx.set_pad_config(pad_low, pad_high, ad_mid)` | 设置 pad 参数              |\n",
      "\n",
      "##### 启动和同步接口\n",
      "\n",
      "* **启动接口（配置与启动分离时使用）：**\n",
      "\n",
      "| 接口                       | 描述                     |\n",
      "| ------------------------ | ---------------------- |\n",
      "| `ctx.trigger()`          | 触发 DTE 操作，返回一个 `event` |\n",
      "| `ctx.trigger_and_wait()` | 触发 DTE 操作并等待完成         |\n",
      "\n",
      "* **同步接口：**\n",
      "\n",
      "| 接口            | 描述              |\n",
      "| ------------- | --------------- |\n",
      "| `wait(event)` | 等待指定 `event` 完成 |\n",
      "\n",
      "##### 配置和启动合并接口\n",
      "\n",
      "在接口中，ctx参数是指定DTE上下文，dst是mdspan指定的数据搬运的输出位置，src是mdspan指定的数据搬运的输入位置。\n",
      "使用下列函数可同时完成配置和启动，均支持九种数据类型，并提供 `_async` 后缀的异步版本：\n",
      "\n",
      "| 接口                                                                | 描述                                       |\n",
      "| ----------------------------------------------------------------- | ---------------------------------------- |\n",
      "| `tops::memcpy(ctx, dst, src)`                                     | 以 `src` 总大小拷贝 `src` 到 `dst`              |\n",
      "| `tops::memset(ctx, dst, const_value)`                             | 将 `dst` 指定的内存设置为 `const_value`           |\n",
      "| `tops::slice(ctx, dst, src, offset)`                              | 按 `dst` 形状和 `offset` 从 `src` 拷贝数据到 `dst` |\n",
      "| `tops::deslice(ctx, dst, src, offset)`                            | 把 `src` 数据拷贝并覆盖到 `dst` 指定位置              |\n",
      "| `tops::transpose(ctx, dst, src, layout)`                          | 按 `layout` 转置 `src` 并拷贝至 `dst`           |\n",
      "| `tops::slice_transpose(ctx, dst, src, offset, layout)`            | 先切片再转置再拷贝至 `dst`                         |\n",
      "| `tops::transpose_deslice(ctx, dst, src, offset, layout)`          | 先转置再覆盖到 `dst`                            |\n",
      "| `tops::pad(ctx, dst, src, pad_low, pad_high, pad_mid, pad_value)` | 按形状填补并拷贝至 `dst`                          |\n",
      "| `tops::mirror_tb(ctx, dst, src)`                                  | 第一维翻转并拷贝至 `dst`                          |\n",
      "| `tops::mirror_lr(ctx, dst, src)`                                  | 第二维翻转并拷贝至 `dst`                          |\n",
      "| `tops::broadcast(ctx, dst, src)`                                  | 按维度变化扩展 `src` 并拷贝至 `dst`                 |\n",
      "\n",
      "##### DTE 软件流水编程\n",
      "\n",
      "使用异步编程接口可以完成数据流的软件流水，把计算和数据搬运的并行起来，从而达到更好的计算性能。\n",
      "代码：计算和数据搬运流水并行示例代码\n",
      "\n",
      "```c\n",
      "    tops_dte_ctx_t ctxs[2][2];\n",
      "    tops::event evs[2][2];\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        for (int j = 0; j < 2; j++)\n",
      "            ctxs[i][j].init();\n",
      "\n",
      "    __aligned__ int input_buffer[2][tile_size];\n",
      "    __aligned__ int output_buffer[2][tile_size];\n",
      "\n",
      "    tops::mdspan input(tops::Global, in, tile_size);  // in 为 L3 指针\n",
      "    tops::mdspan output(tops::Global, out, tile_size); // out 为 L3 指针\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        ctxs[0][i].config_memcpy(tops::mdspan(tops::Private,\n",
      "                               input_buffer[i], tile), input, tile_size);\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        ctxs[1][i].config_memcpy(output,\n",
      "                               tops::mdspan(tops::Private, output_buffer[i], tile), tile_size);\n",
      "\n",
      "    evs[0][0] = ctxs[0][0].trigger();\n",
      "    int iter = 0;\n",
      "\n",
      "    for (int i = 0; i < size; i += tile_size) {\n",
      "        evs[0][iter%2].wait();\n",
      "        if (i + tile_size < size) {\n",
      "            ctxs[0][(iter+1)%2].set_src_addr(in + i);\n",
      "            evs[0][(iter+1)%2] = ctxs[0][(iter+1)%2].trigger();\n",
      "        }\n",
      "\n",
      "        // do computation\n",
      "        foo(input_buffer[iter%2], output_buffer[iter%2]);\n",
      "\n",
      "        if (i != 0) {\n",
      "            evs[1][(iter-1)%2].wait();\n",
      "        }\n",
      "        ctxs[1][iter%2].set_dst_addr(output + i);\n",
      "        evs[1][iter%2] = ctxs[1][iter%2].trigger();\n",
      "        if (i + tile_size >= size) {\n",
      "            evs[1][iter%2].wait();\n",
      "        }\n",
      "        iter++;\n",
      "    }\n",
      "\n",
      "    for (int i = 0; i < 2; i++)\n",
      "        for (int j = 0; j < 2; j++)\n",
      "            ctxs[i][j].destroy();\n",
      "```\n",
      "\n",
      "默认情况下，DTE 的非法行为不会报错，加上宏 -DTOPS_ENABLE_DTE_CHECK 会检查非法行为。\n",
      "\n",
      "#### 3.2.4.2 计算流程编程\n",
      "\n",
      "一般地，topscc 支持标量计算。计算只能发生在线程内部，且从 L1 中读取数据。对于 L1 的地址，可以直接使用下标索引数据。\n",
      "\n",
      "```c\n",
      "    __aligned__ int inp[128];\n",
      "    __aligned__ int out[128];\n",
      "    for (size_t i = 0; i < 128; ++i) {\n",
      "        out[i] = inp[i] * inp[i];\n",
      "    }\n",
      "```\n",
      "\n",
      "此外，TopsCC 提供了向量接口和矩阵计算接口，以利用 GCU 的 1D 和 2D 算力。\n",
      "\n",
      "##### 1D 计算流编程\n",
      "\n",
      "一个 `vector` 类型默认长度为 **128** 字节，支持的 `vector` 类型如下所示。\n",
      "\n",
      "###### 表 3-7 支持的 `vector` 类型\n",
      "\n",
      "| 类型        | 说明                    | 默认的元素个数                                   |\n",
      "| --------- | --------------------- | ----------------------------------------- |\n",
      "| `vchar`   | `char` 向量类型           | 一个 `vchar` 向量包含 **128** 个 `int8_t`        |\n",
      "| `vuchar`  | `unsigned char` 向量类型  | 一个 `vuchar` 向量包含 **128** 个 `uint8_t`      |\n",
      "| `vshort`  | `short` 向量类型          | 一个 `vshort` 向量包含 **64** 个 `int16_t`       |\n",
      "| `vushort` | `unsigned short` 向量类型 | 一个 `vushort` 向量包含 **64** 个 `uint16_t`     |\n",
      "| `vint`    | `int` 向量类型            | 一个 `vint` 向量包含 **32** 个 `int`             |\n",
      "| `vuint`   | `unsigned int` 向量类型   | 一个 `vuint` 向量包含 **32** 个 `unsigned int`   |\n",
      "| `vfloat`  | `float` 向量类型          | 一个 `vfloat` 向量包含 **32** 个 `float`         |\n",
      "| `vhalf`   | `half` 向量类型           | 一个 `vhalf` 向量包含 **64** 个 `tops::half`     |\n",
      "| `vbfloat` | `bfloat` 向量类型         | 一个 `vbfloat` 向量包含 **64** 个 `tops::bfloat` |\n",
      "\n",
      "> 支持的 `vector` 操作包括：\n",
      "\n",
      "###### 表 3-8 支持的 `vector` 操作（I）\n",
      "\n",
      "| 接口           | 描述                                                                                       |\n",
      "| ------------ | ---------------------------------------------------------------------------------------- |\n",
      "| `vload`      | 从指定地址开始读取一个向量数据。`vload` 访问的地址需要对齐，即需要用 `__aligned__` 修饰。例如：`auto v = vload<vint>(addr);` |\n",
      "| `vstore`     | 存储一个向量数据到某个指定地址。例如：`vstore(value, addr);`                                                |\n",
      "| `vlength`    | 根据给定的数据类型，返回对应的 `vector` 计算所支持的向量长度。例如：`__aligned__ int buf[tops::vlength<vint>()]`      |\n",
      "| `vzero`      | 返回一个向量，所有值都设置为 `0`                                                                       |\n",
      "| `vadd`       | 返回两个向量的和。例如：`vint sum = tops::vadd(lhs, rhs)`                                            |\n",
      "| `vsub`       | 返回两个向量的差。例如：`vint diff = tops::vsub(lhs, rhs)`                                           |\n",
      "| `vmul`       | 返回两个向量的乘积。例如：`vint prdt = tops::vmul(lhs, rhs)`                                          |\n",
      "| `vdiv`       | 返回两个向量的商。例如：`vint quot = tops::vdiv(lhs, rhs)`                                           |\n",
      "| `vmod`       | 返回两个向量的模。例如：`vint md = tops::vmod(lhs, rhs)`                                             |\n",
      "| `vrem`       | 返回两个向量的余数。例如：`vint rm = tops::vrem(lhs, rhs)`                                            |\n",
      "| `vsign`      | 返回一个向量中每个元素的“符号”型，正数返回 1，负数返回 −1。例如：`vint sgn = tops::vsign(v)`                          |\n",
      "| `vbroadcast` | 将一个标量的值赋给向量的所有成员。例如：`vint brd = tops::vbroadcast(int2)`                                  |\n",
      "| `vcast`      | 因为向量类型不支持隐式转换，所以可以用这个函数进行**显示类型转换**                                                      |\n",
      "| `vbitcast`   | 将一个向量强制转换为另外一个相同大小的向量。例如：`vchar cv = tops::vbitcast(iv)`                                 |\n",
      "| `vsin`       | 返回一个向量每个元素的正弦，仅支持 `vfloat` 类型。例如：`auto vsn = tops::vsin(fv)`                             |\n",
      "| `vasin`      | 返回一个向量每个元素的反正弦，仅支持 `vfloat` 类型。例如：`auto vasn = tops::vasin(fv)`                          |\n",
      "| `vsinh`  | 返回一个向量每个元素的双曲正弦，仅支持 `vfloat` 类型。例如：`auto vhs = tops::vsinh(fv)`                                               |\n",
      "| `vasinh` | 返回一个向量每个元素的反双曲正弦，仅支持 `vfloat` 类型。例如：`auto vahs = tops::vasinh(fv)`                                            |\n",
      "| `vcos`   | 返回一个向量每个元素的余弦，仅支持 `vfloat` 类型。例如：`auto vcs = tops::vcos(fv)`                                                  |\n",
      "| `vcosh`  | 返回一个向量每个元素的双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhcs = tops::vcosh(fv)`                                              |\n",
      "| `vacos`  | 返回一个向量每个元素的反余弦，仅支持 `vfloat` 类型。例如：`auto vacs = tops::vacos(fv)`                                               |\n",
      "| `vacosh` | 返回一个向量每个元素的反双曲余弦，仅支持 `vfloat` 类型。例如：`auto vhacs = tops::vacosh(fv)`                                           |\n",
      "| `vabs`   | 返回一个向量每个元素的绝对值，仅支持 `vfloat` 类型。例如：`auto vabso = tops::vabs(fv)`                                               |\n",
      "| `vcbrt`  | 返回一个向量每个元素的立方根，仅支持 `vfloat` 类型。例如：`auto vcbr = tops::vcbrt(fv)`                                               |\n",
      "| `vtan`   | 返回一个向量每个元素的正切，仅支持 `vfloat` 类型。例如：`auto vtn = tops::vtan(fv)`                                                  |\n",
      "| `vatan`  | 返回一个向量每个元素的反正切，仅支持 `vfloat` 类型。例如：`auto vatn = tops::vatan(fv)`                                               |\n",
      "| `vatan2` | 将两个向量每个元素分别相除，再对结果进行反正切，仅支持 `vfloat` 类型。例如：`auto vatan2 = tops::vatan2(fv1, fv2)`                             |\n",
      "| `vneg`   | 返回一个向量的符号相反的值，支持所有符号类型。例如：`auto vng = tops::vneg(fv)`                                                         |\n",
      "| `vsqrt`  | 返回一个向量每个元素的平方根，仅支持 `vfloat` 类型。例如：`auto vsqt = tops::vsqrt(fv)`                                               |\n",
      "| `vrsqrt` | 返回一个向量每个元素的**反平方根**，仅支持 `vfloat` 类型。例如：`auto vrsqt = tops::vrsqrt(fv)`                                        |\n",
      "| `vfloor` | 返回一个向量每个元素的**向下取整**（最接近且不大于自身的整数），仅支持 `vfloat` 类型。例如：`auto vflr = tops::vfloor(fv)`                           |\n",
      "| `vceil`  | 返回一个向量每个元素的**向上取整**（最接近且不小于自身的整数），仅支持 `vfloat` 类型。例如：`auto vcl = tops::vceil(fv)`                             |\n",
      "| `vround` | 返回一个向量每个元素**最接近**的整数，仅支持 `vfloat` 类型。例如：`auto vrnd = tops::vround(fv)`                                        |\n",
      "| `vtrunc` | 按截断规则 `trunc(x) = x >= 0 ? floor(x) : ceil(x)` 处理向量每个元素返回，仅支持 `vfloat` 类型。例如：`auto vtrc = tops::vtrunc(fv)`   |\n",
      "| `vrint`  | 和 `vround` 很像，例如把 `x=5.5` 的浮点数，`round` 会处理成 `+1`，`rint` 是 `×`；仅支持 `vfloat` 类型。例如：`auto vri = tops::vrint(fv)` |\n",
      "| `vexp`   | 按输入向量的每个元素作为数学常数 `e` 的指数计算后，返回一个**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto vxp = tops::vexp(fv)`                     |\n",
      "| `vexpm1` | 按输入向量的每个元素作为指数的 **`e^x - 1`** 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxpm = tops::vexpm1(fv)`                |\n",
      "| `vexp2`  | 按输入向量的每个元素为 2 的指数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vxp2 = tops::vexp2(fv)`                              |\n",
      "| `vlog`   | 按输入向量的每个元素为数学常数 `e` 的对数计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg = tops::vlog(fv)`                          |\n",
      "| `vlog1p`    | 按输入向量的每个元素加 1 后作自然对数计算（`log(1+x)`），返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlgp = tops::vlog1p(fv)`                     |\n",
      "| `vlog2`     | 按输入向量的每个元素为 2 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg2 = tops::vlog2(fv)`                                     |\n",
      "| `vlog10`    | 按输入向量的每个元素为 10 的对数计算，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vlg10 = tops::vlog10(fv)`                                  |\n",
      "| `vlogb`     | 按输入向量的每个元素以 10 为底的对数，只保留**整数部分**，并返回**相同类型**向量，仅支持 `vfloat` 类型。例如：`auto v lgb = tops::vlogb(fv)`                    |\n",
      "| `vilogb`    | 按输入向量的每个元素以 10 为底的对数，只保留结果的**整数部分**，并返回一个**整数型**向量，仅支持 `vfloat` 类型。例如：`auto vilgb = tops::vilogb(fv)`               |\n",
      "| `vpower`    | 按第一个输入向量的每个元素为底数、第二个输入向量的对应元素为指数计算，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vpw = tops::vpower(fv1, fv2)`               |\n",
      "| `vgelu`     | 计算输入向量每个元素的高斯误差线性单元，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vglu = tops::vgelu(fv)`                                    |\n",
      "| `vsoftplus` | 按照规则 `vlog(vexp(v)+1)` 计算后，返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vstp = tops::vsoftplus(fv)`                          |\n",
      "| `vsigmoid`  | 计算输入向量每个元素的 Sigmoid 函数，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vsigmoid(fv)`                               |\n",
      "| `vdim`      | 计算第一个输入向量和第二个向量的差值，如果差值是个负数则返回 `0`，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vsm = tops::vdim(fv1, fv2)`                 |\n",
      "| `vhypot`    | 以第一个向量每个元素的直角边，以及第二个向量的对应元素作为第二直角边，计算相应的斜边，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vhypot(fv1, fv2)`    |\n",
      "| `vcopysign` | 以第二个向量的每个元素的符号，作为第一个向量对应元素的符号，并返回一个相同类型向量，仅支持 `vfloat` 类型。例如：`auto vhpt = tops::vcopysign(fv1, fv2)`                |\n",
      "| `visnan`    | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素不是 `NaN`，其它位代表 `NaN`，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visnan(fv)`       |\n",
      "| `visfinite` | 返回一个 `vuint` 的向量，它的元素的值为 `0` 代表输入向量的对应元素是 `NaN` 或者 `INF`，其它代表不是，仅支持 `vfloat` 类型。例如：`auto vnn = tops::visfinite(fv)` |\n",
      "| `vmax`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最大**值组成，支持所有类型。例如：`auto vmx = tops::vmax(v1, v2)`                                      |\n",
      "| `vmin`      | 返回一个向量，该向量中每个元素为两个输入向量相应位置的**最小**值组成，支持所有类型。例如：`auto vmn = tops::vmin(v1, v2)`                                      |\n",
      "| `vand`      | 按照两个输入向量的位计算“与”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vand(v1, v2)`                                              |\n",
      "| `vor`       | 按照两个输入向量的位计算“或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vor(v1, v2)`                                               |\n",
      "| `vxor`      | 按照两个输入向量的位计算“异或”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vxor(v1, v2)`                                             |\n",
      "| `vnot`    | 按照两个输入向量的位计算“非”结果，并返回相同类型的向量，支持所有类型。例如：`auto vrt = tops::vnot(v1, v2)`                                                    |\n",
      "| `vshl`    | 按照向量 `v` 中的每个元素指定的位数，按位向左移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshl(v1, v2)`          |\n",
      "| `vshr`    | 按照向量 `v` 中的每个元素指定的位数，按位向右移动向量 `in` 中对应元素的数值（**保留符号**），并返回相同类型的向量，不支持无符号类型。例如：`auto vrt = tops::vshr(v1, v2)`          |\n",
      "| `vshli`   | 按照参数 `is` 指定的位数，按位向左移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshli(iv, is)`                 |\n",
      "| `vshri`   | 按照参数 `is` 指定的位数，按位向右移动向量 `in` 中对应元素的数值（**不保留符号**），并返回相同类型的向量，仅支持无符号类型。例如：`auto vrt = tops::vshri(iv, is)`                 |\n",
      "| `vselect` | 按照第一个向量每个元素的条件（`0` 代表否），选择第二个向量对应元素（条件为是）或第三个（条件为否），并返回和后两个向量相同的类型的向量，支持所有类型。例如：`auto vsel = tops::vselect(vcnd, v1, v2)` |\n",
      "\n",
      "#### 3.2.4.2 2D 计算流编程\n",
      "\n",
      "（在 2D 计算相关题目里，会在题目说明中提供 2DAPI 使用方法。）\n",
      "\n",
      "#### 3.2.4.3 同步\n",
      "\n",
      "TopsCC 支持 **Block** 内的所有 **Thread** 同步，以及整个 **Grid** 的全局同步。\n",
      "\n",
      "* `__syncthreads`：Block 内所有 Thread 做一次同步。\n",
      "* `__synclockblocks`：Grid 内所有 Thread 做一次同步。\n",
      "\n",
      "> 说明：使用 `__synclockblocks` 的 `kernel` 需必须声明为 `__cooperative__`。\n",
      "\n",
      "### 3.2.5 主机端编程\n",
      "\n",
      "> 注：本次竞赛主要考察设备端编程，主机端编程部分作为参考，帮助参赛者理解主机侧。\n",
      "\n",
      "主机端运行时实现依赖 `TopsRT` 库中，基于 TopsCC 开发的应用程序会动态链接到 `libtopsrt.so`。运行时所有接口都以 `tops` 为命名前缀。运行时主要负责以下类别的管理：\n",
      "\n",
      "* 执行环境：描述了主机运行时的设备管理和初始化过程。\n",
      "* 存储系统：描述了运行时感知的存储管理系统。\n",
      "* 异步并行：描述了在不同层面上如何通过运行时接口实现异步并行。\n",
      "* 多设备：描述了跨多个设备编程时的相关接口行为。\n",
      "\n",
      "#### 3.2.5.1 互斥限制\n",
      "\n",
      "使用 `shared` 类型时，一个 **Block** 中只能有一个 `thread`（对应一个 **SIP**）执行 L3->L2 内存复制。\n",
      "\n",
      "#### 3.2.5.2 存储系统\n",
      "\n",
      "TopsCC 编程模型下假设系统由主机端和设备端组成，二者有独立的存储：**主存**和**设备内存**。Kernel 主要在设备内存中工作，主机运行时需要负责设备内存的**分配、释放、拷贝，以及在主存和设备内存间的数据搬运**。\n",
      "\n",
      "#### 3.2.5.3 设备内存\n",
      "\n",
      "当前设备内存为**线性内存**，内存句柄中仅包含地址信息，不包含维度解释、切片（tiling）等信息。\n",
      "当前设备地址空间为设备物理地址，因此和主机地址空间没有统一。设备地址空间的位宽如下所示：\n",
      "\n",
      "**表 3-9 设备内存**\n",
      "\n",
      "| 设备地址空间位宽 | T20           | i20           |\n",
      "| -------- | ------------- | ------------- |\n",
      "|          | 最大 **40bits** | 最大 **40bits** |\n",
      "\n",
      "线性内存分配在设备地址空间中，并**映射式**地映射到主机地址空间中。每个分配的内存对象可以在主机端通过指针来引用，主机端的指针被包装为运行时的内存对象句柄。而在设备端 **Kernel** 通过设备地址引用内存对象，其表现形式仍为指针。在主机端启动 Kernel 时，会将主机端指针转换为设备端指针，让工作在两个地址空间中的代码可以协同。\n",
      "\n",
      "内存对象通常通过 **topsMalloc()** 分配和 **topsFree()** 释放，数据搬运使用 **topsMemcpy** 接口（如前所述目前 **topsMalloc3D** 和 **topsMallocPitch** 类接口均不支持）。下面代码所示：\n",
      "\n",
      "```cpp\n",
      "#include <stdio.h>\n",
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__global__ void vec_add(int *from, int *to, size_t N)\n",
      "{\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "    __aligned__ int buffer[128];\n",
      "\n",
      "    tops::mdspan buf(tops::Private, &buffer, 128);\n",
      "\n",
      "    for (size_t i = 0; i < N; i += 128) {\n",
      "        tops::mdspan src(tops::Global, from + i, 128);\n",
      "        tops::mdspan dst(tops::Global, to + i, 128);\n",
      "        tops::memcpy(ctx, buf, src);\n",
      "\n",
      "        for (size_t j = 0; j < 128; j += tops::vlength<vint>()) {\n",
      "            const auto &v = tops::vload<vint>(buffer + j);\n",
      "            tops::vstore(tops::vadd<vint>(v, v), buffer + j);\n",
      "        }\n",
      "\n",
      "        tops::memcpy(ctx, dst, buf);\n",
      "    }\n",
      "}\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int *A_d, *C_d;\n",
      "    int *A_h, *C_h;\n",
      "    size_t N = 512;\n",
      "    size_t Nbytes = N * sizeof(int);\n",
      "\n",
      "    A_h = (int*)malloc(Nbytes);\n",
      "    C_h = (int*)malloc(Nbytes);\n",
      "\n",
      "    // Initialize the data.\n",
      "    ...\n",
      "\n",
      "    topsMalloc(&A_d, Nbytes);\n",
      "    topsMalloc(&C_d, Nbytes);\n",
      "\n",
      "    topsMemcpy(A_d, A_h, Nbytes, topsMemcpyHostToDevice);\n",
      "\n",
      "    vec_add<<<1, 1>>>(A_d, C_d, N);\n",
      "\n",
      "    topsMemcpy(C_h, C_d, Nbytes, topsMemcpyDeviceToHost);\n",
      "\n",
      "    topsFree(A_d);\n",
      "    topsFree(C_d);\n",
      "\n",
      "    free(A_h);\n",
      "    free(C_h);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "#### 3.2.5.4 访问主存\n",
      "\n",
      "除设备内存之外，设备也可以访问**问系统主存**，用户需要通过 ``topsMallocHost()`` 分配或 ``topsHostRegister()`` 接口注册分配的系统内存指针。主存同样会被映射到两个地址空间中，并且锁定在物理内存中（**pinned pages**）。\n",
      "\n",
      "设备端对其访问的性能会较低，但会有如下优点：\n",
      "\n",
      "* 可以实现设备端发起的异步数据拷贝从而和 ``Kernel`` 的执行并行。\n",
      "* 映射到设备地址空间后，设备端可以直接访问少量内存拷贝。\n",
      "* 目前在主存和设备内存之间自动迁移的内存对象尚不支持，即 ``topsMallocManaged()`` 当前不可用。\n",
      "\n",
      "#### 3.2.5.5 全局变量\n",
      "\n",
      "主机运行时还可以访问程序中的设备空间全局变量，示例如下：\n",
      "\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops/tops_runtime_api.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__device__ int globalIn[256];\n",
      "__device__ int globalOut[256];\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int data[256] = {0};\n",
      "    int* ptr;\n",
      "\n",
      "    topsMalloc(&ptr, 256 * sizeof(int));\n",
      "\n",
      "    topsMemcpyFromSymbol(data, globalIn, 256 * sizeof(int));\n",
      "\n",
      "    topsMemcpy(ptr, data, 256 * sizeof(int), topsMemcpyHostToDevice);\n",
      "\n",
      "    topsMemcpyToSymbol(globalOut, ptr, 256 * sizeof(int));\n",
      "\n",
      "    topsFree(ptr);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "``topsGetSymbolAddress()`` 可以获取全局变量的内存句柄，``topsGetSymbolSize()`` 可以获取内存对象的大小。\n",
      "\n",
      "#### 3.2.5.6 异步并行\n",
      "\n",
      "TopsRider 提供了一系列 **API**，为各种层级的计算和存储运并行提供支持：\n",
      "\n",
      "* 在主机端的计算\n",
      "* 在设备端的计算\n",
      "* 从主机端向设备搬运数据\n",
      "* 从设备端向主机搬运数据\n",
      "* 在指定设备内搬运数据\n",
      "* 在设备之间搬运数据\n",
      "\n",
      "上述这些任务可以在不同层面并行。\n",
      "\n",
      "##### 主机端和设备端并行\n",
      "\n",
      "主机端通过异步接口将任务下发到设备的队列中，设备执行完毕后会通知主机端（**event**），在此期间设备端可以执行其他任务而不是阻塞等待。设备端支持如下的异步任务：\n",
      "\n",
      "* 启动内核\n",
      "* 内存拷贝\n",
      "* 内存赋值\n",
      "\n",
      "上述任务同样支持对应的同步任务 API。\n",
      "\n",
      "#### 3.2.5.7 多核并行执行\n",
      "\n",
      "在同一个设备上，不同的进程、上下文、线程都可以使用并行下发的方式异步启动内核任务。多个内核使用的资源充足时，它们就会并行调度执行。\n",
      "\n",
      "##### 数据流与计算并行\n",
      "\n",
      "数据通道需要从主存搬运数据到设备内存，经由计算后将结果从设备内存搬回主存，这个过程可以通过**输入、计算、输出**三级流水，在内核逻辑里也有类似的流水并行优化，但是主机端运行时不感知，三者也可以并行执行。\n",
      "\n",
      "##### 数据传输并行\n",
      "\n",
      "在硬件上主数据搬运的带宽通常大于一个，因此输入、输出和设备内的数据搬运经常可以并行，受限于总线带宽和读写口数量，并发数据传输并不总是会获得更好的性能，部分场景下会有较大收益。\n",
      "\n",
      "##### Stream 任务流\n",
      "\n",
      "上述描述的所有并行场景都是通过一种称为 **stream** 的任务流来实现的。**stream** 是一段命令协议包（**command packet**）的序列，命令序列会被设备端按照顺序执行。不同的 stream 中的命令序列的执行顺序则是彼此独立的，可以在多个 stream 之间显式的添加依赖来控制它们执行顺序的关系。同步等待一个 stream 可以保证之前已下发的所有命令全部完成。\n",
      "\n",
      "**1. 创建和销毁**\n",
      "\n",
      "stream 的创建包括构造一个任务流对象以及添加任务流中的任务，例如启动内核、主存与设备内存之间的数据拷贝。下面代码例子中创建了两个 stream 对象并分配了一个映射到设备端的主存中的数组。\n",
      "\n",
      "```cpp\n",
      "topsStream_t stream[2];\n",
      "\n",
      "for (int i = 0; i < 2; ++i)\n",
      "    topsStreamCreate(&stream[i]);\n",
      "\n",
      "float* hostPtr;\n",
      "topsMallocHost(&hostPtr, 2 * size);\n",
      "```\n",
      "\n",
      "每个stream对象负责一个主存到设备内存的数据搬运、一个启动内核操作、一次设备内存到主存的数据搬运\n",
      "\n",
      "```cpp\n",
      "for (int i = 0; i < 2; ++i) {\n",
      "    topsMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,\n",
      "                    size, topsMemcpyHostToDevice, stream[i]);\n",
      "\n",
      "    MyKernel<<<1, 0, stream[i]>>>(\n",
      "        outputDevPtr + i * size, inputDevPtr + i * size, size);\n",
      "\n",
      "    topsMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,\n",
      "                    size, topsMemcpyDeviceToHost, stream[i]);\n",
      "}\n",
      "```\n",
      "\n",
      "两个 stream 都会拷贝自己的一段输入数组 **hostPtr** 到设备内存的 **inputDevPtr** 中，然后调用 **MyKernel()** 处理 **inputDevPtr**，再将结果 **outputDevPtr** 从设备内存中拷贝回 **hostPtr** 的主存里。根据设备的能力，两个 stream 交替或同时执行。\n",
      "\n",
      "用户需要主动销毁 stream 对象。\n",
      "\n",
      "```cpp\n",
      "for (int i = 0; i < 2; ++i)\n",
      "    topsStreamDestroy(stream[i]);\n",
      "```\n",
      "\n",
      "为避免用户阻塞正在执行的 stream，**topsStreamDestroy()** 接口会立即返回，但是 stream 对象和关联的资源会在设备端完成 stream 的执行后才会释放。\n",
      "\n",
      "**2. 默认 stream**\n",
      "\n",
      "用户调用异步任务接口时通常需要传递 **stream** 参数指定任务流。如果用户不指定或者传递空 **stream** 指针，则任务会被发送到**默认 stream** 上，并且按顺序下发顺序保证顺序执行。每个设备拥有一个默认 stream，所有线程在该设备上共享同一个默认 stream。尚不支持多线程下每个线程拥有独立的默认 stream。\n",
      "\n",
      "**3. 显式同步**\n",
      "\n",
      "用户可以主动同步 stream：\n",
      "\n",
      "* `topsDeviceSynchronize()` 会等待当前所有线程的所有 **stream** 全部执行完成。\n",
      "* `topsStreamSynchronize()` 接受一个 **stream** 对象作为参数，等待该 stream 对象上的所有任务都完成。\n",
      "* `topsStreamWaitEvent()` 接受一个 **stream** 和一个 **event** 作为参数，在任务流上构建一个异步等待任务，所有该任务之后下发的任务都会等待 **event** 对应的事件发生后才会继续执行。\n",
      "* `topsStreamQuery()` 供应用程序查询某个 **stream** 里的任务是否已经完成。\n",
      "\n",
      "**4. 隐式同步**\n",
      "\n",
      "不同 **stream** 的命令通常可以并行，暂时没有操作会触发隐含的同步行为。\n",
      "\n",
      "**5. 并发行为**\n",
      "\n",
      "多个 stream 上的命令，其并发行为取决于各自命令所在序列顺序，以及设备对各种类型任务支持的最大并发数量。\n",
      "例如，在设备上如果某个时钟的数据搬运任务的最大并发度是 **1**，那么两个 stream 上的内存拷贝操作将会结构性冒险（**structural hazard**），进而串行执行。运行时未来将提供接口可查询各类型任务当前执行环境下的最大并发度。\n",
      "两个 stream 上的不同类型的任务可以在设备端并发执行。\n",
      "\n",
      "**6. 主机端回调**\n",
      "\n",
      "运行时提供了 `topsStreamAddCallback()` 接口，可以向 stream 中插入一个异步的主机端回调任务，在这个任务之前的所有任务执行完毕后，该任务才会执行。下面例子中 **MyCallback** 函数会在设备内存到主存的数据搬运结束后被执行。\n",
      "\n",
      "```cpp\n",
      "void topsStreamCallback_t MyCallback(topsStream_t stream, topsError_t status, void *data) {\n",
      "    printf(\"inside callback %d\\n\", (size_t)data);\n",
      "}\n",
      "\n",
      "for (size_t i = 0; i < 2; ++i) {\n",
      "    topsMemcpyAsync(devPtrIn[i], hostPtr[i], size, topsMemcpyHostToDevice, stream[i]);\n",
      "\n",
      "    MyKernel<<<1, 1, 0, stream[i]>>>(devPtrOut[i], devPtrIn[i], size);\n",
      "\n",
      "    topsMemcpyAsync(hostPtr[i], devPtrOut[i], size, topsMemcpyDeviceToHost, stream[i]);\n",
      "\n",
      "    topsStreamAddCallback(stream[i], MyCallback, (void*)i);\n",
      "}\n",
      "```\n",
      "\n",
      "在主机端回调任务之后下发到 stream 上的任务不会等待回调函数结束后才执行，而是直接顺序执行。因此如果需要同步阻塞等待的场景，需要主机端使用同步接口例如 `topsStreamSynchronize()` 来实现。\n",
      "\n",
      "**7. Stream 优先级**\n",
      "\n",
      "当前 **stream 不支持优先级** 调度。\n",
      "\n",
      "##### 事件\n",
      "\n",
      "**event** 事件可以用于跟踪设备端异步任务的执行进度，显式同步设备端的多个 **stream**，同步主机端和设备端的任务。事件可以记录在 stream 上；当一个事件完成时，该 stream 上所有处于这个 **event** 前的任务都已经执行完成。默认 **stream** 上的事件发生时，所有 stream 上在这个事件记录之前下发的所有任务都已经执行完成。\n",
      "\n",
      "**创建和销毁：**\n",
      "\n",
      "```cpp\n",
      "topsEvent_t start, stop;\n",
      "\n",
      "topsEventCreate(&start);\n",
      "topsEventCreate(&stop);\n",
      "\n",
      "topsEventDestroy(start);\n",
      "topsEventDestroy(stop);\n",
      "```\n",
      "\n",
      "##### 同步任务调用\n",
      "\n",
      "有一些任务接口是**同步**的，在设备端将任务执行完之前，接口不会返回。可以通过 `topsSetDeviceFlags()` 接口来控制主机端线程此时是让步（yield）、阻塞或是忙等。\n",
      "\n",
      "#### 3.2.5.8 统一地址空间\n",
      "\n",
      "目前 TopsCC 程序尚未实现完整的统一地址空间机制。通过存储管理接口分配的内存对象句柄均为主机端指针，用户程序可以直接对其读写访问。当句柄被传递到接口中使用时，会根据需要将其转换到设备地址空间的指针，用户程序可以直接使用。\n",
      "\n",
      "```cpp\n",
      "__global__ void test(int *ptr)\n",
      "{\n",
      "    printf(\"%lx\\n\", (uint64_t)ptr); // device address pointer\n",
      "}\n",
      "\n",
      "int main(int argc, char *argv[])\n",
      "{\n",
      "    int *data;\n",
      "\n",
      "    topsMalloc(&data, sizeof(int));\n",
      "    *data = 0; // host address pointer\n",
      "\n",
      "    test<<<1, 1>>>(data);\n",
      "\n",
      "    topsFree(data);\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "__device__ extern void foo();\n",
      "\n",
      "__global__ void bar() {\n",
      "    foo();\n",
      "}\n",
      "\n",
      "int main() {\n",
      "    bar<<<1,1>>>();\n",
      "    return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "### 3.4 编程限制汇总\n",
      "\n",
      "#### 3.4.1 编程相关\n",
      "\n",
      "1. **GCU 2.0 不支持全局寻址**。kernel 不能直接访问 `__shared__` 和 `__device__` 地址空间。需要通过 **DTE** 将 `__shared__` 和 `__device__` 地址的内容搬运至 **L1** 进行计算。\n",
      "2. 关于打印功能，在 kernel function 中 **printf** 只支持打印**整型**，不支持 **%s** 和 **%p**。关于地址打印，可以将指针对强制转换成 **long long** 类型。\n",
      "3. 在 **GCU210** 上 **Block dims** 的乘积最大为 **12**，即一个 Block 内**最多开 12 个 Thread**。\n",
      "4. 在 **GCU210** 上 **Grid dims** 的乘积最大为 **2**。\n",
      "5. **GCU 2.0 不允许直接访问 shared memory（L2）**，只能用于 **DTE** 数据搬运操作。动态大小的 shared memory，每个 `__global__` 函数只能使用一个。\n",
      "6. 有关硬件支持 shared memory 的大小限制，**i20** 上每个 Block **最大 share memory 24MB**。\n",
      "7. 当核函数里有 `printf` 或者 `assert` 调用时，runtime 处于 **debug 同步模式**，也就是一个 Stream 上核函数的运行是强制同步的。\n",
      "\n",
      "### 3.4.2 DTE 数据搬运\n",
      "\n",
      "1. 用 `__shared_dte__` 和 `__private_dte__` 声明的 **DTE Context** 只能支持 **Global** 和 **Shared** 之间的数据传输。不加任何修饰符声明的 **DTE Context** 是 **Thread** 私有的 DTE 上下文，支持 **Global、Shared 和 Private** 之间的数据传输。\n",
      "2. 使用 **shared dte** 时，一个 **Block** 中只有一个 **Thread** 可以做 **L3->L2** 或 **L2->L3** 搬运。\n",
      "\n",
      "### 3.5 性能调优指南\n",
      "\n",
      "尽量使用 **DTE 软件流水** 使得**数据搬运**和**计算**可以并行。\n",
      "\n",
      "---\n",
      "\n",
      "# 4 FAQ\n",
      "\n",
      "## 4.1 使用报错信息\n",
      "\n",
      "**Q：** 使用 `mdspan` 时地址空间类型设置错误，可能会引发程序 *hang*。\n",
      "**A：** 检查地址空间类型设置，**L1 内存**地址设置为 `tops::Private`，**L2 内存**地址设置为 `tops::Shared`，**L3 内存**地址设置为 `tops::Global`。\n",
      "示例程序如下：\n",
      "\n",
      "```cpp\n",
      "__global__ void foo(int *arr, int size) {\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "\n",
      "    int buf[size];\n",
      "\n",
      "    tops::mdspan L3(tops::Private, arr, size); // L3 should be set to tops::Global but wrongly set to tops::Private\n",
      "    tops::mdspan L1(tops::Global, buf, size);  // L1 should be set to tops::Private but wrongly set to tops::Global\n",
      "\n",
      "    tops::memcpy(ctx, L1, L3);                 // at this point the program may hang\n",
      "}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**Q：** DTE 未经初始化直接使用，可能会引发程序 *hang*。\n",
      "**A：** 使用 `tops::dte_scope` 或者显式调用 `init` 函数，其中 `tops::dte_scope` 会自动完成 DTE 的初始化操作以及销毁操作；如果显式调用 `init` 函数，在 DTE 使用完成之后**注意调用** `destroy` 函数释放 DTE 资源。\n",
      "示例程序如下：\n",
      "\n",
      "```cpp\n",
      "__global__ void foo() {\n",
      "    int a[32];\n",
      "    int b[32];\n",
      "\n",
      "    tops::mdspan src(tops::Private, a, 32);\n",
      "    tops::mdspan dst(tops::Private, b, 32);\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "\n",
      "    tops::dte_scope s(ctx);       // use tops::dte_scope to initialize dte context\n",
      "    // ctx.init();                // or use init() to initialize dte context\n",
      "\n",
      "    tops::memcpy(ctx, dst, src);  // if dte is uninitialized, the program may hang or abort\n",
      "\n",
      "    // ctx.destroy();             // if use init(), remember to use destroy() to free dte context\n",
      "}\n",
      "```\n",
      "注意DTE 事件等待与地址复用不严，写回被覆盖或遗漏 → 输出出现 0\n",
      "\n",
      "**GCU210（i20）**，忽略 GCU200。并修正术语对齐到 v2（例如对齐修饰符统一为 `__aligned__`）。\n",
      "\n",
      "## 0. 适用范围与术语对齐\n",
      "- **芯片/平台**：GCU210（i20）。\n",
      "- **地址空间修饰**（与 v2 保持一致）：\n",
      "  - `tops::Global` ↔ L3（设备全局存储）\n",
      "  - `tops::Shared` ↔ L2（簇共享存储，**仅 DTE 通道**）\n",
      "  - `tops::Private` ↔ L1（SIP 私有存储，**可计算**）\n",
      "- **对齐修饰**：统一使用 `__aligned__`（v1 中出现的 `__valigned__` 系误写，按 v2 规范更正为 `__aligned__`）。\n",
      "---\n",
      "\n",
      "## 1. v2 未覆盖/强调不够的 **高层算子框架 API**\n",
      "> 这些 API 在 v1 被反复提及，但 v2 未系统收录；可显著简化典型“搬运→计算→写回”的模板代码。\n",
      "\n",
      "### 1.1 Elementwise（逐元素）框架\n",
      "- **场景**：在 L3 张量上执行逐元素函数（自动以 tile 方式搬运至 L1，再执行）。\n",
      "- **核心接口**（设备端）：\n",
      "  ```cpp\n",
      "  #include <tops/elemwise.h>\n",
      "\n",
      "  // 在 Kernel 内部直接调用\n",
      "  tops::elemwise_kernel(\n",
      "      [] __device__(auto &out, auto &in) {\n",
      "          out = in * in;  // 在 L1 上的逐元素操作\n",
      "      },\n",
      "      N,                          // 总元素个数\n",
      "      tops::Input(0), in_ptr,     // 输入\n",
      "      tops::Output(0), out_ptr    // 输出\n",
      "  );\n",
      "  ```\n",
      "- **变体/控制**：`elemwise_tiles`（按 tile 粒度自定义）、`elemwise_local`（已在 L1 的缓冲上直接算）。\n",
      "- **优势**：自动封装 DTE 切片/回写与对齐处理，减少手写样板代码。\n",
      "\n",
      "### 1.2 Reduction（归约）框架\n",
      "- **场景**：对张量做加/最大/最小等归约（可从 L3 直接发起或在 L1 上本地归约）。\n",
      "- **核心接口**（设备端，示例）：\n",
      "  ```cpp\n",
      "  #include <tops/reduction.h>\n",
      "\n",
      "  // kernel 级：从 L3 发起（内部自动搬运）\n",
      "  tops::reduction_kernel(\n",
      "      [] __device__(auto &acc, auto &x) {\n",
      "          acc = __reduction_add(acc, x);\n",
      "      },\n",
      "      out_ptr, out_shape,          // 归约输出\n",
      "      in_ptr,  in_shape,           // 归约输入\n",
      "      /*identity*/ 0               // 加法幺元\n",
      "  );\n",
      "\n",
      "  // local 级：对已在 L1 的缓冲做归约\n",
      "  tops::reduction_local(\n",
      "      [] __device__(auto &acc, auto &x) {\n",
      "          acc = __reduction_max(acc, x);\n",
      "      },\n",
      "      out_L1, in_L1\n",
      "  );\n",
      "  ```\n",
      "- **内置运算符**：`__reduction_add / __reduction_max / __reduction_min`。\n",
      "- **注意**：默认归约维度常为“中间维”，需与 `in_shape/out_shape` 对齐。\n",
      "\n",
      "### 1.3 Select / Broadcast 等辅助算子\n",
      "- **条件选择**：\n",
      "  ```cpp\n",
      "  #include <tops/select.h>\n",
      "  tops::select_kernel(\n",
      "      [] __device__(auto &o, auto &lhs, auto &rhs, auto &cond) {\n",
      "          o = cond ? lhs : rhs;\n",
      "      },\n",
      "      size, tops::Input(0), lhs, tops::Input(1), rhs, tops::Input(2), cond,\n",
      "      tops::Output(0), out\n",
      "  );\n",
      "  ```\n",
      "- **按维广播**：\n",
      "  ```cpp\n",
      "  #include <tops/broadcast.h>\n",
      "  tops::broadcast_in_dim(out, in, dim0, dim1, /*broadcast_dim*/1, /*bsize*/k);\n",
      "  ```\n",
      "\n",
      "> 这些高层 API 有助于**标准化**常见套路；v2 可在“3.2.4 设备端编程”后追加“高层封装”小节引入。\n",
      "\n",
      "---\n",
      "\n",
      "## 2. DTE 进阶：链式/异步流水的细节补全\n",
      "v2 已介绍同步/异步与软件流水；v1 另强调了“**多 DTE 上下文链式**”与若干 **易错点**：\n",
      "\n",
      "### 2.1 dte_chain（多上下文串联）\n",
      "```cpp\n",
      "// 伪头文件名，实际以你环境为准：\n",
      "#include <tops/dte_chain.h>\n",
      "\n",
      "tops_dte_ctx_t ctxA, ctxB;\n",
      "ctxA.init(); ctxB.init();\n",
      "\n",
      "auto chain = tops::dte_chain(ctxA, ctxB);\n",
      "chain.connect(...);               // 配置 A→B 的数据流\n",
      "chain.trigger();                  // 触发\n",
      "chain.wait();                     // 等待完成\n",
      "\n",
      "ctxB.destroy(); ctxA.destroy();\n",
      "```\n",
      "> 适合 **L3→L1→L3** 的双向搬运在不同 ctx 上交错、做更深流水。若你当前环境无 `dte_chain` 头（SDK 版本差异），可用**手动双 ctx + event** 等价实现（v2 已给出）。\n",
      "\n",
      "### 2.2 `slice_async` 签名易错\n",
      "- **正确**：必须给 **offset**（至少 4 参起），例如：\n",
      "  ```cpp\n",
      "  auto ev = tops::slice_async(ctx, dst_md, src_md, /*offset*/ {x0, y0, z0});\n",
      "  tops::wait(ev);\n",
      "  ```\n",
      "- **错误**：`slice_async(ctx, dst, src)`（少 offset）会编译/链接失败。\n",
      "\n",
      "### 2.3 `_async` 返回 `tops::event`\n",
      "- 只有带 `_async` 的接口返回 `tops::event`；**无后缀**版本为 `void`。\n",
      "- 典型易错：\n",
      "  ```cpp\n",
      "  // 错误：同步接口赋给 event\n",
      "  tops::event ev = tops::transpose_deslice(...); // ❌ 返回 void\n",
      "  // 正确：\n",
      "  tops::event ev = tops::transpose_deslice_async(...);\n",
      "  tops::wait(ev);\n",
      "  ```\n",
      "\n",
      "### 2.4 开发期健壮性\n",
      "- 建议全程开启：`-DTOPS_ENABLE_DTE_CHECK`（越界/地址空间不一致更早暴露）。\n",
      "- **地址空间配置**一旦写错（如把 L3 标成 `tops::Private`），现象多为 **hang** 而非报错。\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 向量工具与类型映射（补充）\n",
      "v2 列了大量向量算子，但 **类型映射/广播**在 v1 有更集中提示：\n",
      "\n",
      "- **固定向量宽**：128B；`vfloat`=32×`float`，`vhalf`=64×`tops::half`，`vbfloat`=64×`tops::bfloat`，…\n",
      "- **从标量到向量类型**：\n",
      "  ```cpp\n",
      "  // 由标量类型 T 查到对应的 vector 类型：\n",
      "  using V = typename tops::scalar2vector<float>::type; // -> vfloat\n",
      "  ```\n",
      "- **标量广播到向量**：\n",
      "  ```cpp\n",
      "  auto v = tops::vbroadcast(3.14f);      // vfloat\n",
      "  auto h = tops::vbroadcast(tops::half(1));\n",
      "  ```\n",
      "- **对齐与边界**：仅在**完全对齐且长度是 vlength<T> 的倍数**时用 `vload/vstore`，否则走标量尾。\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 调试/运行时补遗（v1 独有要点）\n",
      "- **printf/assert 导致同步**：kernel 内使用 `printf/assert` 会让 runtime 进入**调试同步模式**（同一 stream 强制同步），用于排错可以，但性能测试前务必移除。v2 有提及，但建议在“性能调优”再次**加粗提醒**。\n",
      "- **不存在 API 的“想当然命名”**：\n",
      "  - 如 `tops::reduce_add / tops::vreduce_add` **不存在**；应使用前述 **reduction** 框架或自己展开。\n",
      "- **评测/比赛环境可能禁用**某些 API：如把 `topsMalloc/topsFree` 宏重定向为 `_topsMalloc_disabled`。**算子实现不要私自设备端分配临时 L3**，尽量用 L1 缓冲或由上层传入。\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 典型模板（v1 风格，按 v2 术语修正）\n",
      "\n",
      "### 5.1 元素算子（完整可嵌入）\n",
      "```cpp\n",
      "#include <tops/elemwise.h>\n",
      "\n",
      "__global__ void square_kernel(float *out, const float *in, int N) {\n",
      "    // 自动按 tile 从 L3 → L1，L1 上逐元素操作，再写回\n",
      "    tops::elemwise_kernel(\n",
      "        [] __device__(auto &o, auto &x) {\n",
      "            o = x * x;\n",
      "        },\n",
      "        N,\n",
      "        tops::Input(0),  in,\n",
      "        tops::Output(0), out\n",
      "    );\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.2 手写 Tile + SIMD（与 v2 一致但给出“边界回退”套路）\n",
      "```cpp\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "__global__ void vec_add(float *a, float *b, float *c, int N) {\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope s(ctx);\n",
      "\n",
      "    constexpr int TILE = 128;                         // 对齐 128B\n",
      "    __aligned__ float buf_a[TILE], buf_b[TILE], buf_c[TILE];\n",
      "\n",
      "    tops::mdspan A_L1(tops::Private, buf_a, TILE);\n",
      "    tops::mdspan B_L1(tops::Private, buf_b, TILE);\n",
      "    tops::mdspan C_L1(tops::Private, buf_c, TILE);\n",
      "\n",
      "    for (int i = 0; i < N; i += TILE) {\n",
      "        int n = min(TILE, N - i);\n",
      "\n",
      "        tops::memcpy(ctx, A_L1, tops::mdspan(tops::Global, a + i, n));\n",
      "        tops::memcpy(ctx, B_L1, tops::mdspan(tops::Global, b + i, n));\n",
      "\n",
      "        int j = 0;\n",
      "        // 向量快路径\n",
      "        for (; j + tops::vlength<vfloat>() <= n; j += tops::vlength<vfloat>()) {\n",
      "            auto va = tops::vload<vfloat>(buf_a + j);\n",
      "            auto vb = tops::vload<vfloat>(buf_b + j);\n",
      "            auto vc = tops::vadd(va, vb);\n",
      "            tops::vstore(vc, buf_c + j);\n",
      "        }\n",
      "        // 边界标量路径\n",
      "        for (; j < n; ++j) buf_c[j] = buf_a[j] + buf_b[j];\n",
      "\n",
      "        tops::memcpy(ctx, tops::mdspan(tops::Global, c + i, n), C_L1);\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.3 归约（加和）示例\n",
      "```cpp\n",
      "#include <tops/reduction.h>\n",
      "\n",
      "__global__ void sum_kernel(float *out, const float *in, int N) {\n",
      "    // 对 1D 数组做加和，identity=0\n",
      "    tops::reduction_kernel(\n",
      "        [] __device__(auto &acc, auto &x) { acc = __reduction_add(acc, x); },\n",
      "        out, /*out_shape*/ N,\n",
      "        in,  /*in_shape*/  N,\n",
      "        0\n",
      "    );\n",
      "}\n",
      "```\n",
      "\n",
      "### 5.4 GEMM 的“稳妥输出路径”提示\n",
      "- 若使用 `tops::transpose_deslice_async` 复杂组合在大规模/动态 tile 下出现偶发误差，**保守做法**：\n",
      "  1) 在 L1 计算出 `C`；\n",
      "  2) 需要转置的场景，**手工在 L1 做转置**到 `C_T`；\n",
      "  3) 用普通 `deslice` 写回 L3。  \n",
      "  实测该路径最稳，代价是多一次 L1 遍历。\n",
      "\n",
      "---\n",
      "\n",
      "## 6. GCU210 资源/并发提醒（与 v2 对齐但再次明确）\n",
      "- **Block 线程总数 ≤ 12**（`blockDim.x * blockDim.y * blockDim.z ≤ 12`）。\n",
      "- **Cooperative Kernel**：grid 总块数 ≤ `multiProcessorCount`（i20 为 **2**）。\n",
      "- **向量化前提**：所有参与 `vload/vstore` 的 L1 缓冲必须 `__aligned__`，且访问地址/长度满足 128B 自然对齐与 `vlength<T>` 整倍数。\n",
      "\n",
      "---\n",
      "\n",
      "## 7. MLP/激活实现的“一致性与稳定性”建议（补充条）\n",
      "> 与 v2 的一般指南不冲突，这里收拢为 **可复制到算子说明** 的检查清单：\n",
      "\n",
      "- **公式一致化**：向量与标量路径使用**同一**数学表达式（如 SiLU 用 `x/(1+exp(-x))`，向量用 `vexp/vdiv`，标量尾用 `exp/`相同公式）。\n",
      "- **边界一致性**：仅“完全对齐”时走向量路径；其余统一走**标量尾**，避免出现微妙的数值分歧。\n",
      "- **累加稳态化**：长链路加法用 **Kahan** 补偿或配对求和，固定加法顺序；批量/并行度变化后需重跑精度回归。\n",
      "- **可切换模式**：保留 `--precise / --fast` 两种路径开关，便于在评测与上线间切换。\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 常见陷阱对照表（v1 特有案例）\n",
      "| 症状 | 可能根因 | 解决方案 |\n",
      "|---|---|---|\n",
      "| kernel 无响应（hang） | DTE 未 init；mdspan 地址空间写错；对齐不足的 vload | 用 `tops::dte_scope`；开启 `-DTOPS_ENABLE_DTE_CHECK`；边界走标量 |\n",
      "| “把 void 当 event” 编译错 | 使用了同步 API 却当作 `_async` 用 | 仅 `_async` 返回 `tops::event`；用 `tops::wait` 同步 |\n",
      "| `slice_async` 参数不匹配 | 遗漏 `offset` | 使用 `slice_async(ctx, dst, src, {offset...})` |\n",
      "| 运行慢/卡住 | kernel 内 `printf/assert` | 调试阶段可用，性能测试前务必移除 |\n",
      "| 链接/编译异常 | 使用被评测环境禁用的分配 API | 不在设备端私自分配 L3；通过 L1 缓冲或调用方传入 |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. 集成方式建议（如何合入 v2）\n",
      "- 在 **3.2.4 设备端编程** 后增设小节 **“高层算子封装（Elementwise / Reduction / Select / Broadcast）”**。\n",
      "- 在 **DTE 软件流水** 小节追加 **dte_chain/多 ctx 提示** 与 `_async`/`void` 返回值区别示例。\n",
      "- 在 **性能与正确性** 小节集中强调：`__aligned__`、边界标量尾、一致公式、`-DTOPS_ENABLE_DTE_CHECK`。\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "### 1) 内建编译期宏（**新**）\n",
      "- `__TOPS_DEVICE_COMPILE__`：设备端编译时定义（便于区分 host/device 代码路径）。  \n",
      "- `__GCU_ARCH__`：三位数字的架构码：`S60=300, T20=200, i20=210`。  \n",
      "  典型用法（按架构走不同实现）：\n",
      "```cpp\n",
      "#if defined(__TOPS_DEVICE_COMPILE__)\n",
      "  #if __GCU_ARCH__ >= 210\n",
      "    // i20 (GCU210) 专用路径\n",
      "  #else\n",
      "    // 其他架构路径\n",
      "  #endif\n",
      "#endif\n",
      "```\n",
      "\n",
      "### 2) 设备/并发属性查询与 cooperative 约束（**更细化**）\n",
      "- `topsGetDeviceProperties` 可取：  \n",
      "  - `multiProcessorCount`：**GCU210 = 2**  \n",
      "  - `maxThreadsPerMultiProcessor`：**GCU210 = 12**（即 Block 维度乘积最大 12）\n",
      "- cooperative kernel：**GCU210 上 Grid 维度乘积 ≤ 2**；且 Grid 总大小 ≤ `multiProcessorCount`。\n",
      "```cpp\n",
      "topsDeviceProp_t prop; int dev=0;\n",
      "topsGetDeviceProperties(&prop, dev);\n",
      "// 验证 GCU210 限制：\n",
      "assert(prop.multiProcessorCount == 2);\n",
      "dim3 block(prop.maxThreadsPerMultiProcessor, 1, 1); // 12\n",
      "// cooperative 启动前自检：\n",
      "auto gridProd = 2u; // 例如 dim3(2,1,1)\n",
      "assert(gridProd <= 2 && gridProd <= (unsigned)prop.multiProcessorCount);\n",
      "```\n",
      "\n",
      "### 3) 存储/寻址与容量（**细化 i20 数据**）\n",
      "- **GCU 2.0 不支持全局寻址**：L2/L3 仅能经 DTE 搬运；计算只能直接访问 L1（私有）与 `__constant__`。  \n",
      "- **共享内存上限**：**i20 = 24 MB**（动态 shared 每个 `__global__` 仅 1 个声明）。  \n",
      "- **设备内存地址宽度**：i20 **≤ 40 bits**。  \n",
      "- **Host 可用内存**：i20 机型示例：**64 GB**（运行库说明）。  \n",
      "\n",
      "### 4) Host 可见内存（pinned）与直访（**新**）\n",
      "- 通过 `topsMallocHost` 或 `topsHostRegister` 分配/注册 **锁页主存**，可映射到设备地址空间，被设备端直接访问或用于异步拷贝（带宽/延迟逊于设备内存；慎用 write‑combining）。\n",
      "```cpp\n",
      "float* hptr = nullptr;\n",
      "topsMallocHost(&hptr, N * sizeof(float));   // pinned host mem\n",
      "// … 填充 hptr …\n",
      "topsMemcpyAsync(devPtr, hptr, N*sizeof(float), topsMemcpyHostToDevice, stream);\n",
      "// kernel 也可直访 hptr（性能较低，场景化使用）\n",
      "```\n",
      "\n",
      "### 5) 设备端全局变量符号访问（**新**）\n",
      "```cpp\n",
      "__device__ int gIn[256];\n",
      "__device__ int gOut[256];\n",
      "\n",
      "// Host:\n",
      "int h[256] = {0};\n",
      "topsMemcpyFromSymbol(h, gIn, sizeof(h));    // 读设备端全局\n",
      "int* dtmp; topsMalloc(&dtmp, sizeof(h));\n",
      "topsMemcpy(dtmp, h, sizeof(h), topsMemcpyHostToDevice);\n",
      "topsMemcpyToSymbol(gOut, dtmp, sizeof(h));  // 写设备端全局\n",
      "topsFree(dtmp);\n",
      "```\n",
      "\n",
      "### 6) 运行时编译（RTC）与 Module 启动（**新**）\n",
      "- 支持 **运行时编译源代码** → 取回 `code` → `topsModuleLoadData` → `topsModuleLaunchKernel`。\n",
      "```cpp\n",
      "// 省略创建与编译…\n",
      "topsModule_t module; topsFunction_t fn;\n",
      "topsModuleLoadData(&module, code);\n",
      "topsModuleGetFunction(&fn, module, \"vector_square\");\n",
      "struct { topsDeviceptr_t a, b; size_t N; } args{A_d, C_d, N};\n",
      "void* cfg[] = { TOPS_LAUNCH_PARAM_BUFFER_POINTER, &args,\n",
      "                TOPS_LAUNCH_PARAM_BUFFER_SIZE,   (void*)sizeof(args),\n",
      "                TOPS_LAUNCH_PARAM_END };\n",
      "topsModuleLaunchKernel(fn, 1,1,1, 1,1,1, 0, nullptr, nullptr, cfg);\n",
      "```\n",
      "\n",
      "### 7) Stream / Event / 回调（**新**）\n",
      "- **默认 stream**：每设备共用一个（当前未区分线程）；不传入显式 stream 参数则落到默认 stream。  \n",
      "- **显式同步**：`topsDeviceSynchronize()`、`topsStreamSynchronize(s)`；事件依赖：`topsStreamWaitEvent(s, e)`。  \n",
      "- **回调**：可在 stream 完成前序任务后触发主机回调（不会阻塞后续命令排队）。\n",
      "```cpp\n",
      "topsStream_t s[2]; for (int i=0;i<2;++i) topsStreamCreate(&s[i]);\n",
      "// … H2D → Kernel → D2H 的三段流水，各自在 s[i] 上 …\n",
      "void MyCb(topsStream_t, topsError_t, void* tag){ printf(\"cb %ld\\n\",(long)tag); }\n",
      "topsStreamAddCallback(s[0], MyCb, (void*)0L);\n",
      "// 销毁：返回即刻，但资源在设备完成该 stream 后回收\n",
      "for (int i=0;i<2;++i) topsStreamDestroy(s[i]);\n",
      "```\n",
      "\n",
      "### 8) 向量计算接口补全与对齐要求（**新增目录**）\n",
      "- **统一长度 128B** 的向量寄存宽度；`tops::vlength<T>()` 可用于编译期尺寸。  \n",
      "- **`vload` 地址必须 `__valigned__` 对齐到向量宽度**（未对齐会触发 kernel abort，且未必被 host 立即捕获）。\n",
      "- 新增/补全的向量算子（除基本四则外）——示例：\n",
      "```cpp\n",
      "__valigned__ float buf[ tops::vlength<tops::vfloat>() ];\n",
      "auto vf = tops::vload<tops::vfloat>(buf);\n",
      "auto y  = tops::vsigmoid(vf);            // 激活\n",
      "auto g  = tops::vgelu(vf);               // GELU\n",
      "auto e2 = tops::vexp2(vf);               // 2^x\n",
      "auto ln = tops::vlog1p(vf);              // log(1+x)\n",
      "auto h  = tops::vhypot(vf, vf);          // hypot\n",
      "auto m  = tops::vmax(vf, y);             // 按元素最大\n",
      "tops::vstore(m, buf);\n",
      "```\n",
      "> v3 文档枚举了大量 **数学/位运算** 族函数（`vexp/expm1/log/log2/log10/logb/visnan/visfinite/vcopysign/vround/vtrunc/vrint/...` 等）；若 v1/v2 未完整列出，请据需合入“可用向量算子表”。\n",
      "\n",
      "### 9) DTE 接口补全（**更丰富**）\n",
      "- **全量配置**：`config_transpose / config_slice_transpose / config_pad / config_mirror_tb / config_mirror_lr / config_broadcast …`  \n",
      "- **增量配置**：`set_*_addr / set_*_offset / set_*_dim_size / set_total_size / set_transpose_layout / set_pad_config`  \n",
      "- **触发**：`trigger()` 返回 `tops::event`，`trigger_and_wait()` 同步；还有 `_async` 族的复合接口：\n",
      "```cpp\n",
      "tops_dte_ctx_t ctx; ctx.init();\n",
      "auto ev = tops::memcpy_async(ctx, dst, src);\n",
      "tops::wait(ev);\n",
      "ctx.destroy();\n",
      "```\n",
      "- **软件流水模板（双缓冲）**：v3 提供了计算‑搬运并行化的示例骨架，可直接套入 tile‑based 算子（GCU210 适用）。\n",
      "\n",
      "### 10) 同步原语（**小补**）\n",
      "- `__syncthreads()`：Block 内同步。  \n",
      "- `__syncblocks()`：Grid 级同步（Kernel 必须 `__cooperative__`）。\n",
      "\n",
      "\n",
      "### 12) 编程限制 / FAQ（**新增可操作排错点**）\n",
      "- **限制汇总（GCU210 相关）**：\n",
      "  - Block 维度乘积 ≤ **12**；cooperative Grid 维度乘积 ≤ **2**；GridMax：x=65536, y=256, z=256。  \n",
      "  - 动态 shared 每 kernel 仅 1 个；i20 shared 上限 **24MB**。  \n",
      "  - **使用 `shared dte` 时，每 Block 只有 1 个 Thread 能执行 L3↔L2 拷贝**。  \n",
      "  - Kernel 内含 `printf/assert` 时，runtime 进入 **debug 同步模式**（同一 stream 强制顺序执行）。\n",
      "- **常见挂起原因**：\n",
      "  1) `mdspan` 地址空间设置错误（把 L3 标成 `tops::Private` 等）：\n",
      "```cpp\n",
      "// 错误示例：arr 是 L3 指针，却被错误地标成 Private\n",
      "tops::mdspan L3_wrong(tops::Private, arr, size);\n",
      "tops::mdspan L1_wrong(tops::Global,  buf, size);\n",
      "tops::memcpy(ctx, L1_wrong, L3_wrong); // 可能 hang\n",
      "```\n",
      "  2) **DTE 未初始化** 就调用 `tops::*`：用 `tops::dte_scope` 或 `ctx.init()/destroy()` 包裹：\n",
      "```cpp\n",
      "tops_dte_ctx_t ctx;\n",
      "tops::dte_scope scope(ctx);     // 自动 init/destroy\n",
      "// ctx.init(); … tops::memcpy(ctx, …); ctx.destroy();\n",
      "```\n",
      "避免把运行时函数当作编译期常量，并在使用模板函数时显式指定模板参数。\n",
      "注意：凡是 L3/L2 的读写，一律 DTE；只有 L1 的私有缓冲可以随便下标读写。\n",
      "尾块也必须通过 L1→DTE 写回\n",
      "要点速记（别再踩坑版）：\n",
      "绝不直访 L3/L2：GCU2.x kernel 只能直接访问 L1（私有）与 __constant__；__device__/__shared__ 都要经 DTE 先搬到 L1。\n",
      "向量化需要“双重对齐”：不仅数组要 __aligned__，访问起始下标也要向量宽对齐。dilation/stride/padding 下很难保证，因此先用标量路径保正确，再做“对齐块才向量化”的优化。\n",
      "PyTorch 的 Conv2d 是交叉相关（不翻核）。不确定时留一个“翻核开关”宏能一键切换。\n",
      "DTE 先 init 再用，推荐 tops::dte_scope；调试期打开 -DTOPS_ENABLE_DTE_CHECK。\n",
      "printf/assert 会强制同步（同一 stream 串行），性能测试前务必移除。\n",
      "异步/流水：读行→计算→写回可以做双缓冲/事件同步，但每一步都必须通过 DTE。\n",
      "SiLU 里用到的异步策略（能学的点）\n",
      "输入异步 + 双缓冲：memcpy_async(Global→Private) 到 buf0/buf1，用 ev_ld[2] 管理；计算前 wait(ev_ld[cur]) 再读缓冲，避免直访 Global。\n",
      "输出也用了异步：memcpy_async(Private→Global) 写回，用 ev_st[2] 做逐缓冲的“写回事件”，在重用同一缓冲做下一次加载前，先 wait(ev_st[cur])，防止还没写完就被新一轮读取覆盖。\n",
      "事件上限明确：每线程最多同时挂 3 个事件（当前 load 完待算 + 下一 tile 的另一个 load + 当前 store）。代码里在复用前必 wait，保证事件不累积。\n",
      "小任务走同步快路：span <= TILE_TINY 直接 同步搬入 → 向量化计算 → 同步写回，规避小规模下的事件/上下文开销。\n",
      "线程分片均衡：把总量平均分给所有线程（前 rem 个多 1），避免最后几个线程很忙，其他线程都在等，提升并行度。\n",
      "向量化细节完善：VLEN = vlength<vfloat>()，8×/4×/1×展开 + 标量尾部；Sigmoid 走 vsigmoid，并保留 __valigned__ 缓冲对齐，保证 vload/vstore 性能。\n",
      "严格的“先 wait 再用”纪律：任何一次读缓冲或重用缓冲前，一定先 wait 对应事件。\n",
      "双缓冲“计算-预取”流水线：当前 tile 计算，同时后台把下一 tile 异步搬进另一组缓冲。\n",
      "把小任务换成同步路径：小到“异步不划算”的规模，直接同步反而更快更稳。\n",
      "线程数保守：最多 12 线程/块；小 N 时降线程，避免“多线程 + 多事件”造成 DMA 饱和。\n",
      "\n",
      "【当前改进方向】\n",
      "目前可能做异步等能加快，但不一定只局限于这一个\n",
      "下面给两个做的比较好的例子提供借鉴：\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "// 单线程高速路径：更大 tile + 双缓冲 + 4 向量累加（减少依赖链）\n",
      "__global__ void kernel_var_single3(float *inp, float *out, size_t nr_elems) {\n",
      "    if (threadIdx.x != 0) return;\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope scope(ctx);\n",
      "\n",
      "    float var = 0.0f;\n",
      "    if (nr_elems <= 1) {\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Global, out, 1),\n",
      "            tops::mdspan(tops::Private, &var, 1)\n",
      "        );\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    const int VLEN = tops::vlength<vfloat>();   // 32\n",
      "    const int TILE = VLEN * 2048;               // 65536 floats (~256KB) per buffer\n",
      "    __valigned__ float buf0[TILE];\n",
      "    __valigned__ float buf1[TILE];\n",
      "\n",
      "    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\n",
      "    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\n",
      "    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\n",
      "    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\n",
      "    float tail_sum = 0.f, tail_sqs = 0.f;\n",
      "\n",
      "    size_t i = 0;\n",
      "    int cur_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\n",
      "    tops::event ev = tops::memcpy_async(\n",
      "        ctx,\n",
      "        tops::mdspan(tops::Private, buf0, cur_len),\n",
      "        tops::mdspan(tops::Global,  inp + i, cur_len)\n",
      "    );\n",
      "    i += cur_len;\n",
      "    bool use0 = true;\n",
      "\n",
      "    while (true) {\n",
      "        bool has_next = (i < nr_elems);\n",
      "        tops::event ev_next;\n",
      "        int nxt_len = 0;\n",
      "        if (has_next) {\n",
      "            nxt_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\n",
      "            ev_next = tops::memcpy_async(\n",
      "                ctx,\n",
      "                tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\n",
      "                tops::mdspan(tops::Global,  inp + i, nxt_len)\n",
      "            );\n",
      "            i += nxt_len;\n",
      "        }\n",
      "\n",
      "        tops::wait(ev);\n",
      "        float *cur = use0 ? buf0 : buf1;\n",
      "        const int n = cur_len;\n",
      "\n",
      "        int j = 0;\n",
      "        int vec4 = (n / (4*VLEN)) * (4*VLEN);\n",
      "        #pragma unroll 2\n",
      "        for (; j < vec4; j += 4*VLEN) {\n",
      "            auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\n",
      "            auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\n",
      "            auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\n",
      "            auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\n",
      "\n",
      "            vs0 = tops::vadd(vs0, v0);\n",
      "            vs1 = tops::vadd(vs1, v1);\n",
      "            vs2 = tops::vadd(vs2, v2);\n",
      "            vs3 = tops::vadd(vs3, v3);\n",
      "\n",
      "            auto w0 = tops::vmul<vfloat>(v0, v0);\n",
      "            auto w1 = tops::vmul<vfloat>(v1, v1);\n",
      "            auto w2 = tops::vmul<vfloat>(v2, v2);\n",
      "            auto w3 = tops::vmul<vfloat>(v3, v3);\n",
      "\n",
      "            vq0 = tops::vadd(vq0, w0);\n",
      "            vq1 = tops::vadd(vq1, w1);\n",
      "            vq2 = tops::vadd(vq2, w2);\n",
      "            vq3 = tops::vadd(vq3, w3);\n",
      "        }\n",
      "        int vec1 = ((n - j) / VLEN) * VLEN;\n",
      "        for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\n",
      "            auto v = tops::vload<vfloat>(cur + j);\n",
      "            vs0 = tops::vadd(vs0, v);\n",
      "            auto w = tops::vmul<vfloat>(v, v);\n",
      "            vq0 = tops::vadd(vq0, w);\n",
      "        }\n",
      "        for (; j < n; ++j) {\n",
      "            float x = cur[j];\n",
      "            tail_sum += x;\n",
      "            tail_sqs += x * x;\n",
      "        }\n",
      "\n",
      "        if (!has_next) break;\n",
      "        use0 = !use0;\n",
      "        cur_len = nxt_len;\n",
      "        ev = ev_next;\n",
      "    }\n",
      "\n",
      "    auto vs01 = tops::vadd(vs0, vs1);\n",
      "    auto vs23 = tops::vadd(vs2, vs3);\n",
      "    auto vs = tops::vadd(vs01, vs23);\n",
      "\n",
      "    auto vq01 = tops::vadd(vq0, vq1);\n",
      "    auto vq23 = tops::vadd(vq2, vq3);\n",
      "    auto vq = tops::vadd(vq01, vq23);\n",
      "\n",
      "    __valigned__ float tmp[128];\n",
      "    tops::vstore(vs, tmp);\n",
      "    float psum = tail_sum;\n",
      "    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\n",
      "    tops::vstore(vq, tmp);\n",
      "    float psqs = tail_sqs;\n",
      "    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\n",
      "\n",
      "    float Nf = (float)nr_elems;\n",
      "    float mu = psum / Nf;\n",
      "    var = (psqs - mu * psum) / (Nf - 1.0f);\n",
      "    if (var < 0.f && var > -1e-12f) var = 0.f;\n",
      "\n",
      "    tops::memcpy(ctx,\n",
      "        tops::mdspan(tops::Global, out, 1),\n",
      "        tops::mdspan(tops::Private, &var, 1)\n",
      "    );\n",
      "}\n",
      "\n",
      "// 多线程高速路径：12 线程上限，8 路向量累加 + 80KB 双缓冲\n",
      "__global__ void kernel_var_multi8(float *inp, float *out, size_t nr_elems) {\n",
      "    const int tid = threadIdx.x;\n",
      "    const int T   = blockDim.x;\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope scope(ctx);\n",
      "\n",
      "    if (nr_elems <= 1) {\n",
      "        if (tid == 0) {\n",
      "            float zero = 0.0f;\n",
      "            tops::memcpy(ctx,\n",
      "                tops::mdspan(tops::Global, out, 1),\n",
      "                tops::mdspan(tops::Private, &zero, 1)\n",
      "            );\n",
      "        }\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    const size_t elems_per_thread = (nr_elems + (size_t)T - 1) / (size_t)T;\n",
      "    const size_t start = (size_t)tid * elems_per_thread;\n",
      "    size_t end = start + elems_per_thread;\n",
      "    if (end > nr_elems) end = nr_elems;\n",
      "\n",
      "    const int VLEN = tops::vlength<vfloat>();     // 32\n",
      "    const int TILE = VLEN * 640;                  // 20480 floats (~80KB) per buffer\n",
      "    __valigned__ float buf0[TILE];\n",
      "    __valigned__ float buf1[TILE];\n",
      "\n",
      "    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\n",
      "    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\n",
      "    auto vs4 = tops::vzero<vfloat>(), vs5 = tops::vzero<vfloat>();\n",
      "    auto vs6 = tops::vzero<vfloat>(), vs7 = tops::vzero<vfloat>();\n",
      "    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\n",
      "    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\n",
      "    auto vq4 = tops::vzero<vfloat>(), vq5 = tops::vzero<vfloat>();\n",
      "    auto vq6 = tops::vzero<vfloat>(), vq7 = tops::vzero<vfloat>();\n",
      "\n",
      "    float tail_sum = 0.f, tail_sqs = 0.f;\n",
      "\n",
      "    if (start < end) {\n",
      "        size_t i = start;\n",
      "        int cur_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\n",
      "        tops::event ev = tops::memcpy_async(\n",
      "            ctx,\n",
      "            tops::mdspan(tops::Private, buf0, cur_len),\n",
      "            tops::mdspan(tops::Global,  inp + i, cur_len)\n",
      "        );\n",
      "        i += cur_len;\n",
      "        bool use0 = true;\n",
      "\n",
      "        while (true) {\n",
      "            bool has_next = (i < end);\n",
      "            tops::event ev_next;\n",
      "            int nxt_len = 0;\n",
      "            if (has_next) {\n",
      "                nxt_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\n",
      "                ev_next = tops::memcpy_async(\n",
      "                    ctx,\n",
      "                    tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\n",
      "                    tops::mdspan(tops::Global,  inp + i, nxt_len)\n",
      "                );\n",
      "                i += nxt_len;\n",
      "            }\n",
      "\n",
      "            tops::wait(ev);\n",
      "            float *cur = use0 ? buf0 : buf1;\n",
      "            const int n = cur_len;\n",
      "\n",
      "            int j = 0;\n",
      "            const int vec8 = (n / (8*VLEN)) * (8*VLEN);\n",
      "            #pragma unroll 2\n",
      "            for (; j < vec8; j += 8*VLEN) {\n",
      "                auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\n",
      "                auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\n",
      "                auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\n",
      "                auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\n",
      "                auto v4 = tops::vload<vfloat>(cur + j + 4*VLEN);\n",
      "                auto v5 = tops::vload<vfloat>(cur + j + 5*VLEN);\n",
      "                auto v6 = tops::vload<vfloat>(cur + j + 6*VLEN);\n",
      "                auto v7 = tops::vload<vfloat>(cur + j + 7*VLEN);\n",
      "\n",
      "                vs0 = tops::vadd(vs0, v0);\n",
      "                vs1 = tops::vadd(vs1, v1);\n",
      "                vs2 = tops::vadd(vs2, v2);\n",
      "                vs3 = tops::vadd(vs3, v3);\n",
      "                vs4 = tops::vadd(vs4, v4);\n",
      "                vs5 = tops::vadd(vs5, v5);\n",
      "                vs6 = tops::vadd(vs6, v6);\n",
      "                vs7 = tops::vadd(vs7, v7);\n",
      "\n",
      "                auto w0 = tops::vmul<vfloat>(v0, v0);\n",
      "                auto w1 = tops::vmul<vfloat>(v1, v1);\n",
      "                auto w2 = tops::vmul<vfloat>(v2, v2);\n",
      "                auto w3 = tops::vmul<vfloat>(v3, v3);\n",
      "                auto w4 = tops::vmul<vfloat>(v4, v4);\n",
      "                auto w5 = tops::vmul<vfloat>(v5, v5);\n",
      "                auto w6 = tops::vmul<vfloat>(v6, v6);\n",
      "                auto w7 = tops::vmul<vfloat>(v7, v7);\n",
      "\n",
      "                vq0 = tops::vadd(vq0, w0);\n",
      "                vq1 = tops::vadd(vq1, w1);\n",
      "                vq2 = tops::vadd(vq2, w2);\n",
      "                vq3 = tops::vadd(vq3, w3);\n",
      "                vq4 = tops::vadd(vq4, w4);\n",
      "                vq5 = tops::vadd(vq5, w5);\n",
      "                vq6 = tops::vadd(vq6, w6);\n",
      "                vq7 = tops::vadd(vq7, w7);\n",
      "            }\n",
      "\n",
      "            const int vec1 = ((n - j) / VLEN) * VLEN;\n",
      "            for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\n",
      "                auto v = tops::vload<vfloat>(cur + j);\n",
      "                vs0 = tops::vadd(vs0, v);\n",
      "                auto w = tops::vmul<vfloat>(v, v);\n",
      "                vq0 = tops::vadd(vq0, w);\n",
      "            }\n",
      "\n",
      "            for (; j < n; ++j) {\n",
      "                float x = cur[j];\n",
      "                tail_sum += x;\n",
      "                tail_sqs += x * x;\n",
      "            }\n",
      "\n",
      "            if (!has_next) break;\n",
      "            use0 = !use0;\n",
      "            cur_len = nxt_len;\n",
      "            ev = ev_next;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // 合并 8 向量累加器\n",
      "    auto vs01 = tops::vadd(vs0, vs1);\n",
      "    auto vs23 = tops::vadd(vs2, vs3);\n",
      "    auto vs45 = tops::vadd(vs4, vs5);\n",
      "    auto vs67 = tops::vadd(vs6, vs7);\n",
      "    auto vs0123 = tops::vadd(vs01, vs23);\n",
      "    auto vs4567 = tops::vadd(vs45, vs67);\n",
      "    auto vs = tops::vadd(vs0123, vs4567);\n",
      "\n",
      "    auto vq01 = tops::vadd(vq0, vq1);\n",
      "    auto vq23 = tops::vadd(vq2, vq3);\n",
      "    auto vq45 = tops::vadd(vq4, vq5);\n",
      "    auto vq67 = tops::vadd(vq6, vq7);\n",
      "    auto vq0123 = tops::vadd(vq01, vq23);\n",
      "    auto vq4567 = tops::vadd(vq45, vq67);\n",
      "    auto vq = tops::vadd(vq0123, vq4567);\n",
      "\n",
      "    __valigned__ float tmp[128];\n",
      "    tops::vstore(vs, tmp);\n",
      "    float psum = tail_sum;\n",
      "    #pragma unroll\n",
      "    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\n",
      "\n",
      "    tops::vstore(vq, tmp);\n",
      "    float psqs = tail_sqs;\n",
      "    #pragma unroll\n",
      "    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\n",
      "\n",
      "    // 线程间合并：Private -> Shared\n",
      "    extern __shared__ float s_partials[]; // 2*T floats\n",
      "    float pair[2] = {psum, psqs};\n",
      "    tops::memcpy(ctx,\n",
      "        tops::mdspan(tops::Shared,  s_partials + 2*tid, 2),\n",
      "        tops::mdspan(tops::Private, pair, 2)\n",
      "    );\n",
      "\n",
      "    __syncthreads();\n",
      "\n",
      "    if (tid == 0) {\n",
      "        const int n_pairs = 2 * T;\n",
      "        __valigned__ float redbuf[24]; // 支持 T<=12\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Private, redbuf, n_pairs),\n",
      "            tops::mdspan(tops::Shared,  s_partials, n_pairs)\n",
      "        );\n",
      "\n",
      "        float tot_sum = 0.f, tot_sqs = 0.f;\n",
      "        #pragma unroll\n",
      "        for (int k = 0; k < T; ++k) {\n",
      "            tot_sum += redbuf[2*k + 0];\n",
      "            tot_sqs += redbuf[2*k + 1];\n",
      "        }\n",
      "\n",
      "        float Nf = (float)nr_elems;\n",
      "        float mu = tot_sum / Nf;\n",
      "        float var = (tot_sqs - mu * tot_sum) / (Nf - 1.0f);\n",
      "        if (var < 0.f && var > -1e-12f) var = 0.f;\n",
      "\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Global, out, 1),\n",
      "            tops::mdspan(tops::Private, &var, 1)\n",
      "        );\n",
      "    }\n",
      "}\n",
      "\n",
      "void GCU_VAR(float * __restrict dev_inp,\n",
      "             float * __restrict dev_out,\n",
      "             const int nr_elems) {\n",
      "    if (nr_elems <= 1) {\n",
      "        kernel_var_single3<<<dim3(1,1,1), dim3(1,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "        topsError_t e1 = topsGetLastError(); (void)e1;\n",
      "        topsError_t e2 = topsDeviceSynchronize(); (void)e2;\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    // 自适应线程策略：小规模单线程；中规模 4/8 线程；大规模 12 线程\n",
      "    int T = 12;\n",
      "    if (nr_elems < 16384)            { kernel_var_single3<<<dim3(1), dim3(1)>>>(dev_inp, dev_out, (size_t)nr_elems); topsError_t e1 = topsGetLastError(); (void)e1; topsError_t e2 = topsDeviceSynchronize(); (void)e2; return; }\n",
      "    else if (nr_elems < 131072)      T = 4;   // 16K - 128K\n",
      "    else if (nr_elems < 1048576)     T = 8;   // 128K - 1M\n",
      "    else                             T = 12;  // >= 1M\n",
      "\n",
      "    const dim3 grid(1,1,1);\n",
      "    const dim3 block(T,1,1);\n",
      "    const size_t shmem = (size_t)T * 2 * sizeof(float);\n",
      "\n",
      "    kernel_var_multi8<<<grid, block, shmem>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "\n",
      "    topsError_t err = topsGetLastError(); (void)err;\n",
      "    topsError_t sync_err = topsDeviceSynchronize(); (void)sync_err;\n",
      "}\n",
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "// SiLU: y = x * sigmoid(x)\n",
      "__device__ __forceinline__ float silu_scalar(float x) {\n",
      "  return x / (1.0f + expf(-x));\n",
      "}\n",
      "__device__ __forceinline__ vfloat silu_vector(vfloat vx) {\n",
      "  auto vs = tops::vsigmoid(vx);\n",
      "  return tops::vmul<vfloat>(vx, vs);\n",
      "}\n",
      "\n",
      "__device__ __forceinline__ void silu_inplace_vec(float* __restrict buf, int len, const int VLEN) {\n",
      "  int j = 0;\n",
      "  const int vec = (len / VLEN) * VLEN;\n",
      "\n",
      "  // 8x unroll, then 4x, then single, then scalar tail\n",
      "  for (; j + 8*VLEN <= vec; j += 8*VLEN) {\n",
      "    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\n",
      "    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\n",
      "    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\n",
      "    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\n",
      "    auto v4 = tops::vload<vfloat>(buf + j + 4*VLEN);\n",
      "    auto v5 = tops::vload<vfloat>(buf + j + 5*VLEN);\n",
      "    auto v6 = tops::vload<vfloat>(buf + j + 6*VLEN);\n",
      "    auto v7 = tops::vload<vfloat>(buf + j + 7*VLEN);\n",
      "    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\n",
      "    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\n",
      "    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\n",
      "    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\n",
      "    tops::vstore(silu_vector(v4), buf + j + 4*VLEN);\n",
      "    tops::vstore(silu_vector(v5), buf + j + 5*VLEN);\n",
      "    tops::vstore(silu_vector(v6), buf + j + 6*VLEN);\n",
      "    tops::vstore(silu_vector(v7), buf + j + 7*VLEN);\n",
      "  }\n",
      "  for (; j + 4*VLEN <= vec; j += 4*VLEN) {\n",
      "    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\n",
      "    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\n",
      "    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\n",
      "    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\n",
      "    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\n",
      "    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\n",
      "    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\n",
      "    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\n",
      "  }\n",
      "  for (; j + VLEN <= vec; j += VLEN) {\n",
      "    auto vx = tops::vload<vfloat>(buf + j);\n",
      "    tops::vstore(silu_vector(vx), buf + j);\n",
      "  }\n",
      "  for (; j < len; ++j) {\n",
      "    buf[j] = silu_scalar(buf[j]);\n",
      "  }\n",
      "}\n",
      "\n",
      "// Double-buffer async pipeline with balanced thread partition\n",
      "__global__ void kernel_silu_db_opt(float* __restrict inp,\n",
      "                                   float* __restrict out,\n",
      "                                   size_t nr_elems) {\n",
      "  if (nr_elems == 0) return;\n",
      "\n",
      "  // Flattened thread id\n",
      "  const int tpb  = blockDim.x * blockDim.y * blockDim.z;\n",
      "  const int tidb = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * (blockDim.x * blockDim.y);\n",
      "  const int bid  = blockIdx.x + blockIdx.y * gridDim.x + blockIdx.z * (gridDim.x * gridDim.y);\n",
      "  const size_t gid = (size_t)bid * (size_t)tpb + (size_t)tidb;\n",
      "  const size_t T   = (size_t)gridDim.x * gridDim.y * gridDim.z * (size_t)tpb;\n",
      "\n",
      "  if (gid >= T) return;\n",
      "\n",
      "  // Balanced 1D partition: base + first 'rem' threads take one extra\n",
      "  const size_t base = nr_elems / T;\n",
      "  const size_t rem  = nr_elems - base * T;\n",
      "  const size_t start = gid * base + (gid < rem ? gid : rem);\n",
      "  const size_t span  = base + (gid < rem ? 1u : 0u);\n",
      "  if (span == 0) return;\n",
      "  const size_t end = start + span;\n",
      "\n",
      "  const int VLEN = tops::vlength<vfloat>(); // 32 for float (128B)\n",
      "\n",
      "  // Tile policy: choose larger tiles for larger spans to amortize DMA/event overhead\n",
      "  static constexpr int TILE_TINY  = 12288;   // 48KB per buffer (tiny span sync path)\n",
      "  static constexpr int TILE_MID   = 49152;   // 192KB per buffer (double buffer)\n",
      "  static constexpr int TILE_LARGE = 65536;   // 256KB per buffer (double buffer)\n",
      "  const int TILE = (span >= (1u<<20)) ? TILE_LARGE : ((span >= (256u<<10)) ? TILE_MID : 32768);\n",
      "\n",
      "  auto min_int = [](size_t a, size_t b)->int { return (int)(a < b ? a : b); };\n",
      "\n",
      "  // Tiny span path: single sync copy -> compute -> sync copy back\n",
      "  if (span <= (size_t)TILE_TINY) {\n",
      "    __valigned__ float buf[TILE_TINY];\n",
      "    const int len = (int)span;\n",
      "\n",
      "    tops_dte_ctx_t c;\n",
      "    tops::dte_scope s(c);\n",
      "\n",
      "    tops::memcpy(c,\n",
      "      tops::mdspan(tops::Private, buf,         len),\n",
      "      tops::mdspan(tops::Global,  inp + start, len));\n",
      "\n",
      "    silu_inplace_vec(buf, len, VLEN);\n",
      "\n",
      "    tops::memcpy(c,\n",
      "      tops::mdspan(tops::Global,  out + start, len),\n",
      "      tops::mdspan(tops::Private, buf,         len));\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  // Double buffer pipeline\n",
      "  __valigned__ float buf0[TILE_LARGE];\n",
      "  __valigned__ float buf1[TILE_LARGE];\n",
      "\n",
      "  tops_dte_ctx_t ctx_ld[2];\n",
      "  tops_dte_ctx_t ctx_st[2];\n",
      "  tops::dte_scope sld0(ctx_ld[0]), sld1(ctx_ld[1]);\n",
      "  tops::dte_scope sst0(ctx_st[0]), sst1(ctx_st[1]);\n",
      "\n",
      "  tops::event ev_ld[2];\n",
      "  tops::event ev_st[2];\n",
      "  bool has_tile[2]    = {false, false};\n",
      "  bool st_inflight[2] = {false, false};\n",
      "  size_t pos[2]       = {0, 0};\n",
      "  int    len[2]       = {0, 0};\n",
      "\n",
      "  size_t cursor = start;\n",
      "\n",
      "  // Preload buf0, then buf1\n",
      "  pos[0] = cursor;\n",
      "  len[0] = min_int(end - cursor, (size_t)TILE);\n",
      "  if (len[0] > 0) {\n",
      "    ev_ld[0] = tops::memcpy_async(\n",
      "        ctx_ld[0],\n",
      "        tops::mdspan(tops::Private, buf0,        len[0]),\n",
      "        tops::mdspan(tops::Global,  inp + cursor, len[0]));\n",
      "    has_tile[0] = true;\n",
      "    cursor += len[0];\n",
      "  }\n",
      "\n",
      "  pos[1] = cursor;\n",
      "  len[1] = min_int(end - cursor, (size_t)TILE);\n",
      "  if (len[1] > 0) {\n",
      "    ev_ld[1] = tops::memcpy_async(\n",
      "        ctx_ld[1],\n",
      "        tops::mdspan(tops::Private, buf1,        len[1]),\n",
      "        tops::mdspan(tops::Global,  inp + cursor, len[1]));\n",
      "    has_tile[1] = true;\n",
      "    cursor += len[1];\n",
      "  }\n",
      "\n",
      "  int cur = 0;      // buffer to compute\n",
      "  int nxt = 1;      // buffer to compute next\n",
      "\n",
      "  while (has_tile[0] || has_tile[1]) {\n",
      "    if (!has_tile[cur]) { int tmp = cur; cur = nxt; nxt = tmp; }\n",
      "    if (!has_tile[cur]) break;\n",
      "\n",
      "    // Wait load done for current tile\n",
      "    tops::wait(ev_ld[cur]);\n",
      "\n",
      "    // Compute SiLU in-place on L1\n",
      "    float* inout = (cur == 0 ? buf0 : buf1);\n",
      "    silu_inplace_vec(inout, len[cur], VLEN);\n",
      "\n",
      "    // Launch async store for current tile (ensure prior store finished)\n",
      "    if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\n",
      "    ev_st[cur] = tops::memcpy_async(\n",
      "        ctx_st[cur],\n",
      "        tops::mdspan(tops::Global,  out + pos[cur], len[cur]),\n",
      "        tops::mdspan(tops::Private, inout,          len[cur]));\n",
      "    st_inflight[cur] = true;\n",
      "\n",
      "    // Current tile consumed\n",
      "    has_tile[cur] = false;\n",
      "\n",
      "    // Prefetch next tile into 'cur' (the buffer we just stored) if input remains\n",
      "    if (cursor < end) {\n",
      "      // Make sure we don't overwrite while store is still in-flight on 'cur'\n",
      "      if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\n",
      "      pos[cur] = cursor;\n",
      "      len[cur] = min_int(end - cursor, (size_t)TILE);\n",
      "      ev_ld[cur] = tops::memcpy_async(\n",
      "          ctx_ld[cur],\n",
      "          tops::mdspan(tops::Private, (cur == 0 ? buf0 : buf1), len[cur]),\n",
      "          tops::mdspan(tops::Global,  inp + cursor,              len[cur]));\n",
      "      has_tile[cur] = (len[cur] > 0);\n",
      "      cursor += len[cur];\n",
      "    }\n",
      "\n",
      "    // Swap buffers: compute next on 'nxt' if it has a prefetched tile\n",
      "    int tmp = cur; cur = nxt; nxt = tmp;\n",
      "  }\n",
      "\n",
      "  // Drain outstanding stores\n",
      "  if (st_inflight[0]) tops::wait(ev_st[0]);\n",
      "  if (st_inflight[1]) tops::wait(ev_st[1]);\n",
      "}\n",
      "\n",
      "void GCU_SILU(float * __restrict dev_inp,\n",
      "              float * __restrict dev_out,\n",
      "              const int nr_elems) {\n",
      "  if (nr_elems <= 0) return;\n",
      "\n",
      "  // Prefer maximum threads on i20; keep small-N under-subscription to reduce overhead\n",
      "  int threads = 12;\n",
      "  if (nr_elems < 4096)        threads = 1;\n",
      "  else if (nr_elems < 16384)  threads = 4;\n",
      "  else if (nr_elems < 65536)  threads = 8;\n",
      "\n",
      "  // Target per-thread work; larger for large N to amortize kernel/DMA overhead\n",
      "  size_t target_per_thr;\n",
      "  if (nr_elems >= 8*1024*1024)      target_per_thr = 512u * 1024u; // >= 8M\n",
      "  else if (nr_elems >= 1*1024*1024) target_per_thr = 384u * 1024u; // 1M~8M\n",
      "  else if (nr_elems >= 128*1024)    target_per_thr = 256u * 1024u; // 128K~1M\n",
      "  else                              target_per_thr = 128u * 1024u; // <128K\n",
      "\n",
      "  size_t total_thr_need = ((size_t)nr_elems + target_per_thr - 1) / target_per_thr;\n",
      "  if (total_thr_need == 0) total_thr_need = 1;\n",
      "\n",
      "  int blocks = (int)((total_thr_need + threads - 1) / threads);\n",
      "  if (blocks < 1) blocks = 1;\n",
      "  if (blocks > 65535) blocks = 65535;\n",
      "\n",
      "  kernel_silu_db_opt<<<dim3(blocks,1,1), dim3(threads,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "  (void)topsGetLastError();\n",
      "  (void)topsDeviceSynchronize();\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(a[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ded297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-CY7g6m45EAEkJGbwmJCxvTIVGvt9l',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1762248702,\n",
       " 'model': 'gpt-5-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '<candidate>\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n#include <math.h>\\n\\n#define MIN(a,b) (((a)<(b))?(a):(b))\\n\\n// ======= 可调 tile（会按规模自适应收缩，默认偏大，运行时收缩） =======\\n#ifndef K_TILE\\n#define K_TILE   1536\\n#endif\\n#ifndef J_TILE\\n#define J_TILE   768    // 128 的整数倍\\n#endif\\n#ifndef H_TILE\\n#define H_TILE   768\\n#endif\\n#ifndef HCHUNK\\n#define HCHUNK   256    // down 行块更粗，减少 DTE 触发\\n#endif\\n\\n#ifndef USE_KAHAN\\n#define USE_KAHAN 0     // 如需更稳累加：-DUSE_KAHAN=1\\n#endif\\n\\n// 与 CPU 一致的 SiLU\\n__device__ __forceinline__ float silu_scalar(float x) {\\n    return x / (1.f + expf(-x));\\n}\\n\\n// RAII DTE 封装\\nstruct dte_scope {\\n    tops_dte_ctx_t &c;\\n    __device__ dte_scope(tops_dte_ctx_t &ctx) : c(ctx) { c.init(); }\\n    __device__ ~dte_scope() { c.destroy(); }\\n};\\n\\n__global__\\nvoid kernel_mlp_fused_c5_stable(\\n    float *__restrict gate_w,   // [H, I]  row-major\\n    float *__restrict up_w,     // [H, I]  row-major\\n    float *__restrict down_w,   // [I, H]  row-major\\n    float *__restrict inp,      // [S, H]  row-major\\n    float *__restrict out,      // [S, H]  row-major\\n    const int S, const int H, const int I)\\n{\\n    const int tid    = blockIdx.x * blockDim.x + threadIdx.x;\\n    const int stride = gridDim.x  * blockDim.x;\\n    if (stride <= 0) return;\\n\\n    // 动态收缩 tile（L1 粗估限制，给调度/栈留余量）\\n    int kTile = K_TILE, jTile = J_TILE, hTile = H_TILE, hChunk = HCHUNK;\\n    const int VLEN = tops::vlength<vfloat>(); // 32\\n\\n    // 经验阈：控制 float 个数 ~26万以内（≈1MB/4），留足余量\\n    while ((size_t)kTile + (size_t)8*jTile + (size_t)hTile + (size_t)4*hChunk > (size_t)260000) {\\n        if (kTile  > 512) kTile  -= 256;\\n        if (jTile  > 512) jTile  -= 128;\\n        if (hTile  > 512) hTile  -= 128;\\n        if (hChunk > 128) hChunk -=  64;\\n        if (kTile <= 512 && jTile <= 512 && hTile <= 512 && hChunk <= 128) break;\\n    }\\n\\n    // ---------------- DTE 上下文 ----------------\\n    // 输入(K)双缓冲\\n    tops_dte_ctx_t ctx_in[2];\\n    dte_scope s_in0(ctx_in[0]), s_in1(ctx_in[1]);\\n\\n    // gate/up 权重加载（两 ctx 交替），目标缓冲用 set_dst_addr 调整\\n    tops_dte_ctx_t ctx_g[2], ctx_u[2];\\n    dte_scope s_g0(ctx_g[0]), s_g1(ctx_g[1]);\\n    dte_scope s_u0(ctx_u[0]), s_u1(ctx_u[1]);\\n\\n    // down 行块双缓冲（稳定可靠的版本）\\n    tops_dte_ctx_t ctx_dw[2];\\n    dte_scope s_d0(ctx_dw[0]), s_d1(ctx_dw[1]);\\n\\n    // 输出回写\\n    tops_dte_ctx_t ctx_out;\\n    dte_scope s_out(ctx_out);\\n\\n    // ---------------- L1 缓冲（全部 128B 对齐） ----------------\\n    // 输入 K 双缓冲（按最大 kTile 上限分配）\\n    alignas(128) float in0[1536];\\n    alignas(128) float in1[1536];\\n\\n    // gate/up 各自四行权重缓冲（按最大 jTile 上限分配）\\n    alignas(128) float gwr0[1024], gwr1[1024], gwr2[1024], gwr3[1024];\\n    alignas(128) float uwr0[1024], uwr1[1024], uwr2[1024], uwr3[1024];\\n\\n    // 中间累加与激活\\n    alignas(128) float gate_acc[1024];\\n    alignas(128) float up_acc  [1024];\\n    alignas(128) float act_seg [1024];\\n\\n    // 输出片（按最大 hTile 上限）\\n    alignas(128) float out_seg [1024];\\n\\n    // down 行块双缓冲（按最大 hChunk 上限）\\n    alignas(128) float dw0[512], dw1[512];\\n\\n#if USE_KAHAN\\n    alignas(128) float h_sum[512], h_comp[512];\\n#else\\n    alignas(128) float h_sum[512];\\n#endif\\n\\n    for (int m0 = tid; m0 < S; m0 += stride) {\\n        const int m = m0;\\n\\n        for (int h0 = 0; h0 < H; h0 += hTile) {\\n            const int hb = MIN(hTile, H - h0);\\n            for (int h = 0; h < hb; ++h) out_seg[h] = 0.f;\\n\\n            for (int j0 = 0; j0 < I; j0 += jTile) {\\n                const int jb = MIN(jTile, I - j0);\\n                for (int j = 0; j < jb; ++j) { gate_acc[j] = 0.f; up_acc[j] = 0.f; }\\n\\n                // =============== 输入(K)双缓冲：一次 config，多次触发（size 用字节） ===============\\n                tops::event ev_in[2];\\n                bool in_has_ev[2] = {false, false};\\n                int cur = 0, nxt = 1;\\n\\n                ctx_in[0].config_memcpy(\\n                    tops::mdspan(tops::Private, in0, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n                ctx_in[1].config_memcpy(\\n                    tops::mdspan(tops::Private, in1, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n\\n                int k0 = 0;\\n                // 预取 tile0\\n                {\\n                    const int kb0 = MIN(kTile, H - k0);\\n                    if (kb0 > 0) {\\n                        ctx_in[cur].set_src_addr(inp + (size_t)m*H + k0);\\n                        ctx_in[cur].set_total_size(kb0 * sizeof(float)); // 字节数\\n                        ev_in[cur] = ctx_in[cur].trigger();\\n                        in_has_ev[cur] = true;\\n                    }\\n                }\\n\\n                // 预配置 gate/up 的 memcpy 模板（dst 用 set_dst_addr 改到对应缓冲）\\n                ctx_g[0].config_memcpy(tops::mdspan(tops::Private, gwr0, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_g[1].config_memcpy(tops::mdspan(tops::Private, gwr1, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_u[0].config_memcpy(tops::mdspan(tops::Private, uwr0, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n                ctx_u[1].config_memcpy(tops::mdspan(tops::Private, uwr1, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n\\n                while (k0 < H) {\\n                    const int kb_cur = MIN(kTile, H - k0);\\n\\n                    // 预取下一 K-tile\\n                    const int k1 = k0 + kb_cur;\\n                    const int kb_next = MIN(kTile, H - k1);\\n                    if (kb_next > 0) {\\n                        ctx_in[nxt].set_src_addr(inp + (size_t)m*H + k1);\\n                        ctx_in[nxt].set_total_size(kb_next * sizeof(float)); // 字节数\\n                        ev_in[nxt] = ctx_in[nxt].trigger();\\n                        in_has_ev[nxt] = true;\\n                    } else {\\n                        in_has_ev[nxt] = false;\\n                    }\\n\\n                    // 等待当前 K-tile\\n                    if (in_has_ev[cur]) tops::wait(ev_in[cur]);\\n                    float *in_seg = (cur==0?in0:in1);\\n\\n                    // ---- 遍历当前 K-tile（四行一组），gate/up 完全独立缓冲加载与累计 ----\\n                    int kk = 0;\\n                    for (; kk + 3 < kb_cur; kk += 4) {\\n                        const int kA = k0 + kk + 0;\\n                        const int kB = k0 + kk + 1;\\n                        const int kC = k0 + kk + 2;\\n                        const int kD = k0 + kk + 3;\\n\\n                        const float xA = in_seg[kk+0];\\n                        const float xB = in_seg[kk+1];\\n                        const float xC = in_seg[kk+2];\\n                        const float xD = in_seg[kk+3];\\n\\n                        // ---- gate：把四行分别放到 gwr0..gwr3\\n                        tops::event eg0, eg1, eg2, eg3;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kA*I + j0); eg0 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr1);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kB*I + j0); eg1 = ctx_g[1].trigger();\\n                        tops::wait(eg0); tops::wait(eg1);\\n                        ctx_g[0].set_dst_addr(gwr2);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kC*I + j0); eg2 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr3);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kD*I + j0); eg3 = ctx_g[1].trigger();\\n                        tops::wait(eg2); tops::wait(eg3);\\n\\n                        // gate 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                                vfloat g0  = tops::vload<vfloat>(gwr0 + j);\\n                                vfloat g1  = tops::vload<vfloat>(gwr1 + j);\\n                                vfloat g2  = tops::vload<vfloat>(gwr2 + j);\\n                                vfloat g3  = tops::vload<vfloat>(gwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g0, vA), tops::vmul<vfloat>(g1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g2, vC), tops::vmul<vfloat>(g3, vD))\\n                                        ));\\n                                tops::vstore(acc, gate_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                gate_acc[j] += gwr0[j]*xA + gwr1[j]*xB + gwr2[j]*xC + gwr3[j]*xD;\\n                        }\\n\\n                        // ---- up：把四行分别放到 uwr0..uwr3\\n                        tops::event eu0, eu1, eu2, eu3;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kA*I + j0); eu0 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr1);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kB*I + j0); eu1 = ctx_u[1].trigger();\\n                        tops::wait(eu0); tops::wait(eu1);\\n                        ctx_u[0].set_dst_addr(uwr2);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kC*I + j0); eu2 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr3);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kD*I + j0); eu3 = ctx_u[1].trigger();\\n                        tops::wait(eu2); tops::wait(eu3);\\n\\n                        // up 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                                vfloat u0  = tops::vload<vfloat>(uwr0 + j);\\n                                vfloat u1  = tops::vload<vfloat>(uwr1 + j);\\n                                vfloat u2  = tops::vload<vfloat>(uwr2 + j);\\n                                vfloat u3  = tops::vload<vfloat>(uwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u0, vA), tops::vmul<vfloat>(u1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u2, vC), tops::vmul<vfloat>(u3, vD))\\n                                        ));\\n                                tops::vstore(acc, up_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                up_acc[j] += uwr0[j]*xA + uwr1[j]*xB + uwr2[j]*xC + uwr3[j]*xD;\\n                        }\\n                    }\\n\\n                    // ---- 剩余 1~3 行（单行）——同样分开 gate / up 的缓冲 ----\\n                    for (; kk < kb_cur; ++kk) {\\n                        const int k = k0 + kk;\\n                        const float x = in_seg[kk];\\n                        const int vec = (jb / VLEN) * VLEN;\\n                        vfloat vx = tops::vbroadcast<vfloat>(x);\\n\\n                        // gate 单行 -> gwr0\\n                        tops::event eg;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)k*I + j0);\\n                        eg = ctx_g[0].trigger(); tops::wait(eg);\\n\\n                        int j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                            vfloat gw  = tops::vload<vfloat>(gwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(gw, vx));\\n                            tops::vstore(acc, gate_acc + j);\\n                        }\\n                        for (; j < jb; ++j) gate_acc[j] += gwr0[j] * x;\\n\\n                        // up 单行 -> uwr0\\n                        tops::event eu;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)k*I + j0);\\n                        eu = ctx_u[0].trigger(); tops::wait(eu);\\n\\n                        j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                            vfloat uw  = tops::vload<vfloat>(uwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(uw, vx));\\n                            tops::vstore(acc, up_acc + j);\\n                        }\\n                        for (; j < jb; ++j) up_acc[j] += uwr0[j] * x;\\n                    }\\n\\n                    // 交换 K 双缓冲\\n                    k0 += kb_cur;\\n                    int t = cur; cur = nxt; nxt = t;\\n                } // while K\\n\\n                // =============== SiLU 融合（优化：vsigmoid + 乘法） ===============\\n                {\\n                    int j = 0, vec = (jb / VLEN) * VLEN;\\n                    for (; j < vec; j += VLEN) {\\n                        vfloat vg = tops::vload<vfloat>(gate_acc + j);\\n                        vfloat vu = tops::vload<vfloat>(up_acc   + j);\\n                        vfloat vs = tops::vsigmoid(vg);\\n                        tops::vstore(tops::vmul<vfloat>(tops::vmul<vfloat>(vg, vs), vu), act_seg + j);\\n                    }\\n                    for (; j < jb; ++j) {\\n                        float x = gate_acc[j];\\n                        act_seg[j] = silu_scalar(x) * up_acc[j];\\n                    }\\n                }\\n\\n                // =============== down 投影（行块 + 增量搬运 + 双缓冲，稳定可靠） ===============\\n                ctx_dw[0].config_memcpy(\\n                    tops::mdspan(tops::Private, dw0, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n                ctx_dw[1].config_memcpy(\\n                    tops::mdspan(tops::Private, dw1, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n\\n                for (int hst = 0; hst < hb; hst += hChunk) {\\n                    const int hc = MIN(hChunk, hb - hst);\\n#if USE_KAHAN\\n                    for (int t = 0; t < hc; ++t) { h_sum[t] = 0.f; h_comp[t] = 0.f; }\\n#else\\n                    for (int t = 0; t < hc; ++t) h_sum[t] = 0.f;\\n#endif\\n                    tops::event ev_dw[2];\\n                    bool has_ev[2] = {false, false};\\n                    int dc = 0, dn = 1;\\n\\n                    int jx = 0;\\n                    // 预取首行（size 用字节数）\\n                    if (jx < jb) {\\n                        ctx_dw[dc].set_src_addr(down_w + (size_t)(j0 + jx)*H + (h0 + hst));\\n                        ctx_dw[dc].set_total_size(hc * sizeof(float)); // 字节数\\n                        ev_dw[dc] = ctx_dw[dc].trigger();\\n                        has_ev[dc] = true;\\n                    }\\n\\n                    while (jx < jb) {\\n                        // 预取下一行\\n                        const int jn = jx + 1;\\n                        if (jn < jb) {\\n                            ctx_dw[dn].set_src_addr(down_w + (size_t)(j0 + jn)*H + (h0 + hst));\\n                            ctx_dw[dn].set_total_size(hc * sizeof(float)); // 字节数\\n                            ev_dw[dn] = ctx_dw[dn].trigger();\\n                            has_ev[dn] = true;\\n                        } else {\\n                            has_ev[dn] = false;\\n                        }\\n\\n                        if (has_ev[dc]) tops::wait(ev_dw[dc]);\\n                        float *dw = (dc==0?dw0:dw1);\\n                        const float a = act_seg[jx];\\n\\n                        int h = 0, vecH = (hc / VLEN) * VLEN;\\n                        vfloat va = tops::vbroadcast<vfloat>(a);\\n#if USE_KAHAN\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vc = tops::vload<vfloat>(h_comp+ h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vfloat vy = tops::vsub<vfloat>(vprod, vc);\\n                            vfloat vt = tops::vadd<vfloat>(vs, vy);\\n                            vfloat vtmp = tops::vsub<vfloat>(vt, vs);\\n                            vc = tops::vsub<vfloat>(vtmp, vy);\\n                            tops::vstore(vt, h_sum + h);\\n                            tops::vstore(vc, h_comp+ h);\\n                        }\\n                        for (; h < hc; ++h) {\\n                            float y = a * dw[h] - h_comp[h];\\n                            float t = h_sum[h] + y;\\n                            h_comp[h] = (t - h_sum[h]) - y;\\n                            h_sum[h]  = t;\\n                        }\\n#else\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vs = tops::vadd<vfloat>(vs, vprod);\\n                            tops::vstore(vs, h_sum + h);\\n                        }\\n                        for (; h < hc; ++h) h_sum[h] += a * dw[h];\\n#endif\\n                        ++jx;\\n                        int t = dc; dc = dn; dn = t;\\n                    } // jx\\n\\n                    // 写回到 out_seg 片\\n                    for (int t = 0; t < hc; ++t) out_seg[hst + t] += h_sum[t];\\n                } // hst\\n            } // j0\\n\\n            // 回写 L3\\n            tops::memcpy(\\n                ctx_out,\\n                tops::mdspan(tops::Global,  out + (size_t)m*H + h0, hb),\\n                tops::mdspan(tops::Private, out_seg, hb)\\n            );\\n        } // h0\\n    } // m\\n}\\n\\n// ---------------- Host 接口（题目指定，保持 C++ 链接） ----------------\\nvoid GCU_MLP(float *__restrict gate_proj_weight,\\n             float *__restrict up_proj_weight,\\n             float *__restrict down_proj_weight,\\n             float *__restrict input,\\n             float *__restrict output,\\n             const int seq_len,\\n             const int hidden_size,\\n             const int intermediate_size)\\n{\\n    const int threads = 12; // i20：一个 block 内最多 12 个 thread\\n    int blocks = (seq_len + threads - 1) / threads;\\n    if (blocks < 1) blocks = 1;\\n    if (blocks > 65535) blocks = 65535;\\n\\n    kernel_mlp_fused_c5_stable<<<blocks, threads>>>(\\n        gate_proj_weight, up_proj_weight, down_proj_weight,\\n        input, output, seq_len, hidden_size, intermediate_size\\n    );\\n\\n    // 开发期可开\\n    // (void)topsGetLastError();\\n    // (void)topsDeviceSynchronize();\\n}\\n</candidate>',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 36454,\n",
       "  'completion_tokens': 6792,\n",
       "  'total_tokens': 43246,\n",
       "  'prompt_tokens_details': {'cached_tokens': 36352, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 1472,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = proxy_chat(a) # gpt medium\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d46312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-CY7Y52CulqxlmNBSgoQBHOmOBanzK',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1762248205,\n",
       " 'model': 'gpt-5-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '<candidate>\\n#include <tops/tops_runtime.h>\\n#include <tops.h>\\n#include <math.h>\\n\\n#define MIN(a,b) (((a)<(b))?(a):(b))\\n\\n// ======= 可调 tile（会按规模自适应收缩，默认偏大，运行时收缩） =======\\n#ifndef K_TILE\\n#define K_TILE   1536\\n#endif\\n#ifndef J_TILE\\n#define J_TILE   768    // 128 的整数倍\\n#endif\\n#ifndef H_TILE\\n#define H_TILE   768\\n#endif\\n#ifndef HCHUNK\\n#define HCHUNK   256    // down 行块更粗，减少 DTE 触发\\n#endif\\n\\n#ifndef USE_KAHAN\\n#define USE_KAHAN 0     // 如需更稳累加：-DUSE_KAHAN=1\\n#endif\\n\\n// 与 CPU 一致的 SiLU\\n__device__ __forceinline__ float silu_scalar(float x) {\\n    return x / (1.f + expf(-x));\\n}\\n\\n// RAII DTE 封装\\nstruct dte_scope {\\n    tops_dte_ctx_t &c;\\n    __device__ dte_scope(tops_dte_ctx_t &ctx) : c(ctx) { c.init(); }\\n    __device__ ~dte_scope() { c.destroy(); }\\n};\\n\\n__global__ __cooperative__\\nvoid kernel_mlp_fused_c5_stable(\\n    float *__restrict gate_w,   // [H, I]  row-major\\n    float *__restrict up_w,     // [H, I]  row-major\\n    float *__restrict down_w,   // [I, H]  row-major\\n    float *__restrict inp,      // [S, H]  row-major\\n    float *__restrict out,      // [S, H]  row-major\\n    const int S, const int H, const int I)\\n{\\n    const int tid    = blockIdx.x * blockDim.x + threadIdx.x;\\n    const int stride = gridDim.x  * blockDim.x;\\n    if (stride <= 0) return;\\n\\n    // 动态收缩 tile（L1 粗估限制，给调度/栈留余量）\\n    int kTile = K_TILE, jTile = J_TILE, hTile = H_TILE, hChunk = HCHUNK;\\n    const int VLEN = tops::vlength<vfloat>(); // 32\\n\\n    // 经验阈：控制 float 个数 ~26万以内（≈1MB/4），留足余量\\n    while ((size_t)kTile + (size_t)8*jTile + (size_t)hTile + (size_t)4*hChunk > (size_t)260000) {\\n        if (kTile  > 512) kTile  -= 256;\\n        if (jTile  > 512) jTile  -= 128;\\n        if (hTile  > 512) hTile  -= 128;\\n        if (hChunk > 128) hChunk -=  64;\\n        if (kTile <= 512 && jTile <= 512 && hTile <= 512 && hChunk <= 128) break;\\n    }\\n\\n    // ---------------- DTE 上下文 ----------------\\n    // 输入(K)双缓冲\\n    tops_dte_ctx_t ctx_in[2];\\n    dte_scope s_in0(ctx_in[0]), s_in1(ctx_in[1]);\\n\\n    // gate/up 权重加载（两 ctx 交替），目标缓冲用 set_dst_addr 调整\\n    tops_dte_ctx_t ctx_g[2], ctx_u[2];\\n    dte_scope s_g0(ctx_g[0]), s_g1(ctx_g[1]);\\n    dte_scope s_u0(ctx_u[0]), s_u1(ctx_u[1]);\\n\\n    // down 行块双缓冲（稳定可靠的版本）\\n    tops_dte_ctx_t ctx_dw[2];\\n    dte_scope s_d0(ctx_dw[0]), s_d1(ctx_dw[1]);\\n\\n    // 输出回写\\n    tops_dte_ctx_t ctx_out;\\n    dte_scope s_out(ctx_out);\\n\\n    // ---------------- L1 缓冲（全部 128B 对齐） ----------------\\n    // 输入 K 双缓冲（按最大 kTile 上限分配）\\n    alignas(128) float in0[1536];\\n    alignas(128) float in1[1536];\\n\\n    // gate/up 各自四行权重缓冲（按最大 jTile 上限分配）\\n    alignas(128) float gwr0[1024], gwr1[1024], gwr2[1024], gwr3[1024];\\n    alignas(128) float uwr0[1024], uwr1[1024], uwr2[1024], uwr3[1024];\\n\\n    // 中间累加与激活\\n    alignas(128) float gate_acc[1024];\\n    alignas(128) float up_acc  [1024];\\n    alignas(128) float act_seg [1024];\\n\\n    // 输出片（按最大 hTile 上限）\\n    alignas(128) float out_seg [1024];\\n\\n    // down 行块双缓冲（按最大 hChunk 上限）\\n    alignas(128) float dw0[512], dw1[512];\\n\\n#if USE_KAHAN\\n    alignas(128) float h_sum[512], h_comp[512];\\n#else\\n    alignas(128) float h_sum[512];\\n#endif\\n\\n    for (int m0 = tid; m0 < S; m0 += stride) {\\n        const int m = m0;\\n\\n        for (int h0 = 0; h0 < H; h0 += hTile) {\\n            const int hb = MIN(hTile, H - h0);\\n            for (int h = 0; h < hb; ++h) out_seg[h] = 0.f;\\n\\n            for (int j0 = 0; j0 < I; j0 += jTile) {\\n                const int jb = MIN(jTile, I - j0);\\n                for (int j = 0; j < jb; ++j) { gate_acc[j] = 0.f; up_acc[j] = 0.f; }\\n\\n                // =============== 输入(K)双缓冲：一次 config，多次触发（size 用字节） ===============\\n                tops::event ev_in[2];\\n                bool in_has_ev[2] = {false, false};\\n                int cur = 0, nxt = 1;\\n\\n                ctx_in[0].config_memcpy(\\n                    tops::mdspan(tops::Private, in0, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n                ctx_in[1].config_memcpy(\\n                    tops::mdspan(tops::Private, in1, kTile),\\n                    tops::mdspan(tops::Global,  inp /*占位*/, kTile)\\n                );\\n\\n                int k0 = 0;\\n                // 预取 tile0\\n                {\\n                    const int kb0 = MIN(kTile, H - k0);\\n                    if (kb0 > 0) {\\n                        ctx_in[cur].set_src_addr(inp + (size_t)m*H + k0);\\n                        ctx_in[cur].set_total_size(kb0 * sizeof(float)); // 字节数\\n                        ev_in[cur] = ctx_in[cur].trigger();\\n                        in_has_ev[cur] = true;\\n                    }\\n                }\\n\\n                // 预配置 gate/up 的 memcpy 模板（dst 用 set_dst_addr 改到对应缓冲）\\n                ctx_g[0].config_memcpy(tops::mdspan(tops::Private, gwr0, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_g[1].config_memcpy(tops::mdspan(tops::Private, gwr1, jb),\\n                                       tops::mdspan(tops::Global,  gate_w /*占位*/, jb));\\n                ctx_u[0].config_memcpy(tops::mdspan(tops::Private, uwr0, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n                ctx_u[1].config_memcpy(tops::mdspan(tops::Private, uwr1, jb),\\n                                       tops::mdspan(tops::Global,  up_w   /*占位*/, jb));\\n\\n                while (k0 < H) {\\n                    const int kb_cur = MIN(kTile, H - k0);\\n\\n                    // 预取下一 K-tile\\n                    const int k1 = k0 + kb_cur;\\n                    const int kb_next = MIN(kTile, H - k1);\\n                    if (kb_next > 0) {\\n                        ctx_in[nxt].set_src_addr(inp + (size_t)m*H + k1);\\n                        ctx_in[nxt].set_total_size(kb_next * sizeof(float)); // 字节数\\n                        ev_in[nxt] = ctx_in[nxt].trigger();\\n                        in_has_ev[nxt] = true;\\n                    } else {\\n                        in_has_ev[nxt] = false;\\n                    }\\n\\n                    // 等待当前 K-tile\\n                    if (in_has_ev[cur]) tops::wait(ev_in[cur]);\\n                    float *in_seg = (cur==0?in0:in1);\\n\\n                    // ---- 遍历当前 K-tile（四行一组），gate/up 完全独立缓冲加载与累计 ----\\n                    int kk = 0;\\n                    for (; kk + 3 < kb_cur; kk += 4) {\\n                        const int kA = k0 + kk + 0;\\n                        const int kB = k0 + kk + 1;\\n                        const int kC = k0 + kk + 2;\\n                        const int kD = k0 + kk + 3;\\n\\n                        const float xA = in_seg[kk+0];\\n                        const float xB = in_seg[kk+1];\\n                        const float xC = in_seg[kk+2];\\n                        const float xD = in_seg[kk+3];\\n\\n                        // ---- gate：把四行分别放到 gwr0..gwr3\\n                        tops::event eg0, eg1, eg2, eg3;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kA*I + j0); eg0 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr1);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kB*I + j0); eg1 = ctx_g[1].trigger();\\n                        tops::wait(eg0); tops::wait(eg1);\\n                        ctx_g[0].set_dst_addr(gwr2);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)kC*I + j0); eg2 = ctx_g[0].trigger();\\n                        ctx_g[1].set_dst_addr(gwr3);\\n                        ctx_g[1].set_src_addr(gate_w + (size_t)kD*I + j0); eg3 = ctx_g[1].trigger();\\n                        tops::wait(eg2); tops::wait(eg3);\\n\\n                        // gate 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                                vfloat g0  = tops::vload<vfloat>(gwr0 + j);\\n                                vfloat g1  = tops::vload<vfloat>(gwr1 + j);\\n                                vfloat g2  = tops::vload<vfloat>(gwr2 + j);\\n                                vfloat g3  = tops::vload<vfloat>(gwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g0, vA), tops::vmul<vfloat>(g1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(g2, vC), tops::vmul<vfloat>(g3, vD))\\n                                        ));\\n                                tops::vstore(acc, gate_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                gate_acc[j] += gwr0[j]*xA + gwr1[j]*xB + gwr2[j]*xC + gwr3[j]*xD;\\n                        }\\n\\n                        // ---- up：把四行分别放到 uwr0..uwr3\\n                        tops::event eu0, eu1, eu2, eu3;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kA*I + j0); eu0 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr1);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kB*I + j0); eu1 = ctx_u[1].trigger();\\n                        tops::wait(eu0); tops::wait(eu1);\\n                        ctx_u[0].set_dst_addr(uwr2);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)kC*I + j0); eu2 = ctx_u[0].trigger();\\n                        ctx_u[1].set_dst_addr(uwr3);\\n                        ctx_u[1].set_src_addr(up_w + (size_t)kD*I + j0); eu3 = ctx_u[1].trigger();\\n                        tops::wait(eu2); tops::wait(eu3);\\n\\n                        // up 累加\\n                        {\\n                            int j = 0, vec = (jb / VLEN) * VLEN;\\n                            vfloat vA = tops::vbroadcast<vfloat>(xA);\\n                            vfloat vB = tops::vbroadcast<vfloat>(xB);\\n                            vfloat vC = tops::vbroadcast<vfloat>(xC);\\n                            vfloat vD = tops::vbroadcast<vfloat>(xD);\\n                            for (; j < vec; j += VLEN) {\\n                                vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                                vfloat u0  = tops::vload<vfloat>(uwr0 + j);\\n                                vfloat u1  = tops::vload<vfloat>(uwr1 + j);\\n                                vfloat u2  = tops::vload<vfloat>(uwr2 + j);\\n                                vfloat u3  = tops::vload<vfloat>(uwr3 + j);\\n                                acc = tops::vadd<vfloat>(acc,\\n                                        tops::vadd<vfloat>(\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u0, vA), tops::vmul<vfloat>(u1, vB)),\\n                                            tops::vadd<vfloat>(tops::vmul<vfloat>(u2, vC), tops::vmul<vfloat>(u3, vD))\\n                                        ));\\n                                tops::vstore(acc, up_acc + j);\\n                            }\\n                            for (; j < jb; ++j)\\n                                up_acc[j] += uwr0[j]*xA + uwr1[j]*xB + uwr2[j]*xC + uwr3[j]*xD;\\n                        }\\n                    }\\n\\n                    // ---- 剩余 1~3 行（单行）——同样分开 gate / up 的缓冲 ----\\n                    for (; kk < kb_cur; ++kk) {\\n                        const int k = k0 + kk;\\n                        const float x = in_seg[kk];\\n                        const int vec = (jb / VLEN) * VLEN;\\n                        vfloat vx = tops::vbroadcast<vfloat>(x);\\n\\n                        // gate 单行 -> gwr0\\n                        tops::event eg;\\n                        ctx_g[0].set_dst_addr(gwr0);\\n                        ctx_g[0].set_src_addr(gate_w + (size_t)k*I + j0);\\n                        eg = ctx_g[0].trigger(); tops::wait(eg);\\n\\n                        int j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(gate_acc + j);\\n                            vfloat gw  = tops::vload<vfloat>(gwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(gw, vx));\\n                            tops::vstore(acc, gate_acc + j);\\n                        }\\n                        for (; j < jb; ++j) gate_acc[j] += gwr0[j] * x;\\n\\n                        // up 单行 -> uwr0\\n                        tops::event eu;\\n                        ctx_u[0].set_dst_addr(uwr0);\\n                        ctx_u[0].set_src_addr(up_w + (size_t)k*I + j0);\\n                        eu = ctx_u[0].trigger(); tops::wait(eu);\\n\\n                        j = 0;\\n                        for (; j < vec; j += VLEN) {\\n                            vfloat acc = tops::vload<vfloat>(up_acc + j);\\n                            vfloat uw  = tops::vload<vfloat>(uwr0 + j);\\n                            acc = tops::vadd<vfloat>(acc, tops::vmul<vfloat>(uw, vx));\\n                            tops::vstore(acc, up_acc + j);\\n                        }\\n                        for (; j < jb; ++j) up_acc[j] += uwr0[j] * x;\\n                    }\\n\\n                    // 交换 K 双缓冲\\n                    k0 += kb_cur;\\n                    int t = cur; cur = nxt; nxt = t;\\n                } // while K\\n\\n                // =============== SiLU 融合 ===============\\n                {\\n                    int j = 0, vec = (jb / VLEN) * VLEN;\\n                    vfloat vone = tops::vbroadcast<vfloat>(1.0f);\\n                    vfloat vneg = tops::vbroadcast<vfloat>(-1.0f);\\n                    for (; j < vec; j += VLEN) {\\n                        vfloat vg = tops::vload<vfloat>(gate_acc + j);\\n                        vfloat vu = tops::vload<vfloat>(up_acc   + j);\\n                        vfloat vexpn = tops::vexp(tops::vmul<vfloat>(vg, vneg));\\n                        vfloat vden  = tops::vadd<vfloat>(vone, vexpn);\\n                        vfloat vsilu = tops::vdiv<vfloat>(vg, vden);\\n                        tops::vstore(tops::vmul<vfloat>(vsilu, vu), act_seg + j);\\n                    }\\n                    for (; j < jb; ++j) {\\n                        float x = gate_acc[j];\\n                        act_seg[j] = silu_scalar(x) * up_acc[j];\\n                    }\\n                }\\n\\n                // =============== down 投影（行块 + 增量搬运 + 双缓冲，稳定可靠） ===============\\n                ctx_dw[0].config_memcpy(\\n                    tops::mdspan(tops::Private, dw0, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n                ctx_dw[1].config_memcpy(\\n                    tops::mdspan(tops::Private, dw1, hChunk),\\n                    tops::mdspan(tops::Global,  down_w /*占位*/, hChunk));\\n\\n                for (int hst = 0; hst < hb; hst += hChunk) {\\n                    const int hc = MIN(hChunk, hb - hst);\\n#if USE_KAHAN\\n                    for (int t = 0; t < hc; ++t) { h_sum[t] = 0.f; h_comp[t] = 0.f; }\\n#else\\n                    for (int t = 0; t < hc; ++t) h_sum[t] = 0.f;\\n#endif\\n                    tops::event ev_dw[2];\\n                    bool has_ev[2] = {false, false};\\n                    int dc = 0, dn = 1;\\n\\n                    int jx = 0;\\n                    // 预取首行（size 用字节数）\\n                    if (jx < jb) {\\n                        ctx_dw[dc].set_src_addr(down_w + (size_t)(j0 + jx)*H + (h0 + hst));\\n                        ctx_dw[dc].set_total_size(hc * sizeof(float)); // 字节数\\n                        ev_dw[dc] = ctx_dw[dc].trigger();\\n                        has_ev[dc] = true;\\n                    }\\n\\n                    while (jx < jb) {\\n                        // 预取下一行\\n                        const int jn = jx + 1;\\n                        if (jn < jb) {\\n                            ctx_dw[dn].set_src_addr(down_w + (size_t)(j0 + jn)*H + (h0 + hst));\\n                            ctx_dw[dn].set_total_size(hc * sizeof(float)); // 字节数\\n                            ev_dw[dn] = ctx_dw[dn].trigger();\\n                            has_ev[dn] = true;\\n                        } else {\\n                            has_ev[dn] = false;\\n                        }\\n\\n                        if (has_ev[dc]) tops::wait(ev_dw[dc]);\\n                        float *dw = (dc==0?dw0:dw1);\\n                        const float a = act_seg[jx];\\n\\n                        int h = 0, vecH = (hc / VLEN) * VLEN;\\n                        vfloat va = tops::vbroadcast<vfloat>(a);\\n#if USE_KAHAN\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vc = tops::vload<vfloat>(h_comp+ h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vfloat vy = tops::vsub<vfloat>(vprod, vc);\\n                            vfloat vt = tops::vadd<vfloat>(vs, vy);\\n                            vfloat vtmp = tops::vsub<vfloat>(vt, vs);\\n                            vc = tops::vsub<vfloat>(vtmp, vy);\\n                            tops::vstore(vt, h_sum + h);\\n                            tops::vstore(vc, h_comp+ h);\\n                        }\\n                        for (; h < hc; ++h) {\\n                            float y = a * dw[h] - h_comp[h];\\n                            float t = h_sum[h] + y;\\n                            h_comp[h] = (t - h_sum[h]) - y;\\n                            h_sum[h]  = t;\\n                        }\\n#else\\n                        for (; h < vecH; h += VLEN) {\\n                            vfloat vs = tops::vload<vfloat>(h_sum + h);\\n                            vfloat vprod = tops::vmul<vfloat>(tops::vload<vfloat>(dw + h), va);\\n                            vs = tops::vadd<vfloat>(vs, vprod);\\n                            tops::vstore(vs, h_sum + h);\\n                        }\\n                        for (; h < hc; ++h) h_sum[h] += a * dw[h];\\n#endif\\n                        ++jx;\\n                        int t = dc; dc = dn; dn = t;\\n                    } // jx\\n\\n                    // 写回到 out_seg 片\\n                    for (int t = 0; t < hc; ++t) out_seg[hst + t] += h_sum[t];\\n                } // hst\\n            } // j0\\n\\n            // 回写 L3\\n            tops::memcpy(\\n                ctx_out,\\n                tops::mdspan(tops::Global,  out + (size_t)m*H + h0, hb),\\n                tops::mdspan(tops::Private, out_seg, hb)\\n            );\\n        } // h0\\n    } // m\\n}\\n\\n// ---------------- Host 接口（题目指定，保持 C++ 链接） ----------------\\nvoid GCU_MLP(float *__restrict gate_proj_weight,\\n             float *__restrict up_proj_weight,\\n             float *__restrict down_proj_weight,\\n             float *__restrict input,\\n             float *__restrict output,\\n             const int seq_len,\\n             const int hidden_size,\\n             const int intermediate_size)\\n{\\n    const int threads = 12; // i20：一个 block 内最多 12 个 thread\\n    int blocks = (seq_len + threads - 1) / threads;\\n    if (blocks < 1) blocks = 1;\\n    if (blocks > 2) blocks = 2; // cooperative：grid 产品 ≤ 2，稳定两块并发\\n\\n    kernel_mlp_fused_c5_stable<<<blocks, threads>>>(\\n        gate_proj_weight, up_proj_weight, down_proj_weight,\\n        input, output, seq_len, hidden_size, intermediate_size\\n    );\\n\\n    // 开发期可开\\n    // (void)topsGetLastError();\\n    // (void)topsDeviceSynchronize();\\n}\\n</candidate>',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 36454,\n",
       "  'completion_tokens': 6491,\n",
       "  'total_tokens': 42945,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 1088,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = proxy_chat(a)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc6b3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_sync/connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_backends/sync.py:207\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    205\u001b[0m }\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    208\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    209\u001b[0m         address,\n\u001b[1;32m    210\u001b[0m         timeout,\n\u001b[1;32m    211\u001b[0m         source_address\u001b[38;5;241m=\u001b[39msource_address,\n\u001b[1;32m    212\u001b[0m     )\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 99] Cannot assign requested address",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [Errno 99] Cannot assign requested address",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 发送请求\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 直接指定模型名称\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m你是谁？。\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 输出结果\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/data0/danzedong/anaconda3/envs/ai/lib/python3.10/site-packages/openai/_base_client.py:1014\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化客户端\n",
    "api_key = \"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\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 发送请求\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",  # 直接指定模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"你是谁？。\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 输出结果\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6418a10",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "print(a[1].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cfe1fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'debug_log': 'testcase0 -> Passed\\ntestcase1 -> Passed\\ntestcase2 -> Passed\\ntestcase3 -> Passed\\ntestcase4 -> Passed\\ntestcase5 -> Passed\\ntestcase6 -> Passed\\ntestcase7 -> Passed\\ntestcase8 -> Passed\\ntestcase9 -> Passed\\n',\n",
       " 'time_comparison': [{'name': 'GCU_CONV2D0',\n",
       "   'avg': '24.85 us',\n",
       "   'best': '20.06 us'},\n",
       "  {'name': 'GCU_CONV2D1', 'avg': '86.22 us', 'best': '82.15 us'},\n",
       "  {'name': 'GCU_CONV2D2', 'avg': '234.44 us', 'best': '195.95 us'},\n",
       "  {'name': 'GCU_CONV2D3', 'avg': '2960.0 us', 'best': '2960.0 us'},\n",
       "  {'name': 'GCU_CONV2D4', 'avg': '5390.0 us', 'best': '5390.0 us'},\n",
       "  {'name': 'GCU_CONV2D5', 'avg': '315.81 us', 'best': '262.91 us'},\n",
       "  {'name': 'GCU_CONV2D6', 'avg': '296.6 us', 'best': '227.96 us'},\n",
       "  {'name': 'GCU_CONV2D7', 'avg': '2140.0 us', 'best': '1860.0 us'},\n",
       "  {'name': 'GCU_CONV2D8', 'avg': '1050.0 us', 'best': '1050.0 us'},\n",
       "  {'name': 'GCU_CONV2D9', 'avg': '43990.0 us', 'best': '43990.0 us'}]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a25cb9f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mconstraints[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_comparison\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# 用正则提取数字部分\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md.]+\u001b[39m\u001b[38;5;124m\"\u001b[39m, item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m     best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md.]+\u001b[39m\u001b[38;5;124m\"\u001b[39m, item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "import re\n",
    "scores = []\n",
    "for item in a[2].constraints['time_comparison']:\n",
    "    # 用正则提取数字部分\n",
    "    avg = float(re.findall(r\"[\\d.]+\", item['avg'])[0])\n",
    "    best = float(re.findall(r\"[\\d.]+\", item['best'])[0])\n",
    "    score = best / avg\n",
    "    scores.append(score)\n",
    "    print(f\"{item['name']}: best/avg = {score:.4f}\")\n",
    "\n",
    "mean_score = sum(scores) / len(scores)\n",
    "print(f\"\\nOverall average score = {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0958bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'debug_log': 'testcase0 -> Passed\\ntestcase1 -> Passed\\ntestcase2 -> Passed\\ntestcase3 -> Passed\\ntestcase4 -> Passed\\ntestcase5 -> Passed\\ntestcase6 -> Passed\\ntestcase7 -> Passed\\ntestcase8 -> Passed\\ntestcase9 -> Passed\\n', 'time_comparison': [{'name': 'GCU_CONV2D0', 'avg': '24.68 us', 'best': '19.49 us'}, {'name': 'GCU_CONV2D1', 'avg': '83.81 us', 'best': '76.93 us'}, {'name': 'GCU_CONV2D2', 'avg': '234.02 us', 'best': '195.95 us'}, {'name': 'GCU_CONV2D3', 'avg': '2970.0 us', 'best': '941.75 us'}, {'name': 'GCU_CONV2D4', 'avg': '5390.0 us', 'best': '4810.0 us'}, {'name': 'GCU_CONV2D5', 'avg': '326.7 us', 'best': '262.91 us'}, {'name': 'GCU_CONV2D6', 'avg': '285.67 us', 'best': '227.96 us'}, {'name': 'GCU_CONV2D7', 'avg': '2160.0 us', 'best': '1860.0 us'}, {'name': 'GCU_CONV2D8', 'avg': '1050.0 us', 'best': '897.41 us'}, {'name': 'GCU_CONV2D9', 'avg': '43880.0 us', 'best': '37780.0 us'}]}\n",
      "best times: {'GCU_CONV2D0': 19.49, 'GCU_CONV2D1': 76.93, 'GCU_CONV2D2': 195.95, 'GCU_CONV2D3': 941.75, 'GCU_CONV2D4': 4810.0, 'GCU_CONV2D5': 262.91, 'GCU_CONV2D6': 227.96, 'GCU_CONV2D7': 1860.0, 'GCU_CONV2D8': 897.41, 'GCU_CONV2D9': 37780.0}\n",
      "gcu_conv2d\n",
      "✅ 已根据最新基准重算完成。示例：\n",
      "0: total = 82.0979\n",
      "1: total = 82.0943\n",
      "2: total = 81.9294\n",
      "3: total = 81.1090\n",
      "4: total = 80.3157\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "root = '/root/nian/mollm_results/gcu/zgca,gpt-5-minimal/mols/gcu_conv2d_1010_42.pkl'\n",
    "with open(root,'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "\n",
    "all_mols = a['all_mols']\n",
    "\n",
    "for mol, _ in reversed(all_mols):\n",
    "    if mol.constraints['status'] == \"success\":\n",
    "        # Step 2: 建立基准 best_time 字典\n",
    "        print(mol.constraints)\n",
    "        best_times = {}\n",
    "        for d in mol.constraints[\"time_comparison\"]:\n",
    "            name = d[\"name\"]\n",
    "            best_us = float(re.findall(r\"[\\d.]+\", d[\"best\"])[0])\n",
    "            best_times[name] = best_us\n",
    "        break\n",
    "print('best times:',best_times)\n",
    "\n",
    "goal = all_mols[0][0].property_list[0]\n",
    "print(goal)\n",
    "for mol, _ in all_mols:\n",
    "    con = mol.constraints\n",
    "\n",
    "    # 没有 time_comparison → 0分\n",
    "    if not con or \"time_comparison\" not in con:\n",
    "        mol.total = 0.0\n",
    "        mol.property[goal] = 100\n",
    "        mol.scores = [1.0]\n",
    "        continue\n",
    "\n",
    "    # 把当前 item 的 time_comparison 转成字典形式方便查找\n",
    "    item_times = {}\n",
    "    for d in con[\"time_comparison\"]:\n",
    "        name = d.get(\"name\")\n",
    "        avg_str = d.get(\"avg\")\n",
    "        if name and avg_str:\n",
    "            avg_us = float(re.findall(r\"[\\d.]+\", avg_str)[0])\n",
    "            item_times[name] = avg_us\n",
    "\n",
    "    # 按 best_times 为主来循环\n",
    "    scores = []\n",
    "    for name, ref_best in best_times.items():\n",
    "        if name not in item_times:\n",
    "            # 这个 name 测试缺失（例如 MLP7）→ 记 0 分\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        avg_us = item_times[name]\n",
    "        scores.append(ref_best / avg_us*100)\n",
    "    mol.total = sum(scores) / len(scores) \n",
    "    mol.property[goal] = mol.total\n",
    "    mol.scores = [1 - mol.total/100]\n",
    "\n",
    "print(\"✅ 已根据最新基准重算完成。示例：\")\n",
    "kkk = sorted(all_mols,key=lambda x:x[0].total,reverse=True)\n",
    "for i, (mol, _) in enumerate(kkk[:5]):  # 打印后5个看看\n",
    "    print(f\"{i}: total = {mol.total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd8c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['all_mols'] = all_mols\n",
    "with open(root,'wb') as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c30aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.09791410719453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mols[kkk[0][1]-1][0].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcd7125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'debug_log': 'testcase0 -> Passed\\ntestcase1 -> Passed\\ntestcase2 -> Passed\\ntestcase3 -> Passed\\ntestcase4 -> Passed\\ntestcase5 -> Passed\\ntestcase6 -> Passed\\ntestcase7 -> Passed\\ntestcase8 -> Passed\\ntestcase9 -> Passed\\n',\n",
       " 'time_comparison': [{'name': 'GCU_CONV2D0',\n",
       "   'avg': '23.2 us',\n",
       "   'best': '20.06 us'},\n",
       "  {'name': 'GCU_CONV2D1', 'avg': '76.93 us', 'best': '76.93 us'},\n",
       "  {'name': 'GCU_CONV2D2', 'avg': '209.37 us', 'best': '195.95 us'},\n",
       "  {'name': 'GCU_CONV2D3', 'avg': '2900.0 us', 'best': '2900.0 us'},\n",
       "  {'name': 'GCU_CONV2D4', 'avg': '5290.0 us', 'best': '5290.0 us'},\n",
       "  {'name': 'GCU_CONV2D5', 'avg': '324.92 us', 'best': '262.91 us'},\n",
       "  {'name': 'GCU_CONV2D6', 'avg': '308.55 us', 'best': '227.96 us'},\n",
       "  {'name': 'GCU_CONV2D7', 'avg': '2180.0 us', 'best': '1860.0 us'},\n",
       "  {'name': 'GCU_CONV2D8', 'avg': '950.58 us', 'best': '950.58 us'},\n",
       "  {'name': 'GCU_CONV2D9', 'avg': '44210.0 us', 'best': '43990.0 us'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkk[0][0].constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaad8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "#include <stdint.h>\n",
      "\n",
      "using namespace tops;\n",
      "\n",
      "static __host__ __forceinline__ int div_up_host(int a, int b) { return (a + b - 1) / b; }\n",
      "\n",
      "// 改进点基于 parent#0：\n",
      "// - 引入行间双缓冲+预取：对相邻输出行的输入3行集合做滚动复用（仅替换退出的那一行），减少DMA次数。\n",
      "// - 对 dilation==1 的常见路径，构建“3行滑窗寄存器缓存”，在水平移动时只搬一组新列（以标量快速路径实现），减少随机访存判断。\n",
      "// - 输出行仍整行写回；每线程专注一个通道集合。\n",
      "// - 权重向量广播，常量化。\n",
      "\n",
      "__global__ void dwconv3x3_row_rolling_prefetch_kernel(\n",
      "    int C, int IH, int IW, int stride, int padding, int dilation,\n",
      "    float* __restrict inp_g,\n",
      "    float* __restrict weight_g,\n",
      "    float* __restrict out_g)\n",
      "{\n",
      "    const int KH = 3, KW = 3;\n",
      "    const int OH = (IH + 2 * padding - dilation * (KH - 1) - 1) / stride + 1;\n",
      "    const int OW = (IW + 2 * padding - dilation * (KW - 1) - 1) / stride + 1;\n",
      "\n",
      "    const int tid = threadIdx.x;\n",
      "    const int tnum = blockDim.x;\n",
      "    const int grid_threads = gridDim.x * tnum;\n",
      "\n",
      "    const int V = tops::vlength<vfloat>(); // 32\n",
      "    for (int c = blockIdx.x * tnum + tid; c < C; c += grid_threads) {\n",
      "        tops_dte_ctx_t dte_w, dte_in, dte_out;\n",
      "        dte_w.init(); dte_in.init(); dte_out.init();\n",
      "\n",
      "        __valigned__ float wbuf[9];\n",
      "        {\n",
      "            mdspan wG(Global, weight_g + c * 9, 9);\n",
      "            mdspan wL(Private, wbuf, 9);\n",
      "            tops::memcpy(dte_w, wL, wG);\n",
      "        }\n",
      "\n",
      "        vfloat wv0 = vbroadcast<vfloat>(wbuf[0]);\n",
      "        vfloat wv1 = vbroadcast<vfloat>(wbuf[1]);\n",
      "        vfloat wv2 = vbroadcast<vfloat>(wbuf[2]);\n",
      "        vfloat wv3 = vbroadcast<vfloat>(wbuf[3]);\n",
      "        vfloat wv4 = vbroadcast<vfloat>(wbuf[4]);\n",
      "        vfloat wv5 = vbroadcast<vfloat>(wbuf[5]);\n",
      "        vfloat wv6 = vbroadcast<vfloat>(wbuf[6]);\n",
      "        vfloat wv7 = vbroadcast<vfloat>(wbuf[7]);\n",
      "        vfloat wv8 = vbroadcast<vfloat>(wbuf[8]);\n",
      "\n",
      "        const int MAXW = 1024;\n",
      "        __valigned__ float rowA[MAXW], rowB[MAXW], rowC[MAXW];\n",
      "        __valigned__ float out_row[MAXW];\n",
      "\n",
      "        // 预取第一条输出行需要的3行\n",
      "        auto load_row_or_zero = [&](float* dst, int ih) {\n",
      "            if (ih >= 0 && ih < IH) {\n",
      "                mdspan g(Global, inp_g + (c * IH + ih) * IW, IW);\n",
      "                mdspan p(Private, dst, IW);\n",
      "                tops::memcpy(dte_in, p, g);\n",
      "            } else {\n",
      "                for (int i = 0; i < IW; ++i) dst[i] = 0.f;\n",
      "            }\n",
      "        };\n",
      "\n",
      "        int prev_in_base = -999999;\n",
      "        int prev_ihs[3] = { -999999, -999999, -999999 };\n",
      "\n",
      "        for (int oh = 0; oh < OH; ++oh) {\n",
      "            int in_h_base = oh * stride - padding;\n",
      "            int ihs_cur[3] = {\n",
      "                in_h_base + 0 * dilation,\n",
      "                in_h_base + 1 * dilation,\n",
      "                in_h_base + 2 * dilation\n",
      "            };\n",
      "\n",
      "            // 滚动复用：如果与前一行共享行则只更新变化的行\n",
      "            if (oh == 0) {\n",
      "                load_row_or_zero(rowA, ihs_cur[0]);\n",
      "                load_row_or_zero(rowB, ihs_cur[1]);\n",
      "                load_row_or_zero(rowC, ihs_cur[2]);\n",
      "            } else {\n",
      "                // 与 prev_ihs 比较，找出需更新的行\n",
      "                // 典型stride=1时，oh+1 的 3 行集合 = prev的 {B,C, new}\n",
      "                if (ihs_cur[0] != prev_ihs[0] && ihs_cur[0] != prev_ihs[1] && ihs_cur[0] != prev_ihs[2]) {\n",
      "                    load_row_or_zero(rowA, ihs_cur[0]);\n",
      "                } else {\n",
      "                    // 将已有的匹配行拷到rowA\n",
      "                    if (ihs_cur[0] == prev_ihs[1]) { for (int i=0;i<IW;++i) rowA[i]=rowB[i]; }\n",
      "                    else if (ihs_cur[0] == prev_ihs[2]) { for (int i=0;i<IW;++i) rowA[i]=rowC[i]; }\n",
      "                }\n",
      "\n",
      "                if (ihs_cur[1] != prev_ihs[0] && ihs_cur[1] != prev_ihs[1] && ihs_cur[1] != prev_ihs[2]) {\n",
      "                    load_row_or_zero(rowB, ihs_cur[1]);\n",
      "                } else {\n",
      "                    if (ihs_cur[1] == prev_ihs[0]) { for (int i=0;i<IW;++i) rowB[i]=rowA[i]; }\n",
      "                    else if (ihs_cur[1] == prev_ihs[2]) { for (int i=0;i<IW;++i) rowB[i]=rowC[i]; }\n",
      "                }\n",
      "\n",
      "                if (ihs_cur[2] != prev_ihs[0] && ihs_cur[2] != prev_ihs[1] && ihs_cur[2] != prev_ihs[2]) {\n",
      "                    load_row_or_zero(rowC, ihs_cur[2]);\n",
      "                } else {\n",
      "                    if (ihs_cur[2] == prev_ihs[0]) { for (int i=0;i<IW;++i) rowC[i]=rowA[i]; }\n",
      "                    else if (ihs_cur[2] == prev_ihs[1]) { for (int i=0;i<IW;++i) rowC[i]=rowB[i]; }\n",
      "                }\n",
      "            }\n",
      "            prev_in_base = in_h_base;\n",
      "            prev_ihs[0] = ihs_cur[0]; prev_ihs[1] = ihs_cur[1]; prev_ihs[2] = ihs_cur[2];\n",
      "\n",
      "            // 计算当前输出行\n",
      "            if (dilation == 1 && stride == 1) {\n",
      "                // 三行滑窗寄存器缓存：以块为单位，vector优先，中间区域无边界分支\n",
      "                int ow = 0;\n",
      "\n",
      "                // 左端标量边界\n",
      "                int left_non_vec = min(OW, max(0, padding));\n",
      "                for (; ow < left_non_vec; ++ow) {\n",
      "                    int base_w = ow - padding;\n",
      "                    float acc = 0.f;\n",
      "                    for (int kw = 0; kw < 3; ++kw) {\n",
      "                        int x = base_w + kw;\n",
      "                        float a = (x >= 0 && x < IW) ? rowA[x] : 0.f;\n",
      "                        float b = (x >= 0 && x < IW) ? rowB[x] : 0.f;\n",
      "                        float cval = (x >= 0 && x < IW) ? rowC[x] : 0.f;\n",
      "                        acc += a * wbuf[0 + kw];\n",
      "                        acc += b * wbuf[3 + kw];\n",
      "                        acc += cval * wbuf[6 + kw];\n",
      "                    }\n",
      "                    out_row[ow] = acc;\n",
      "                }\n",
      "\n",
      "                // 中间向量段\n",
      "                int ow_mid_begin = max(ow, padding);\n",
      "                int ow_mid_end = min(OW, IW - 2 + padding);\n",
      "                int ow_mid = ow_mid_begin;\n",
      "\n",
      "                // 主批量：一次处理 V*6 (=192) 的输出，以内循环展开提升ILP\n",
      "                const int STEP = V * 6;\n",
      "                for (; ow_mid + STEP <= ow_mid_end; ow_mid += STEP) {\n",
      "                    #pragma unroll\n",
      "                    for (int t = 0; t < 6; ++t) {\n",
      "                        int o = ow_mid + t * V;\n",
      "                        int x0 = o - padding + 0;\n",
      "                        int x1 = o - padding + 1;\n",
      "                        int x2 = o - padding + 2;\n",
      "\n",
      "                        vfloat a0 = vload<vfloat>(rowA + x0);\n",
      "                        vfloat a1 = vload<vfloat>(rowA + x1);\n",
      "                        vfloat a2 = vload<vfloat>(rowA + x2);\n",
      "                        vfloat b0 = vload<vfloat>(rowB + x0);\n",
      "                        vfloat b1 = vload<vfloat>(rowB + x1);\n",
      "                        vfloat b2 = vload<vfloat>(rowB + x2);\n",
      "                        vfloat c0 = vload<vfloat>(rowC + x0);\n",
      "                        vfloat c1 = vload<vfloat>(rowC + x1);\n",
      "                        vfloat c2 = vload<vfloat>(rowC + x2);\n",
      "\n",
      "                        vfloat accv = vadd(vmul(a0, wv0), vmul(a1, wv1));\n",
      "                        accv = vadd(accv, vmul(a2, wv2));\n",
      "                        accv = vadd(accv, vmul(b0, wv3));\n",
      "                        accv = vadd(accv, vmul(b1, wv4));\n",
      "                        accv = vadd(accv, vmul(b2, wv5));\n",
      "                        accv = vadd(accv, vmul(c0, wv6));\n",
      "                        accv = vadd(accv, vmul(c1, wv7));\n",
      "                        accv = vadd(accv, vmul(c2, wv8));\n",
      "\n",
      "                        vstore(accv, out_row + o);\n",
      "                    }\n",
      "                }\n",
      "                // 次级批量：V 对齐\n",
      "                for (; ow_mid + V <= ow_mid_end; ow_mid += V) {\n",
      "                    int o = ow_mid;\n",
      "                    int x0 = o - padding + 0;\n",
      "                    int x1 = o - padding + 1;\n",
      "                    int x2 = o - padding + 2;\n",
      "\n",
      "                    vfloat a0 = vload<vfloat>(rowA + x0);\n",
      "                    vfloat a1 = vload<vfloat>(rowA + x1);\n",
      "                    vfloat a2 = vload<vfloat>(rowA + x2);\n",
      "                    vfloat b0 = vload<vfloat>(rowB + x0);\n",
      "                    vfloat b1 = vload<vfloat>(rowB + x1);\n",
      "                    vfloat b2 = vload<vfloat>(rowB + x2);\n",
      "                    vfloat c0 = vload<vfloat>(rowC + x0);\n",
      "                    vfloat c1 = vload<vfloat>(rowC + x1);\n",
      "                    vfloat c2 = vload<vfloat>(rowC + x2);\n",
      "\n",
      "                    vfloat accv = vadd(vmul(a0, wv0), vmul(a1, wv1));\n",
      "                    accv = vadd(accv, vmul(a2, wv2));\n",
      "                    accv = vadd(accv, vmul(b0, wv3));\n",
      "                    accv = vadd(accv, vmul(b1, wv4));\n",
      "                    accv = vadd(accv, vmul(b2, wv5));\n",
      "                    accv = vadd(accv, vmul(c0, wv6));\n",
      "                    accv = vadd(accv, vmul(c1, wv7));\n",
      "                    accv = vadd(accv, vmul(c2, wv8));\n",
      "\n",
      "                    vstore(accv, out_row + o);\n",
      "                }\n",
      "\n",
      "                // 右端尾部\n",
      "                for (int o = ow_mid; o < OW; ++o) {\n",
      "                    int base_w = o - padding;\n",
      "                    float acc = 0.f;\n",
      "                    for (int kw = 0; kw < 3; ++kw) {\n",
      "                        int x = base_w + kw;\n",
      "                        float a = (x >= 0 && x < IW) ? rowA[x] : 0.f;\n",
      "                        float b = (x >= 0 && x < IW) ? rowB[x] : 0.f;\n",
      "                        float cv = (x >= 0 && x < IW) ? rowC[x] : 0.f;\n",
      "                        acc += a * wbuf[0 + kw];\n",
      "                        acc += b * wbuf[3 + kw];\n",
      "                        acc += cv * wbuf[6 + kw];\n",
      "                    }\n",
      "                    out_row[o] = acc;\n",
      "                }\n",
      "            } else {\n",
      "                // 通用路径：标量滑窗\n",
      "                for (int ow = 0; ow < OW; ++ow) {\n",
      "                    int base_w = ow * stride - padding;\n",
      "                    float acc = 0.f;\n",
      "                    for (int kw = 0; kw < 3; ++kw) {\n",
      "                        int x = base_w + kw * dilation;\n",
      "                        float a = (x >= 0 && x < IW) ? rowA[x] : 0.f;\n",
      "                        float b = (x >= 0 && x < IW) ? rowB[x] : 0.f;\n",
      "                        float cv = (x >= 0 && x < IW) ? rowC[x] : 0.f;\n",
      "                        acc += a * wbuf[0 + kw];\n",
      "                        acc += b * wbuf[3 + kw];\n",
      "                        acc += cv * wbuf[6 + kw];\n",
      "                    }\n",
      "                    out_row[ow] = acc;\n",
      "                }\n",
      "            }\n",
      "\n",
      "            // 写回\n",
      "            {\n",
      "                mdspan oL(Private, out_row, OW);\n",
      "                mdspan oG(Global, out_g + (c * OH + oh) * OW, OW);\n",
      "                tops::memcpy(dte_out, oG, oL);\n",
      "            }\n",
      "        }\n",
      "\n",
      "        dte_w.destroy(); dte_in.destroy(); dte_out.destroy();\n",
      "    }\n",
      "}\n",
      "\n",
      "void GCU_Conv2D(int C, int IH, int IW, int stride, int padding, int dilation,\n",
      "                float * __restrict dev_inp,\n",
      "                float * __restrict dev_weight,\n",
      "                float * __restrict dev_out)\n",
      "{\n",
      "    int threads = 12;\n",
      "    int blocks = div_up_host(C, threads);\n",
      "    if (blocks < 1) blocks = 1;\n",
      "    dwconv3x3_row_rolling_prefetch_kernel<<<blocks, threads>>>(\n",
      "        C, IH, IW, stride, padding, dilation, dev_inp, dev_weight, dev_out);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(kkk[0][0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_results(item):\n",
    "    goal = item.property_list[0]\n",
    "    print(goal)\n",
    "    mol = item\n",
    "    con = mol.constraints\n",
    "\n",
    "    # 没有 time_comparison → 0分\n",
    "    if not con or \"time_comparison\" not in con:\n",
    "        mol.total = 0.0\n",
    "        mol.property[goal] = 100\n",
    "        mol.scores = [1.0]\n",
    "        return mol\n",
    "\n",
    "    # 把当前 item 的 time_comparison 转成字典形式方便查找\n",
    "    item_times = {}\n",
    "    for d in con[\"time_comparison\"]:\n",
    "        name = d.get(\"name\")\n",
    "        avg_str = d.get(\"avg\")\n",
    "        if name and avg_str:\n",
    "            avg_us = float(re.findall(r\"[\\d.]+\", avg_str)[0])\n",
    "            item_times[name] = avg_us\n",
    "\n",
    "    # 按 best_times 为主来循环\n",
    "    scores = []\n",
    "    for name, ref_best in best_times.items():\n",
    "        if name not in item_times:\n",
    "            # 这个 name 测试缺失（例如 MLP7）→ 记 0 分\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "        \n",
    "        avg_us = item_times[name]\n",
    "        scores.append(ref_best / avg_us*100)\n",
    "    mol.total = sum(scores) / len(scores) \n",
    "    mol.property[goal] = mol.total\n",
    "    mol.scores = [1 - mol.total/100]\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "29ac68ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['history', 'init_pops', 'final_pops', 'all_mols', 'properties', 'evaluation', 'running_time'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd24786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"title\": \"可落地的高性能经验\",\n",
    "    \"author\": \"姜诗蕴\",\n",
    "    \"content\": \"这是一段测试文字。\"\n",
    "}\n",
    "\n",
    "# 正确写法：ensure_ascii=False\n",
    "with open(\"example.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c571bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77051611",
   "metadata": {},
   "source": [
    "## 石化分子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0456f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:57] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Diversity: 0.8939171963589432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:42:58] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CCCCN',\n",
       " 'c1ccccc1',\n",
       " 'O=CO',\n",
       " 'CC(C)Br',\n",
       " 'C=CCCl',\n",
       " 'CC=CC',\n",
       " 'CNC',\n",
       " 'CCNC(=O)O',\n",
       " 'COC',\n",
       " 'CCl',\n",
       " 'CCN(C)C',\n",
       " 'CF',\n",
       " 'CC(N)=O',\n",
       " 'CCOCC',\n",
       " 'CC(O)CO',\n",
       " 'CCCCl',\n",
       " 'CCCOC',\n",
       " 'CCBr',\n",
       " 'CBr',\n",
       " 'CCO']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import random\n",
    "from tdc import Oracle\n",
    "diversity_scorer = Oracle(name='diversity')\n",
    "\n",
    "def compute_tanimoto_matrix(fps):\n",
    "    \"\"\"计算指纹间的Tanimoto相似度矩阵\"\"\"\n",
    "    n = len(fps)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            sim = DataStructs.TanimotoSimilarity(fps[i], fps[j])\n",
    "            sim_matrix[i, j] = sim_matrix[j, i] = sim\n",
    "    return sim_matrix\n",
    "\n",
    "def maxmin_diversity_selection(smiles_list, subset_size=20, seed=42):\n",
    "    \"\"\"从SMILES列表中选出多样性最大的子集（MaxMin贪心法）\"\"\"\n",
    "    random.seed(seed)\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
    "    mols = [i for i in mols if i is not None]\n",
    "    smiles_list = [Chem.MolToSmiles(m) for m in mols]\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(m, radius=2, nBits=2048) for m in mols]\n",
    "    sim_matrix = compute_tanimoto_matrix(fps)\n",
    "    \n",
    "    n = len(smiles_list)\n",
    "    # 随机选一个起点\n",
    "    selected = [random.randint(0, n - 1)]\n",
    "    remaining = list(set(range(n)) - set(selected))\n",
    "    \n",
    "    # 逐步选择与当前集合最不相似的分子\n",
    "    while len(selected) < subset_size:\n",
    "        # 计算每个未选分子与已选分子的最大相似度\n",
    "        max_sims = [max(sim_matrix[i][selected]) for i in remaining]\n",
    "        # 选择最大相似度最小的那个分子（即最不相似的）\n",
    "        next_idx = remaining[int(np.argmin(max_sims))]\n",
    "        selected.append(next_idx)\n",
    "        remaining.remove(next_idx)\n",
    "    \n",
    "    # 计算最终子集的平均相似度\n",
    "    sub_sims = []\n",
    "    for i in range(len(selected)):\n",
    "        for j in range(i + 1, len(selected)):\n",
    "            sub_sims.append(sim_matrix[selected[i]][selected[j]])\n",
    "    avg_sim = np.mean(sub_sims)\n",
    "    diversity = 1 - avg_sim\n",
    "    selected = [smiles_list[i] for i in selected]\n",
    "    return selected, avg_sim, diversity\n",
    "\n",
    "# ===============================\n",
    "# 示例用法\n",
    "# ===============================\n",
    "# 假设你有50个分子（这里用简单示例代替）\n",
    "smiles_list = [\n",
    "    \"CCO\", \"CCC\", \"CCN\", \"CCCl\", \"CCBr\", \"C1=CC=CC=C1\", \"C=CC\", \"CNC\", \"CC(C)O\",\n",
    "    \"CCOC\", \"CCS\", \"CCF\", \"CC=O\", \"CCCO\", \"CCCN\", \"CCCF\", \"COC\", \"CCOCC\", \"C=CCCl\",\n",
    "    \"CCNC(=O)O\", \"CCCCl\", \"CCCC\", \"CCBrO\", \"CCClO\", \"CC=CC\", \"CCCBr\", \"CCC(=O)O\",\n",
    "    \"CC(C)Cl\", \"CC(C)Br\", \"CC(C)F\", \"CCCCO\", \"CCCCN\", \"CCCOC\", \"CCl\", \"CBr\", \"CF\",\n",
    "    \"CCN(C)C\", \"CNC(=O)C\", \"CC(=O)N\", \"C(=O)O\", \"CC(O)C\", \"CC(C)C\", \"CCCOC(=O)N\",\n",
    "    \"CC(O)CO\", \"CC(=O)O\", \"C=CO\", \"C=CCO\", \"C=CCN\", \"C=CCCl\", \"C=CCBr\", \"C=CCF\"\n",
    "]\n",
    "\n",
    "best = None\n",
    "for seed in range(10):\n",
    "    sel, avg, div = maxmin_diversity_selection(smiles_list, 20, seed)\n",
    "    if best is None or div > best[2]:\n",
    "        best = (sel, avg, div)\n",
    "print(\"最佳 Diversity:\", best[2])\n",
    "sel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4aa39df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'molecular_weight': 130.18699999999998,\n",
       "  'sa_score': 3.2731448214527816,\n",
       "  'homo_lumo_gap_au': 0.306,\n",
       "  'dipole_moment_debye': 2.3085},\n",
       " 1006)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "all_mols = []\n",
    "all_smiles = []\n",
    "with open('/root/nian/mollm_results/shihua_mol/zgca,gpt-5-minimal/mols/molecular_weight_sa_score_homo_lumo_gap_au_dipole_moment_debye_1020_constraint5_42.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "all_mols.extend(mols)\n",
    "all_smiles.extend([i.value for i in mols])\n",
    "mols[0].property,len(mols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e07baa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'molecular_weight': 127.18699999999998,\n",
       "  'sa_score': 3.2885291550679927,\n",
       "  'homo_lumo_gap_au': 0.2979,\n",
       "  'dipole_moment_debye': 2.249},\n",
       " 416,\n",
       " 1413)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/shihua_mol/zgca,gpt-5-minimal/mols/molecular_weight_sa_score_homo_lumo_gap_au_dipole_moment_debye_1020_constraint5_43.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "for mol in mols:\n",
    "    if mol.value not in all_smiles:\n",
    "        all_mols.append(mol)\n",
    "        all_smiles.append(mol.value)\n",
    "mols[0].property,len(mols),len(all_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5316cb3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_smiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m mols \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_mols\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mol \u001b[38;5;129;01min\u001b[39;00m mols:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mol\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_smiles\u001b[49m:\n\u001b[1;32m      8\u001b[0m         all_mols\u001b[38;5;241m.\u001b[39mappend(mol)\n\u001b[1;32m      9\u001b[0m         all_smiles\u001b[38;5;241m.\u001b[39mappend(mol\u001b[38;5;241m.\u001b[39mvalue)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_smiles' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/shihua_mol/zgca,gpt-5-minimal/mols/molecular_weight_sa_score_homo_lumo_gap_au_dipole_moment_debye_1020_43.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "for mol in mols:\n",
    "    if mol.value not in all_smiles:\n",
    "        all_mols.append(mol)\n",
    "        all_smiles.append(mol.value)\n",
    "mols[0].property,len(mols),len(all_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "65a2f14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'molecular_weight': 130.23100000000002,\n",
       "  'sa_score': 2.2346510841486342,\n",
       "  'homo_lumo_gap_au': 0.3422,\n",
       "  'dipole_moment_debye': 1.3219},\n",
       " 404,\n",
       " 2351)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/shihua_mol/zgca,gpt-5-minimal/mols/molecular_weight_sa_score_homo_lumo_gap_au_dipole_moment_debye_1020_constraint_3_42.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "for mol in mols:\n",
    "    if mol.value not in all_smiles:\n",
    "        all_mols.append(mol)\n",
    "        all_smiles.append(mol.value)\n",
    "mols[0].property,len(mols),len(all_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92f17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>sa_score</th>\n",
       "      <th>homo_lumo_gap_au</th>\n",
       "      <th>dipole_moment_debye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)(C)C1CCCO1</td>\n",
       "      <td>128.215</td>\n",
       "      <td>3.093616</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>1.434600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1CCC2CCC12O</td>\n",
       "      <td>126.199</td>\n",
       "      <td>3.793891</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>1.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1OCC(O)CO1</td>\n",
       "      <td>118.132</td>\n",
       "      <td>3.278211</td>\n",
       "      <td>0.330300</td>\n",
       "      <td>1.901600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1CC2CCC2C1O</td>\n",
       "      <td>126.199</td>\n",
       "      <td>3.763289</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>1.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COCCCC(O)CO</td>\n",
       "      <td>134.175</td>\n",
       "      <td>2.612727</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>2.914600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>CC1OCC2(O)C1CC1OC(COC(=O)OC(C)(C)C)CC12</td>\n",
       "      <td>314.378</td>\n",
       "      <td>4.623851</td>\n",
       "      <td>0.280229</td>\n",
       "      <td>0.754659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>CC(C)COC(=O)CN1CCOC(CCl)C1</td>\n",
       "      <td>249.738</td>\n",
       "      <td>2.922103</td>\n",
       "      <td>0.204387</td>\n",
       "      <td>2.841036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>CC(COC(=O)C(C)C)OC(C)(C)CO</td>\n",
       "      <td>218.293</td>\n",
       "      <td>3.300918</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>1.540837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>CC(C)(C)OC(=O)N1CC2OC(CCl)C(O)C2C1</td>\n",
       "      <td>277.748</td>\n",
       "      <td>4.013255</td>\n",
       "      <td>0.256753</td>\n",
       "      <td>3.608903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>CC1OC2CN(C(=O)OCC(C)(C)Cl)CC2C1O</td>\n",
       "      <td>277.748</td>\n",
       "      <td>4.328563</td>\n",
       "      <td>0.263408</td>\n",
       "      <td>4.251726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SMILES  molecular_weight  sa_score  \\\n",
       "0                            CC(C)(C)C1CCCO1           128.215  3.093616   \n",
       "1                              CC1CCC2CCC12O           126.199  3.793891   \n",
       "2                               CC1OCC(O)CO1           118.132  3.278211   \n",
       "3                              CC1CC2CCC2C1O           126.199  3.763289   \n",
       "4                                COCCCC(O)CO           134.175  2.612727   \n",
       "..                                       ...               ...       ...   \n",
       "533  CC1OCC2(O)C1CC1OC(COC(=O)OC(C)(C)C)CC12           314.378  4.623851   \n",
       "534               CC(C)COC(=O)CN1CCOC(CCl)C1           249.738  2.922103   \n",
       "535               CC(COC(=O)C(C)C)OC(C)(C)CO           218.293  3.300918   \n",
       "536       CC(C)(C)OC(=O)N1CC2OC(CCl)C(O)C2C1           277.748  4.013255   \n",
       "537         CC1OC2CN(C(=O)OCC(C)(C)Cl)CC2C1O           277.748  4.328563   \n",
       "\n",
       "     homo_lumo_gap_au  dipole_moment_debye  \n",
       "0            0.314700             1.434600  \n",
       "1            0.317100             1.258700  \n",
       "2            0.330300             1.901600  \n",
       "3            0.316000             1.352800  \n",
       "4            0.315200             2.914600  \n",
       "..                ...                  ...  \n",
       "533          0.280229             0.754659  \n",
       "534          0.204387             2.841036  \n",
       "535          0.256609             1.540837  \n",
       "536          0.256753             3.608903  \n",
       "537          0.263408             4.251726  \n",
       "\n",
       "[538 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#mols = all_mols\n",
    "df = pd.DataFrame({\n",
    "    'SMILES': [i.value for i in mols],\n",
    "    'molecular_weight': [i.property['molecular_weight'] for i in mols],\n",
    "    'sa_score': [i.property['sa_score'] for i in mols],\n",
    "    'homo_lumo_gap_au': [i.property['homo_lumo_gap_au'] for i in mols],\n",
    "    'dipole_moment_debye': [i.property['dipole_moment_debye'] for i in mols]\n",
    "})\n",
    "df.to_csv('/root/nian/MOLLM/problem/shihua_mol/start_mols.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562c5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 5)\n",
      "(13, 5)\n",
      "(2, 5)\n",
      "(35, 5)\n",
      "(0, 5)\n"
     ]
    }
   ],
   "source": [
    "constraints = [\n",
    "    {\"constraint_id\": \"test_001\", \"molecular_weight\": [200, 350], \"sa_score\": [1, 4], \"homo_lumo_gap\": [0.25, 0.35], \"dipole_moment\": [1.0, 3.0]},\n",
    "{\"constraint_id\": \"test_002\", \"molecular_weight\": [350, 500], \"sa_score\": [3, 6], \"homo_lumo_gap\": [0.20, 0.30], \"dipole_moment\": [2.0, 5.0]},\n",
    "{\"constraint_id\": \"test_003\", \"molecular_weight\": [150, 250], \"sa_score\": [1, 3.5], \"homo_lumo_gap\": [0.30, 0.40], \"dipole_moment\": [0.0, 1.5]},\n",
    "{\"constraint_id\": \"test_004\", \"molecular_weight\": [250, 400], \"sa_score\": [2.5, 5.5], \"homo_lumo_gap\": [0.22, 0.32], \"dipole_moment\": [4.0, 7.0]},\n",
    "{\"constraint_id\": \"test_005\", \"molecular_weight\": [280, 320], \"sa_score\": [2.0, 3.5], \"homo_lumo_gap\": [0.29, 0.31], \"dipole_moment\": [1.5, 2.5]}\n",
    "]\n",
    "for constraint in constraints:\n",
    "    df_filtered = df[\n",
    "        (df[\"molecular_weight\"].between(*constraint[\"molecular_weight\"])) &\n",
    "        (df[\"sa_score\"].between(*constraint[\"sa_score\"])) &\n",
    "        (df[\"homo_lumo_gap_au\"].between(*constraint[\"homo_lumo_gap\"])) &\n",
    "        (df[\"dipole_moment_debye\"].between(*constraint[\"dipole_moment\"]))\n",
    "    ]\n",
    "    print(df_filtered.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4564875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳 Diversity: 0.8281878091664023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:37:07] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CC(COC(=O)C(C)(C)Cl)OC(C)(C)CI',\n",
       " 'CC1CCC(C2OC(C)(C)OC2COC2OCCN(C(C)C)C2=O)CC1',\n",
       " 'CC(C)(C)OC1C(O)OC(CO)C(O)C1OC(=O)NCC1OCCCO1',\n",
       " 'CC(F)(F)OC(=O)N1CC(COC2(C)OC3(COC3)OC2C(F)(F)F)C1',\n",
       " 'CC(C)(C)OCCOC(CO)COC(=O)OC(C)(C)c1ccccc1',\n",
       " 'CC(C)COC(=O)NCC1CCOCC1c1ccc(Cl)c(Cl)c1',\n",
       " 'CC(C)(C)C(C(=O)OCCBr)(c1ccc(Cl)cc1)C(F)(F)F',\n",
       " 'CC(C)(C)OC(=O)OC1OC(OC(C)(C)C)CC1OC(C)(C)Cl',\n",
       " 'CC(C)(C)NC(=O)OCC1OC1C(C)(C)CI',\n",
       " 'CC(=O)OCC1OC(COC(C)(C)Cl)C(O)C(O)C1OCCOC(C)C',\n",
       " 'CN(CCCl)C(=O)C(COC(=O)N(C)c1ccccc1)OC(C)(C)C',\n",
       " 'CCN1CCOC(CNC(=O)OCC(C)(C)C)C1c1ccc(F)cc1',\n",
       " 'CC(=O)OC1C(CO)OC(OC(C)(C)C)C(O)C1Oc1ccccc1',\n",
       " 'CC(C)(F)OC(=O)N1CC(C(C)(C)C)OC(C(F)(F)C2OC(C)(C)O2)C1',\n",
       " 'CC(C)(C)OC(=O)NCCOC(CCl)COC(=O)OC(C)(C)C',\n",
       " 'CC(COC(=O)NCC1CCOCC1)OC(C)(C)CBr',\n",
       " 'CC(=O)OC1C(COC(C)(C)Cl)OC(C)C(OC(C)(C)Cl)C1O',\n",
       " 'CC(C)(F)OC(=O)N1CC2OC(C(C)(C)F)(C(F)(F)C3OC(C)(C)O3)OC2C1',\n",
       " 'CC1CCC(C2OC(C)(C)OC2COC2OCCN(C(C)C)C2=O)CC1',\n",
       " 'CC(C)(C)NC(=O)OCC1OC1C(C)(C)CI']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = None\n",
    "smiles_list = df_filtered['SMILES'].tolist()\n",
    "smiles_list += smiles_list[:10] \n",
    "for seed in range(10):\n",
    "    sel, avg, div = maxmin_diversity_selection(smiles_list, 20, seed)\n",
    "    if best is None or div > best[2]:\n",
    "        best = (sel, avg, div)\n",
    "print(\"最佳 Diversity:\", best[2])\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e0dafa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'molecular_weight': 0.015289999999999963,\n",
       "  'sa_score': 0.10127243320952921,\n",
       "  'homo_lumo_gap_au': 0.047372283212956,\n",
       "  'dipole_moment_debye': 0.04464978105809832},\n",
       " 3.7914155025194165,\n",
       " 1023)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/shihua_mol/zgca,gpt-5-minimal/mols/molecular_weight_sa_score_homo_lumo_gap_au_dipole_moment_debye_new_score_constraint5_47.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "mols = sorted(mols,key=lambda x:x.total,reverse=True)\n",
    "mols[0].property,mols[0].total,len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c1ea40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'molecular_weight': 298.471,\n",
       " 'sa_score': 3.762724332095292,\n",
       " 'homo_lumo_gap_au': 0.252627716787044,\n",
       " 'dipole_moment_debye': 2.446497810580983}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols[0].constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5d1f85af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN(CC1CO1)C(=O)C(c1ccc(F)cc1)C(F)(F)F,291.244,3.3253411611426102,0.2134871965390492,2.0201057308730253\n",
      "COc1ccc2ccc(OC)c(CN(CCO)CCO)c2c1,305.374,2.1975791884522664,0.1487611918060252,2.2722831328119755\n",
      "CC(C)(C)OC(=O)C1CCN(C(=O)OC(C)(C)C)CC1,285.384,2.045824375273094,0.2273361871940214,2.5686017994692167\n",
      "O=C(c1cccc(Cl)c1)N(CCO)CCBr,306.587,2.168015957865814,0.2175759604231031,3.53267574812644\n",
      "OCCOCCn1ccc2cc(O)c(Br)cc21,300.15200000000004,2.518898312609787,0.1726227528594019,4.256679288171063\n",
      "Cn1c(=O)n(-c2ccccc2)n(-c2ccc(F)cc2)c1=O,285.278,2.1983802566772805,0.1942642307822674,1.1020844690302984\n",
      "O=C(OCCCO)c1c(Cl)cc(Cl)c(Cl)c1Cl,317.98300000000006,2.301820427994402,0.2067988003106018,3.506698806771414\n",
      "COc1cc2ccc(CCN3CCOCC3)cc2cc1O,287.3589999999999,2.0408312622985,0.1625387605829231,3.738730386617634\n",
      "OCCOCCn1cc(CCO)c2cc(Cl)ccc21,283.755,2.335533558909132,0.1757209423930069,5.16197307630347\n"
     ]
    }
   ],
   "source": [
    "constraint = {\"constraint_id\": \"test_005\", \"molecular_weight\": [280, 320], \"sa_score\": [2.0, 3.5], \"homo_lumo_gap\": [0.29, 0.31], \"dipole_moment\": [1.5, 2.5]}\n",
    "i = 0\n",
    "for mol in mols:\n",
    "    if constraint['sa_score'][0]<=mol.constraints['sa_score']<=constraint['sa_score'][1] \\\n",
    "        and constraint['molecular_weight'][0]<=mol.constraints['molecular_weight']<=constraint['molecular_weight'][1] :\n",
    "        print(f\"{mol.value},{mol.constraints['molecular_weight']},{mol.constraints['sa_score']},{mol.constraints['homo_lumo_gap_au']},{mol.constraints['dipole_moment_debye']}\")\n",
    "        i += 1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "121ebd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = df_filtered['SMILES'].tolist()\n",
    "diversity_scorer(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0fe45aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'constraint_id': 'test_001',\n",
       "  'molecular_weight': [200, 350],\n",
       "  'sa_score': [1, 4],\n",
       "  'homo_lumo_gap': [0.25, 0.35],\n",
       "  'dipole_moment': [1.0, 3.0]},\n",
       " {'constraint_id': 'test_002',\n",
       "  'molecular_weight': [350, 500],\n",
       "  'sa_score': [3, 6],\n",
       "  'homo_lumo_gap': [0.2, 0.3],\n",
       "  'dipole_moment': [2.0, 5.0]},\n",
       " {'constraint_id': 'test_003',\n",
       "  'molecular_weight': [150, 250],\n",
       "  'sa_score': [1, 3.5],\n",
       "  'homo_lumo_gap': [0.3, 0.4],\n",
       "  'dipole_moment': [0.0, 1.5]},\n",
       " {'constraint_id': 'test_004',\n",
       "  'molecular_weight': [250, 400],\n",
       "  'sa_score': [2.5, 5.5],\n",
       "  'homo_lumo_gap': [0.22, 0.32],\n",
       "  'dipole_moment': [4.0, 7.0]},\n",
       " {'constraint_id': 'test_005',\n",
       "  'molecular_weight': [280, 320],\n",
       "  'sa_score': [2.0, 3.5],\n",
       "  'homo_lumo_gap': [0.29, 0.31],\n",
       "  'dipole_moment': [1.5, 2.5]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "constraints = []\n",
    "with open('/root/nian/初赛约束条件.jsonl','r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        constraints.append(data)\n",
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d04d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[尝试 1/3] 提交成功, result_id=44789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "BASE_URL = \"http://119.4.205.3:8008/api\"\n",
    "COOKIE = {\"ocp_token\": \"66b5d454-f3f2-4836-814e-81bc48b2762b\"}  # 你的登录 cookie\n",
    "def auto_submit(problem_id: int, code: str, wait_interval: int = 10, timeout: int = 360, max_retries: int = 3):\n",
    "    \"\"\"\n",
    "    自动提交代码并获取最终分数，带重试逻辑\n",
    "    :param problem_id: 题目编号 (int)\n",
    "    :param code: 代码 (str)\n",
    "    :param wait_interval: 轮询间隔秒数\n",
    "    :param timeout: 超时时间（秒）\n",
    "    :param max_retries: 平台出错时最大重试次数\n",
    "    :return: (status, score, log)\n",
    "             status: \"success\" / \"failed\" / \"platform_error\"\n",
    "             score: str or None\n",
    "             log: str\n",
    "    \"\"\"\n",
    "    new_times = []\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        # Step 1. 提交代码\n",
    "        submit_url = f\"{BASE_URL}/answers/submit\"\n",
    "        payload = {\"answer\": code, \"problems_id\": problem_id}\n",
    "        r = requests.post(submit_url, json=payload, cookies=COOKIE)\n",
    "        e = None\n",
    "        try:\n",
    "            r.raise_for_status()\n",
    "            res = r.json()\n",
    "        except Exception as e:\n",
    "            res = e\n",
    "        log = \"\"\n",
    "        if not res.get(\"success\") or e:\n",
    "            print(f\"提交失败,准备重试: {res}\")\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            result_id = res[\"data\"][\"result_id\"]\n",
    "            print(f\"[尝试 {attempt}/{max_retries}] 提交成功, result_id={result_id}\")\n",
    "\n",
    "            # Step 2. 轮询判题结果\n",
    "            result_url = f\"{BASE_URL}/submissions/result?result_id={result_id}\"\n",
    "            start_time = time.time()\n",
    "            status = None\n",
    "\n",
    "            while True:\n",
    "                r = requests.get(result_url, cookies=COOKIE)\n",
    "                r.raise_for_status()\n",
    "                res = r.json()\n",
    "                # print(res)  # 调试用\n",
    "\n",
    "                jenkins_log = res.get(\"jenkins_log\", \"\")\n",
    "                if jenkins_log:\n",
    "                    log = jenkins_log\n",
    "\n",
    "                #build_status = res[\"data\"][\"build\"][\"status\"]\n",
    "                test_status = res[\"data\"][\"test\"][\"status\"]\n",
    "\n",
    "                if test_status in (\"success\", \"failed\"):\n",
    "                    status = test_status\n",
    "                    break\n",
    "\n",
    "                if time.time() - start_time > timeout:\n",
    "                    raise TimeoutError(\"等待超时，判题还没完成\")\n",
    "\n",
    "                time.sleep(wait_interval)\n",
    "\n",
    "            # Step 3. 查询最新提交分数\n",
    "            list_url = f\"{BASE_URL}/submissions/list?problem_id={problem_id}\"\n",
    "            r = requests.get(list_url, cookies=COOKIE)\n",
    "            r.raise_for_status()\n",
    "            res = r.json()\n",
    "\n",
    "            score = None\n",
    "            if res.get(\"success\") and \"data\" in res:\n",
    "                for item in res[\"data\"]:\n",
    "                    if item[\"result_id\"] == result_id:\n",
    "                        score = item.get(\"score\")\n",
    "                        times = item.get(\"time\")\n",
    "                        keep_names = ['name','avg','best']\n",
    "                        for t in times:\n",
    "                            new_times.append({\n",
    "                                key:t[key] for key in keep_names\n",
    "                            })\n",
    "                        break\n",
    "\n",
    "            # Step 4. 判断结果\n",
    "            if status == \"success\":\n",
    "                return \"success\", score, log, new_times\n",
    "\n",
    "            if status == \"failed\":\n",
    "                if \"no such file or directory\" in log:  # 平台出错\n",
    "                    print(\"⚠️ 平台异常: 文件缺失，30s 后重试\")\n",
    "                    if attempt < max_retries:\n",
    "                        time.sleep(30)\n",
    "                        continue\n",
    "                    else:\n",
    "                        return \"platform_error\", 0, log, new_times\n",
    "                else:\n",
    "                    return \"failed\", score, log, new_times\n",
    "    # 如果所有尝试都失败\n",
    "    return \"platform_error\", 0, log, new_times\n",
    "\n",
    "success,score,log,new_times  = auto_submit(16,all_mols[0][0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e27cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mols[0][0].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ef5076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <tops/tops_runtime.h>\n",
      "\n",
      "// ============================================================\n",
      "// GCU Depthwise Conv2D (3x3, stride ≤3, dilation ≤4, padding ≤5)\n",
      "// ============================================================\n",
      "\n",
      "__attribute__((global, cooperative))\n",
      "void kernel_depthwise_conv2d(float *__restrict inp,\n",
      "                             float *__restrict weight,\n",
      "                             float *__restrict out,\n",
      "                             const int C,\n",
      "                             const int IH, const int IW,\n",
      "                             const int stride,\n",
      "                             const int padding,\n",
      "                             const int dilation) {\n",
      "    // Thread info\n",
      "    int thread_idx = threadIdx.x;\n",
      "    int thread_num = blockDim.x;\n",
      "\n",
      "    // DTE context\n",
      "    tops_dte_ctx_t dte_in, dte_w, dte_out;\n",
      "    dte_in.init();\n",
      "    dte_w.init();\n",
      "    dte_out.init();\n",
      "\n",
      "    // L1 buffer\n",
      "    __local__ __valigned__ char l1_buffer[104000];\n",
      "    int used = 0;\n",
      "    float *win_buf = reinterpret_cast<float *>(l1_buffer + used);\n",
      "    used += 9 * sizeof(float);\n",
      "    float *w_buf = reinterpret_cast<float *>(l1_buffer + used);\n",
      "    used += 9 * sizeof(float);\n",
      "    float *out_val = reinterpret_cast<float *>(l1_buffer + used);\n",
      "    used += sizeof(float);\n",
      "\n",
      "    // 输出大小\n",
      "    int OH = (IH + 2 * padding - dilation * (3 - 1) - 1) / stride + 1;\n",
      "    int OW = (IW + 2 * padding - dilation * (3 - 1) - 1) / stride + 1;\n",
      "\n",
      "    // 每线程处理若干通道\n",
      "    int ch_per_thread = (C + thread_num - 1) / thread_num;\n",
      "    int c_start = thread_idx * ch_per_thread;\n",
      "    int c_end = (c_start + ch_per_thread < C) ? (c_start + ch_per_thread) : C;\n",
      "\n",
      "    for (int c = c_start; c < c_end; ++c) {\n",
      "        // load weight[c, 0, 3, 3]\n",
      "        {\n",
      "            int w_idx = c * 9;\n",
      "            tops::mdspan g_w(tops::Global, weight + w_idx, 9);\n",
      "            tops::mdspan p_w(tops::Private, w_buf, 9);\n",
      "            tops::memcpy(dte_w, p_w, g_w);\n",
      "        }\n",
      "\n",
      "        for (int oh = 0; oh < OH; ++oh) {\n",
      "            for (int ow = 0; ow < OW; ++ow) {\n",
      "                float acc = 0.f;\n",
      "\n",
      "                int base_h = oh * stride - padding;\n",
      "                int base_w = ow * stride - padding;\n",
      "\n",
      "                // 3x3 kernel\n",
      "                for (int kh = 0; kh < 3; ++kh) {\n",
      "                    for (int kw = 0; kw < 3; ++kw) {\n",
      "                        int ih = base_h + kh * dilation;\n",
      "                        int iw = base_w + kw * dilation;\n",
      "\n",
      "                        float val = 0.f;\n",
      "                        if (ih >= 0 && ih < IH && iw >= 0 && iw < IW) {\n",
      "                            int inp_idx = (c * IH + ih) * IW + iw;\n",
      "                            tops::mdspan g_in(tops::Global, inp + inp_idx, 1);\n",
      "                            tops::mdspan p_in(tops::Private, win_buf, 1);\n",
      "                            tops::memcpy(dte_in, p_in, g_in);\n",
      "                            val = win_buf[0];\n",
      "                        }\n",
      "                        acc += val * w_buf[kh * 3 + kw];\n",
      "                    }\n",
      "                }\n",
      "\n",
      "                // write output\n",
      "                out_val[0] = acc;\n",
      "                int out_idx = (c * OH + oh) * OW + ow;\n",
      "                tops::mdspan g_out(tops::Global, out + out_idx, 1);\n",
      "                tops::mdspan p_out(tops::Private, out_val, 1);\n",
      "                tops::memcpy(dte_out, g_out, p_out);\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "\n",
      "    dte_in.destroy();\n",
      "    dte_w.destroy();\n",
      "    dte_out.destroy();\n",
      "}\n",
      "\n",
      "// ============================================================\n",
      "// Host wrapper\n",
      "// ============================================================\n",
      "void GCU_Conv2D(int C, int IH, int IW,\n",
      "                int stride, int padding, int dilation,\n",
      "                float *__restrict dev_inp,\n",
      "                float *__restrict dev_weight,\n",
      "                float *__restrict dev_out) {\n",
      "    static const size_t blocks = 1;\n",
      "    static const size_t threads = 12; // GCU210 typical\n",
      "    kernel_depthwise_conv2d<<<blocks, threads>>>(\n",
      "        dev_inp, dev_weight, dev_out,\n",
      "        C, IH, IW, stride, padding, dilation);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(all_mols[0][0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25fb814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/root/nian/mollm_results/gcu/zgca,gpt-5/mols/gcu_var_0904_42.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()\n",
    "mols = [i[0] for i in a['all_mols']]\n",
    "mols[0].total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f1c1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols = sorted(mols,key=lambda x:x.total,reverse=True)\n",
    "mols[0].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39611803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "// 单线程高速路径：更大 tile + 双缓冲 + 4 向量累加（减少依赖链）\n",
      "__global__ void kernel_var_single3(float *inp, float *out, size_t nr_elems) {\n",
      "    if (threadIdx.x != 0) return;\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope scope(ctx);\n",
      "\n",
      "    float var = 0.0f;\n",
      "    if (nr_elems <= 1) {\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Global, out, 1),\n",
      "            tops::mdspan(tops::Private, &var, 1)\n",
      "        );\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    const int VLEN = tops::vlength<vfloat>();   // 32\n",
      "    const int TILE = VLEN * 2048;               // 65536 floats (~256KB) per buffer\n",
      "    __valigned__ float buf0[TILE];\n",
      "    __valigned__ float buf1[TILE];\n",
      "\n",
      "    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\n",
      "    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\n",
      "    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\n",
      "    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\n",
      "    float tail_sum = 0.f, tail_sqs = 0.f;\n",
      "\n",
      "    size_t i = 0;\n",
      "    int cur_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\n",
      "    tops::event ev = tops::memcpy_async(\n",
      "        ctx,\n",
      "        tops::mdspan(tops::Private, buf0, cur_len),\n",
      "        tops::mdspan(tops::Global,  inp + i, cur_len)\n",
      "    );\n",
      "    i += cur_len;\n",
      "    bool use0 = true;\n",
      "\n",
      "    while (true) {\n",
      "        bool has_next = (i < nr_elems);\n",
      "        tops::event ev_next;\n",
      "        int nxt_len = 0;\n",
      "        if (has_next) {\n",
      "            nxt_len = (int)((nr_elems - i) < (size_t)TILE ? (nr_elems - i) : (size_t)TILE);\n",
      "            ev_next = tops::memcpy_async(\n",
      "                ctx,\n",
      "                tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\n",
      "                tops::mdspan(tops::Global,  inp + i, nxt_len)\n",
      "            );\n",
      "            i += nxt_len;\n",
      "        }\n",
      "\n",
      "        tops::wait(ev);\n",
      "        float *cur = use0 ? buf0 : buf1;\n",
      "        const int n = cur_len;\n",
      "\n",
      "        int j = 0;\n",
      "        int vec4 = (n / (4*VLEN)) * (4*VLEN);\n",
      "        #pragma unroll 2\n",
      "        for (; j < vec4; j += 4*VLEN) {\n",
      "            auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\n",
      "            auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\n",
      "            auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\n",
      "            auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\n",
      "\n",
      "            vs0 = tops::vadd(vs0, v0);\n",
      "            vs1 = tops::vadd(vs1, v1);\n",
      "            vs2 = tops::vadd(vs2, v2);\n",
      "            vs3 = tops::vadd(vs3, v3);\n",
      "\n",
      "            auto w0 = tops::vmul<vfloat>(v0, v0);\n",
      "            auto w1 = tops::vmul<vfloat>(v1, v1);\n",
      "            auto w2 = tops::vmul<vfloat>(v2, v2);\n",
      "            auto w3 = tops::vmul<vfloat>(v3, v3);\n",
      "\n",
      "            vq0 = tops::vadd(vq0, w0);\n",
      "            vq1 = tops::vadd(vq1, w1);\n",
      "            vq2 = tops::vadd(vq2, w2);\n",
      "            vq3 = tops::vadd(vq3, w3);\n",
      "        }\n",
      "        int vec1 = ((n - j) / VLEN) * VLEN;\n",
      "        for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\n",
      "            auto v = tops::vload<vfloat>(cur + j);\n",
      "            vs0 = tops::vadd(vs0, v);\n",
      "            auto w = tops::vmul<vfloat>(v, v);\n",
      "            vq0 = tops::vadd(vq0, w);\n",
      "        }\n",
      "        for (; j < n; ++j) {\n",
      "            float x = cur[j];\n",
      "            tail_sum += x;\n",
      "            tail_sqs += x * x;\n",
      "        }\n",
      "\n",
      "        if (!has_next) break;\n",
      "        use0 = !use0;\n",
      "        cur_len = nxt_len;\n",
      "        ev = ev_next;\n",
      "    }\n",
      "\n",
      "    auto vs01 = tops::vadd(vs0, vs1);\n",
      "    auto vs23 = tops::vadd(vs2, vs3);\n",
      "    auto vs = tops::vadd(vs01, vs23);\n",
      "\n",
      "    auto vq01 = tops::vadd(vq0, vq1);\n",
      "    auto vq23 = tops::vadd(vq2, vq3);\n",
      "    auto vq = tops::vadd(vq01, vq23);\n",
      "\n",
      "    __valigned__ float tmp[128];\n",
      "    tops::vstore(vs, tmp);\n",
      "    float psum = tail_sum;\n",
      "    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\n",
      "    tops::vstore(vq, tmp);\n",
      "    float psqs = tail_sqs;\n",
      "    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\n",
      "\n",
      "    float Nf = (float)nr_elems;\n",
      "    float mu = psum / Nf;\n",
      "    var = (psqs - mu * psum) / (Nf - 1.0f);\n",
      "    if (var < 0.f && var > -1e-12f) var = 0.f;\n",
      "\n",
      "    tops::memcpy(ctx,\n",
      "        tops::mdspan(tops::Global, out, 1),\n",
      "        tops::mdspan(tops::Private, &var, 1)\n",
      "    );\n",
      "}\n",
      "\n",
      "// 多线程高速路径：12 线程上限，8 路向量累加 + 80KB 双缓冲\n",
      "__global__ void kernel_var_multi8(float *inp, float *out, size_t nr_elems) {\n",
      "    const int tid = threadIdx.x;\n",
      "    const int T   = blockDim.x;\n",
      "\n",
      "    tops_dte_ctx_t ctx;\n",
      "    tops::dte_scope scope(ctx);\n",
      "\n",
      "    if (nr_elems <= 1) {\n",
      "        if (tid == 0) {\n",
      "            float zero = 0.0f;\n",
      "            tops::memcpy(ctx,\n",
      "                tops::mdspan(tops::Global, out, 1),\n",
      "                tops::mdspan(tops::Private, &zero, 1)\n",
      "            );\n",
      "        }\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    const size_t elems_per_thread = (nr_elems + (size_t)T - 1) / (size_t)T;\n",
      "    const size_t start = (size_t)tid * elems_per_thread;\n",
      "    size_t end = start + elems_per_thread;\n",
      "    if (end > nr_elems) end = nr_elems;\n",
      "\n",
      "    const int VLEN = tops::vlength<vfloat>();     // 32\n",
      "    const int TILE = VLEN * 640;                  // 20480 floats (~80KB) per buffer\n",
      "    __valigned__ float buf0[TILE];\n",
      "    __valigned__ float buf1[TILE];\n",
      "\n",
      "    auto vs0 = tops::vzero<vfloat>(), vs1 = tops::vzero<vfloat>();\n",
      "    auto vs2 = tops::vzero<vfloat>(), vs3 = tops::vzero<vfloat>();\n",
      "    auto vs4 = tops::vzero<vfloat>(), vs5 = tops::vzero<vfloat>();\n",
      "    auto vs6 = tops::vzero<vfloat>(), vs7 = tops::vzero<vfloat>();\n",
      "    auto vq0 = tops::vzero<vfloat>(), vq1 = tops::vzero<vfloat>();\n",
      "    auto vq2 = tops::vzero<vfloat>(), vq3 = tops::vzero<vfloat>();\n",
      "    auto vq4 = tops::vzero<vfloat>(), vq5 = tops::vzero<vfloat>();\n",
      "    auto vq6 = tops::vzero<vfloat>(), vq7 = tops::vzero<vfloat>();\n",
      "\n",
      "    float tail_sum = 0.f, tail_sqs = 0.f;\n",
      "\n",
      "    if (start < end) {\n",
      "        size_t i = start;\n",
      "        int cur_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\n",
      "        tops::event ev = tops::memcpy_async(\n",
      "            ctx,\n",
      "            tops::mdspan(tops::Private, buf0, cur_len),\n",
      "            tops::mdspan(tops::Global,  inp + i, cur_len)\n",
      "        );\n",
      "        i += cur_len;\n",
      "        bool use0 = true;\n",
      "\n",
      "        while (true) {\n",
      "            bool has_next = (i < end);\n",
      "            tops::event ev_next;\n",
      "            int nxt_len = 0;\n",
      "            if (has_next) {\n",
      "                nxt_len = (int)((end - i) < (size_t)TILE ? (end - i) : (size_t)TILE);\n",
      "                ev_next = tops::memcpy_async(\n",
      "                    ctx,\n",
      "                    tops::mdspan(tops::Private, use0 ? buf1 : buf0, nxt_len),\n",
      "                    tops::mdspan(tops::Global,  inp + i, nxt_len)\n",
      "                );\n",
      "                i += nxt_len;\n",
      "            }\n",
      "\n",
      "            tops::wait(ev);\n",
      "            float *cur = use0 ? buf0 : buf1;\n",
      "            const int n = cur_len;\n",
      "\n",
      "            int j = 0;\n",
      "            const int vec8 = (n / (8*VLEN)) * (8*VLEN);\n",
      "            #pragma unroll 2\n",
      "            for (; j < vec8; j += 8*VLEN) {\n",
      "                auto v0 = tops::vload<vfloat>(cur + j + 0*VLEN);\n",
      "                auto v1 = tops::vload<vfloat>(cur + j + 1*VLEN);\n",
      "                auto v2 = tops::vload<vfloat>(cur + j + 2*VLEN);\n",
      "                auto v3 = tops::vload<vfloat>(cur + j + 3*VLEN);\n",
      "                auto v4 = tops::vload<vfloat>(cur + j + 4*VLEN);\n",
      "                auto v5 = tops::vload<vfloat>(cur + j + 5*VLEN);\n",
      "                auto v6 = tops::vload<vfloat>(cur + j + 6*VLEN);\n",
      "                auto v7 = tops::vload<vfloat>(cur + j + 7*VLEN);\n",
      "\n",
      "                vs0 = tops::vadd(vs0, v0);\n",
      "                vs1 = tops::vadd(vs1, v1);\n",
      "                vs2 = tops::vadd(vs2, v2);\n",
      "                vs3 = tops::vadd(vs3, v3);\n",
      "                vs4 = tops::vadd(vs4, v4);\n",
      "                vs5 = tops::vadd(vs5, v5);\n",
      "                vs6 = tops::vadd(vs6, v6);\n",
      "                vs7 = tops::vadd(vs7, v7);\n",
      "\n",
      "                auto w0 = tops::vmul<vfloat>(v0, v0);\n",
      "                auto w1 = tops::vmul<vfloat>(v1, v1);\n",
      "                auto w2 = tops::vmul<vfloat>(v2, v2);\n",
      "                auto w3 = tops::vmul<vfloat>(v3, v3);\n",
      "                auto w4 = tops::vmul<vfloat>(v4, v4);\n",
      "                auto w5 = tops::vmul<vfloat>(v5, v5);\n",
      "                auto w6 = tops::vmul<vfloat>(v6, v6);\n",
      "                auto w7 = tops::vmul<vfloat>(v7, v7);\n",
      "\n",
      "                vq0 = tops::vadd(vq0, w0);\n",
      "                vq1 = tops::vadd(vq1, w1);\n",
      "                vq2 = tops::vadd(vq2, w2);\n",
      "                vq3 = tops::vadd(vq3, w3);\n",
      "                vq4 = tops::vadd(vq4, w4);\n",
      "                vq5 = tops::vadd(vq5, w5);\n",
      "                vq6 = tops::vadd(vq6, w6);\n",
      "                vq7 = tops::vadd(vq7, w7);\n",
      "            }\n",
      "\n",
      "            const int vec1 = ((n - j) / VLEN) * VLEN;\n",
      "            for (int t = 0; t < vec1; t += VLEN, j += VLEN) {\n",
      "                auto v = tops::vload<vfloat>(cur + j);\n",
      "                vs0 = tops::vadd(vs0, v);\n",
      "                auto w = tops::vmul<vfloat>(v, v);\n",
      "                vq0 = tops::vadd(vq0, w);\n",
      "            }\n",
      "\n",
      "            for (; j < n; ++j) {\n",
      "                float x = cur[j];\n",
      "                tail_sum += x;\n",
      "                tail_sqs += x * x;\n",
      "            }\n",
      "\n",
      "            if (!has_next) break;\n",
      "            use0 = !use0;\n",
      "            cur_len = nxt_len;\n",
      "            ev = ev_next;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    // 合并 8 向量累加器\n",
      "    auto vs01 = tops::vadd(vs0, vs1);\n",
      "    auto vs23 = tops::vadd(vs2, vs3);\n",
      "    auto vs45 = tops::vadd(vs4, vs5);\n",
      "    auto vs67 = tops::vadd(vs6, vs7);\n",
      "    auto vs0123 = tops::vadd(vs01, vs23);\n",
      "    auto vs4567 = tops::vadd(vs45, vs67);\n",
      "    auto vs = tops::vadd(vs0123, vs4567);\n",
      "\n",
      "    auto vq01 = tops::vadd(vq0, vq1);\n",
      "    auto vq23 = tops::vadd(vq2, vq3);\n",
      "    auto vq45 = tops::vadd(vq4, vq5);\n",
      "    auto vq67 = tops::vadd(vq6, vq7);\n",
      "    auto vq0123 = tops::vadd(vq01, vq23);\n",
      "    auto vq4567 = tops::vadd(vq45, vq67);\n",
      "    auto vq = tops::vadd(vq0123, vq4567);\n",
      "\n",
      "    __valigned__ float tmp[128];\n",
      "    tops::vstore(vs, tmp);\n",
      "    float psum = tail_sum;\n",
      "    #pragma unroll\n",
      "    for (int k = 0; k < VLEN; ++k) psum += tmp[k];\n",
      "\n",
      "    tops::vstore(vq, tmp);\n",
      "    float psqs = tail_sqs;\n",
      "    #pragma unroll\n",
      "    for (int k = 0; k < VLEN; ++k) psqs += tmp[k];\n",
      "\n",
      "    // 线程间合并：Private -> Shared\n",
      "    extern __shared__ float s_partials[]; // 2*T floats\n",
      "    float pair[2] = {psum, psqs};\n",
      "    tops::memcpy(ctx,\n",
      "        tops::mdspan(tops::Shared,  s_partials + 2*tid, 2),\n",
      "        tops::mdspan(tops::Private, pair, 2)\n",
      "    );\n",
      "\n",
      "    __syncthreads();\n",
      "\n",
      "    if (tid == 0) {\n",
      "        const int n_pairs = 2 * T;\n",
      "        __valigned__ float redbuf[24]; // 支持 T<=12\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Private, redbuf, n_pairs),\n",
      "            tops::mdspan(tops::Shared,  s_partials, n_pairs)\n",
      "        );\n",
      "\n",
      "        float tot_sum = 0.f, tot_sqs = 0.f;\n",
      "        #pragma unroll\n",
      "        for (int k = 0; k < T; ++k) {\n",
      "            tot_sum += redbuf[2*k + 0];\n",
      "            tot_sqs += redbuf[2*k + 1];\n",
      "        }\n",
      "\n",
      "        float Nf = (float)nr_elems;\n",
      "        float mu = tot_sum / Nf;\n",
      "        float var = (tot_sqs - mu * tot_sum) / (Nf - 1.0f);\n",
      "        if (var < 0.f && var > -1e-12f) var = 0.f;\n",
      "\n",
      "        tops::memcpy(ctx,\n",
      "            tops::mdspan(tops::Global, out, 1),\n",
      "            tops::mdspan(tops::Private, &var, 1)\n",
      "        );\n",
      "    }\n",
      "}\n",
      "\n",
      "void GCU_VAR(float * __restrict dev_inp,\n",
      "             float * __restrict dev_out,\n",
      "             const int nr_elems) {\n",
      "    if (nr_elems <= 1) {\n",
      "        kernel_var_single3<<<dim3(1,1,1), dim3(1,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "        topsError_t e1 = topsGetLastError(); (void)e1;\n",
      "        topsError_t e2 = topsDeviceSynchronize(); (void)e2;\n",
      "        return;\n",
      "    }\n",
      "\n",
      "    // 自适应线程策略：小规模单线程；中规模 4/8 线程；大规模 12 线程\n",
      "    int T = 12;\n",
      "    if (nr_elems < 16384)            { kernel_var_single3<<<dim3(1), dim3(1)>>>(dev_inp, dev_out, (size_t)nr_elems); topsError_t e1 = topsGetLastError(); (void)e1; topsError_t e2 = topsDeviceSynchronize(); (void)e2; return; }\n",
      "    else if (nr_elems < 131072)      T = 4;   // 16K - 128K\n",
      "    else if (nr_elems < 1048576)     T = 8;   // 128K - 1M\n",
      "    else                             T = 12;  // >= 1M\n",
      "\n",
      "    const dim3 grid(1,1,1);\n",
      "    const dim3 block(T,1,1);\n",
      "    const size_t shmem = (size_t)T * 2 * sizeof(float);\n",
      "\n",
      "    kernel_var_multi8<<<grid, block, shmem>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "\n",
      "    topsError_t err = topsGetLastError(); (void)err;\n",
      "    topsError_t sync_err = topsDeviceSynchronize(); (void)sync_err;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mols[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6f654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <tops/tops_runtime.h>\n",
      "#include <tops.h>\n",
      "\n",
      "// SiLU: y = x * sigmoid(x)\n",
      "__device__ __forceinline__ float silu_scalar(float x) {\n",
      "  return x / (1.0f + expf(-x));\n",
      "}\n",
      "__device__ __forceinline__ vfloat silu_vector(vfloat vx) {\n",
      "  auto vs = tops::vsigmoid(vx);\n",
      "  return tops::vmul<vfloat>(vx, vs);\n",
      "}\n",
      "\n",
      "__device__ __forceinline__ void silu_inplace_vec(float* __restrict buf, int len, const int VLEN) {\n",
      "  int j = 0;\n",
      "  const int vec = (len / VLEN) * VLEN;\n",
      "\n",
      "  // 8x unroll, then 4x, then single, then scalar tail\n",
      "  for (; j + 8*VLEN <= vec; j += 8*VLEN) {\n",
      "    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\n",
      "    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\n",
      "    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\n",
      "    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\n",
      "    auto v4 = tops::vload<vfloat>(buf + j + 4*VLEN);\n",
      "    auto v5 = tops::vload<vfloat>(buf + j + 5*VLEN);\n",
      "    auto v6 = tops::vload<vfloat>(buf + j + 6*VLEN);\n",
      "    auto v7 = tops::vload<vfloat>(buf + j + 7*VLEN);\n",
      "    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\n",
      "    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\n",
      "    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\n",
      "    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\n",
      "    tops::vstore(silu_vector(v4), buf + j + 4*VLEN);\n",
      "    tops::vstore(silu_vector(v5), buf + j + 5*VLEN);\n",
      "    tops::vstore(silu_vector(v6), buf + j + 6*VLEN);\n",
      "    tops::vstore(silu_vector(v7), buf + j + 7*VLEN);\n",
      "  }\n",
      "  for (; j + 4*VLEN <= vec; j += 4*VLEN) {\n",
      "    auto v0 = tops::vload<vfloat>(buf + j + 0*VLEN);\n",
      "    auto v1 = tops::vload<vfloat>(buf + j + 1*VLEN);\n",
      "    auto v2 = tops::vload<vfloat>(buf + j + 2*VLEN);\n",
      "    auto v3 = tops::vload<vfloat>(buf + j + 3*VLEN);\n",
      "    tops::vstore(silu_vector(v0), buf + j + 0*VLEN);\n",
      "    tops::vstore(silu_vector(v1), buf + j + 1*VLEN);\n",
      "    tops::vstore(silu_vector(v2), buf + j + 2*VLEN);\n",
      "    tops::vstore(silu_vector(v3), buf + j + 3*VLEN);\n",
      "  }\n",
      "  for (; j + VLEN <= vec; j += VLEN) {\n",
      "    auto vx = tops::vload<vfloat>(buf + j);\n",
      "    tops::vstore(silu_vector(vx), buf + j);\n",
      "  }\n",
      "  for (; j < len; ++j) {\n",
      "    buf[j] = silu_scalar(buf[j]);\n",
      "  }\n",
      "}\n",
      "\n",
      "// Double-buffer async pipeline with balanced thread partition\n",
      "__global__ void kernel_silu_db_opt(float* __restrict inp,\n",
      "                                   float* __restrict out,\n",
      "                                   size_t nr_elems) {\n",
      "  if (nr_elems == 0) return;\n",
      "\n",
      "  // Flattened thread id\n",
      "  const int tpb  = blockDim.x * blockDim.y * blockDim.z;\n",
      "  const int tidb = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * (blockDim.x * blockDim.y);\n",
      "  const int bid  = blockIdx.x + blockIdx.y * gridDim.x + blockIdx.z * (gridDim.x * gridDim.y);\n",
      "  const size_t gid = (size_t)bid * (size_t)tpb + (size_t)tidb;\n",
      "  const size_t T   = (size_t)gridDim.x * gridDim.y * gridDim.z * (size_t)tpb;\n",
      "\n",
      "  if (gid >= T) return;\n",
      "\n",
      "  // Balanced 1D partition: base + first 'rem' threads take one extra\n",
      "  const size_t base = nr_elems / T;\n",
      "  const size_t rem  = nr_elems - base * T;\n",
      "  const size_t start = gid * base + (gid < rem ? gid : rem);\n",
      "  const size_t span  = base + (gid < rem ? 1u : 0u);\n",
      "  if (span == 0) return;\n",
      "  const size_t end = start + span;\n",
      "\n",
      "  const int VLEN = tops::vlength<vfloat>(); // 32 for float (128B)\n",
      "\n",
      "  // Tile policy: choose larger tiles for larger spans to amortize DMA/event overhead\n",
      "  static constexpr int TILE_TINY  = 12288;   // 48KB per buffer (tiny span sync path)\n",
      "  static constexpr int TILE_MID   = 49152;   // 192KB per buffer (double buffer)\n",
      "  static constexpr int TILE_LARGE = 65536;   // 256KB per buffer (double buffer)\n",
      "  const int TILE = (span >= (1u<<20)) ? TILE_LARGE : ((span >= (256u<<10)) ? TILE_MID : 32768);\n",
      "\n",
      "  auto min_int = [](size_t a, size_t b)->int { return (int)(a < b ? a : b); };\n",
      "\n",
      "  // Tiny span path: single sync copy -> compute -> sync copy back\n",
      "  if (span <= (size_t)TILE_TINY) {\n",
      "    __valigned__ float buf[TILE_TINY];\n",
      "    const int len = (int)span;\n",
      "\n",
      "    tops_dte_ctx_t c;\n",
      "    tops::dte_scope s(c);\n",
      "\n",
      "    tops::memcpy(c,\n",
      "      tops::mdspan(tops::Private, buf,         len),\n",
      "      tops::mdspan(tops::Global,  inp + start, len));\n",
      "\n",
      "    silu_inplace_vec(buf, len, VLEN);\n",
      "\n",
      "    tops::memcpy(c,\n",
      "      tops::mdspan(tops::Global,  out + start, len),\n",
      "      tops::mdspan(tops::Private, buf,         len));\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  // Double buffer pipeline\n",
      "  __valigned__ float buf0[TILE_LARGE];\n",
      "  __valigned__ float buf1[TILE_LARGE];\n",
      "\n",
      "  tops_dte_ctx_t ctx_ld[2];\n",
      "  tops_dte_ctx_t ctx_st[2];\n",
      "  tops::dte_scope sld0(ctx_ld[0]), sld1(ctx_ld[1]);\n",
      "  tops::dte_scope sst0(ctx_st[0]), sst1(ctx_st[1]);\n",
      "\n",
      "  tops::event ev_ld[2];\n",
      "  tops::event ev_st[2];\n",
      "  bool has_tile[2]    = {false, false};\n",
      "  bool st_inflight[2] = {false, false};\n",
      "  size_t pos[2]       = {0, 0};\n",
      "  int    len[2]       = {0, 0};\n",
      "\n",
      "  size_t cursor = start;\n",
      "\n",
      "  // Preload buf0, then buf1\n",
      "  pos[0] = cursor;\n",
      "  len[0] = min_int(end - cursor, (size_t)TILE);\n",
      "  if (len[0] > 0) {\n",
      "    ev_ld[0] = tops::memcpy_async(\n",
      "        ctx_ld[0],\n",
      "        tops::mdspan(tops::Private, buf0,        len[0]),\n",
      "        tops::mdspan(tops::Global,  inp + cursor, len[0]));\n",
      "    has_tile[0] = true;\n",
      "    cursor += len[0];\n",
      "  }\n",
      "\n",
      "  pos[1] = cursor;\n",
      "  len[1] = min_int(end - cursor, (size_t)TILE);\n",
      "  if (len[1] > 0) {\n",
      "    ev_ld[1] = tops::memcpy_async(\n",
      "        ctx_ld[1],\n",
      "        tops::mdspan(tops::Private, buf1,        len[1]),\n",
      "        tops::mdspan(tops::Global,  inp + cursor, len[1]));\n",
      "    has_tile[1] = true;\n",
      "    cursor += len[1];\n",
      "  }\n",
      "\n",
      "  int cur = 0;      // buffer to compute\n",
      "  int nxt = 1;      // buffer to compute next\n",
      "\n",
      "  while (has_tile[0] || has_tile[1]) {\n",
      "    if (!has_tile[cur]) { int tmp = cur; cur = nxt; nxt = tmp; }\n",
      "    if (!has_tile[cur]) break;\n",
      "\n",
      "    // Wait load done for current tile\n",
      "    tops::wait(ev_ld[cur]);\n",
      "\n",
      "    // Compute SiLU in-place on L1\n",
      "    float* inout = (cur == 0 ? buf0 : buf1);\n",
      "    silu_inplace_vec(inout, len[cur], VLEN);\n",
      "\n",
      "    // Launch async store for current tile (ensure prior store finished)\n",
      "    if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\n",
      "    ev_st[cur] = tops::memcpy_async(\n",
      "        ctx_st[cur],\n",
      "        tops::mdspan(tops::Global,  out + pos[cur], len[cur]),\n",
      "        tops::mdspan(tops::Private, inout,          len[cur]));\n",
      "    st_inflight[cur] = true;\n",
      "\n",
      "    // Current tile consumed\n",
      "    has_tile[cur] = false;\n",
      "\n",
      "    // Prefetch next tile into 'cur' (the buffer we just stored) if input remains\n",
      "    if (cursor < end) {\n",
      "      // Make sure we don't overwrite while store is still in-flight on 'cur'\n",
      "      if (st_inflight[cur]) { tops::wait(ev_st[cur]); st_inflight[cur] = false; }\n",
      "      pos[cur] = cursor;\n",
      "      len[cur] = min_int(end - cursor, (size_t)TILE);\n",
      "      ev_ld[cur] = tops::memcpy_async(\n",
      "          ctx_ld[cur],\n",
      "          tops::mdspan(tops::Private, (cur == 0 ? buf0 : buf1), len[cur]),\n",
      "          tops::mdspan(tops::Global,  inp + cursor,              len[cur]));\n",
      "      has_tile[cur] = (len[cur] > 0);\n",
      "      cursor += len[cur];\n",
      "    }\n",
      "\n",
      "    // Swap buffers: compute next on 'nxt' if it has a prefetched tile\n",
      "    int tmp = cur; cur = nxt; nxt = tmp;\n",
      "  }\n",
      "\n",
      "  // Drain outstanding stores\n",
      "  if (st_inflight[0]) tops::wait(ev_st[0]);\n",
      "  if (st_inflight[1]) tops::wait(ev_st[1]);\n",
      "}\n",
      "\n",
      "void GCU_SILU(float * __restrict dev_inp,\n",
      "              float * __restrict dev_out,\n",
      "              const int nr_elems) {\n",
      "  if (nr_elems <= 0) return;\n",
      "\n",
      "  // Prefer maximum threads on i20; keep small-N under-subscription to reduce overhead\n",
      "  int threads = 12;\n",
      "  if (nr_elems < 4096)        threads = 1;\n",
      "  else if (nr_elems < 16384)  threads = 4;\n",
      "  else if (nr_elems < 65536)  threads = 8;\n",
      "\n",
      "  // Target per-thread work; larger for large N to amortize kernel/DMA overhead\n",
      "  size_t target_per_thr;\n",
      "  if (nr_elems >= 8*1024*1024)      target_per_thr = 512u * 1024u; // >= 8M\n",
      "  else if (nr_elems >= 1*1024*1024) target_per_thr = 384u * 1024u; // 1M~8M\n",
      "  else if (nr_elems >= 128*1024)    target_per_thr = 256u * 1024u; // 128K~1M\n",
      "  else                              target_per_thr = 128u * 1024u; // <128K\n",
      "\n",
      "  size_t total_thr_need = ((size_t)nr_elems + target_per_thr - 1) / target_per_thr;\n",
      "  if (total_thr_need == 0) total_thr_need = 1;\n",
      "\n",
      "  int blocks = (int)((total_thr_need + threads - 1) / threads);\n",
      "  if (blocks < 1) blocks = 1;\n",
      "  if (blocks > 65535) blocks = 65535;\n",
      "\n",
      "  kernel_silu_db_opt<<<dim3(blocks,1,1), dim3(threads,1,1)>>>(dev_inp, dev_out, (size_t)nr_elems);\n",
      "  (void)topsGetLastError();\n",
      "  (void)topsDeviceSynchronize();\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mols[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145650fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
