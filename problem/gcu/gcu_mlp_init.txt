<candidate>
#include <tops/tops_runtime.h>
#include <math.h>

// -------- SiLU（数值稳健）---------
__device__ __forceinline__ float silu_fast(float x) {
    return x / (1.f + expf(-x));
}

// -------- Tile 尺寸（适度放大，减少DMA次数；L1占用仍很小）---------
#ifndef K_TILE
#define K_TILE   512    // hidden 方向分块
#endif
#ifndef J_TILE
#define J_TILE   512    // intermediate 方向分块
#endif
#ifndef H_TILE
#define H_TILE   512    // 输出 hidden 方向分块
#endif

// 不使用 cooperative 属性，避免 gcu2X 的 cooperative 限制
__attribute__((global))
void kernel_mlp(float *__restrict gate_w,   // [hidden, inter] 行主
                float *__restrict up_w,     // [hidden, inter] 行主
                float *__restrict down_w,   // [inter,  hidden] 行主
                float *__restrict inp,      // [seq,   hidden] 行主
                float *__restrict out,      // [seq,   hidden] 行主
                const int seq_len,
                const int hidden_size,
                const int inter_size) {

    // —— grid-stride: 每个线程可覆盖多行 —— 
    int tid_global = blockIdx.x * blockDim.x + threadIdx.x;
    int stride     = gridDim.x * blockDim.x;
    if (tid_global >= seq_len && stride <= 0) return; // 防御

    // -------- DTE ctx（线程私有）--------
    tops_dte_ctx_t ctx_in, ctx_wg, ctx_wu, ctx_wd, ctx_out;
    ctx_in.init();  ctx_wg.init();  ctx_wu.init();  ctx_wd.init();  ctx_out.init();

    // -------- L1 缓冲：全部 __valigned__，仅存一小片 tile --------
    __local__ __valigned__ char l1_buf[104000];
    int used = 0;

    // 输入片段（K_TILE）
    float *input_tile = reinterpret_cast<float *>(l1_buf + used);
    used += K_TILE * sizeof(float);

    // gate/up 的累加器（J_TILE）
    float *gate_acc   = reinterpret_cast<float *>(l1_buf + used);
    used += J_TILE * sizeof(float);
    float *up_acc     = reinterpret_cast<float *>(l1_buf + used);
    used += J_TILE * sizeof(float);

    // act（J_TILE）+ 权重临时缓冲（J_TILE）
    float *act_tile   = reinterpret_cast<float *>(l1_buf + used);
    used += J_TILE * sizeof(float);
    float *wj_buf     = reinterpret_cast<float *>(l1_buf + used);
    used += J_TILE * sizeof(float);

    // down_w 的一段（H_TILE） + out 的 H 方向累加器（H_TILE）
    float *dw_buf     = reinterpret_cast<float *>(l1_buf + used);
    used += H_TILE * sizeof(float);
    float *out_tile   = reinterpret_cast<float *>(l1_buf + used);
    used += H_TILE * sizeof(float);

    for (int r = tid_global; r < seq_len; r += stride) {
        // —— H 方向输出分块 —— 
        for (int h0 = 0; h0 < hidden_size; h0 += H_TILE) {
            const int h_blk = (h0 + H_TILE <= hidden_size) ? H_TILE : (hidden_size - h0);

            // out_tile 清零
            for (int t = 0; t < h_blk; ++t) out_tile[t] = 0.f;

            // —— J 方向分块：先算 act_tile，再累加到 out_tile —— 
            for (int j0 = 0; j0 < inter_size; j0 += J_TILE) {
                const int j_blk = (j0 + J_TILE <= inter_size) ? J_TILE : (inter_size - j0);

                // gate/up 累加器清零
                for (int j = 0; j < j_blk; ++j) {
                    gate_acc[j] = 0.f;
                    up_acc[j]   = 0.f;
                }

                // ---- K 方向分块：读 input 段 + 读权重行段并累加 ----
                for (int k0 = 0; k0 < hidden_size; k0 += K_TILE) {
                    const int k_blk = (k0 + K_TILE <= hidden_size) ? K_TILE : (hidden_size - k0);

                    // 1) 读 input[r, k0:k1] → input_tile
                    {
                        tops::mdspan g_in_seg(tops::Global, inp + (size_t)r * hidden_size + k0, k_blk);
                        tops::mdspan p_in_seg(tops::Private, input_tile, k_blk);
                        // Global → Private
                        tops::memcpy(ctx_in, p_in_seg, g_in_seg);
                    }

                    // 2) 对该 K 片的每个 k，读 gate_w/ up_w 的连续 j 段并累加
                    for (int kk = 0; kk < k_blk; ++kk) {
                        const int k = k0 + kk;
                        const float in_val = input_tile[kk];

                        // gate_w[k, j0:j1] → wj_buf
                        {
                            tops::mdspan g_w_row(tops::Global, gate_w + (size_t)k * inter_size + j0, j_blk);
                            tops::mdspan p_w_row(tops::Private, wj_buf, j_blk);
                            tops::memcpy(ctx_wg, p_w_row, g_w_row); // Global → Private
                            for (int j = 0; j < j_blk; ++j)
                                gate_acc[j] += in_val * wj_buf[j];
                        }
                        // up_w[k, j0:j1] → wj_buf
                        {
                            tops::mdspan g_w_row2(tops::Global, up_w + (size_t)k * inter_size + j0, j_blk);
                            tops::mdspan p_w_row2(tops::Private, wj_buf, j_blk);
                            tops::memcpy(ctx_wu, p_w_row2, g_w_row2); // Global → Private
                            for (int j = 0; j < j_blk; ++j)
                                up_acc[j] += in_val * wj_buf[j];
                        }
                    } // end kk
                } // end k0

                // 3) act_tile = silu(gate_acc) * up_acc
                for (int j = 0; j < j_blk; ++j)
                    act_tile[j] = silu_fast(gate_acc[j]) * up_acc[j];

                // 4) 用 act_tile 更新 out_tile[h] ：
                //    out_tile[h] += sum_{k=j0..j1-1} act[k] * down_w[k, h0:h1]
                for (int k = 0; k < j_blk; ++k) {
                    const int kg = j0 + k;
                    // 读 down_w[kg, h0:h1] → dw_buf（连续）
                    tops::mdspan g_dw_seg(tops::Global, down_w + (size_t)kg * hidden_size + h0, h_blk);
                    tops::mdspan p_dw_seg(tops::Private, dw_buf, h_blk);
                    tops::memcpy(ctx_wd, p_dw_seg, g_dw_seg); // Global → Private

                    const float a = act_tile[k];
                    for (int h = 0; h < h_blk; ++h)
                        out_tile[h] += a * dw_buf[h];
                }

            } // end j0

            // 5) 把 out_tile 写回 out[r, h0:h1]
            {
                tops::mdspan g_out_seg(tops::Global, out + (size_t)r * hidden_size + h0, h_blk);
                tops::mdspan p_out_seg(tops::Private, out_tile, h_blk);
                // *** Private → Global：目的在前、来源在后 ***
                tops::memcpy(ctx_out, g_out_seg, p_out_seg);
            }

        } // end h0
    } // end r grid-stride

    // -------- 销毁 ctx --------
    ctx_in.destroy(); ctx_wg.destroy(); ctx_wu.destroy(); ctx_wd.destroy(); ctx_out.destroy();
}

// ---------------- Host 接口 ----------------
void GCU_MLP(float *__restrict gate_proj_weight,
             float *__restrict up_proj_weight,
             float *__restrict down_proj_weight,
             float *__restrict input,
             float *__restrict output,
             const int seq_len,
             const int hidden_size,
             const int intermediate_size) {

    // gcu210: 每个 block ≤12 线程；用大 grid 并行 seq_len
    const int threads = (seq_len >= 12) ? 12 : (seq_len > 0 ? seq_len : 1);
    int blocks = (seq_len + threads - 1) / threads;
    if (blocks > 65535) blocks = 65535; // gcu2X 安全上限

    kernel_mlp<<<blocks, threads>>>(
        gate_proj_weight,
        up_proj_weight,
        down_proj_weight,
        input,
        output,
        seq_len,
        hidden_size,
        intermediate_size
    );
}
</candidate>
<score>52.87</score>
<log>testcase0 -> Passed
testcase1 -> Passed
testcase2 -> Passed
testcase3 -> Passed
testcase4 -> Passed
testcase5 -> Passed
testcase6 -> Passed
testcase7 -> MLP Test Failed! MisMatch at Index : [0, 596]. CPU vs GCU : 2.42433 vs 2.42558
testcase8 -> Passed
testcase9 -> Passed
</log>