<candidate>#include <tops/tops_runtime.h>

#define EPSILON 1e-6f

// ========== 辅助函数 ==========

// 快速倒平方根近似 (牛顿迭代)
__device__ __forceinline__ float fast_rsqrt(float x) {
    float y = 1.0f;
    for (int i = 0; i < 3; ++i) {
        y = 0.5f * y * (3.0f - x * y * y);
    }
    return y;
}

// 安全获取线程信息（如果 SDK 未提供 GetThreadIdx / GetThreadNum）
__device__ __forceinline__ int get_thread_idx() {
#ifdef GetThreadIdx
    return GetThreadIdx();
#else
    return threadIdx.x; // fallback
#endif
}

__device__ __forceinline__ int get_thread_num() {
#ifdef GetThreadNum
    return GetThreadNum();
#else
    return blockDim.x; // fallback
#endif
}

// ========== RMSNorm Kernel ==========

__attribute__((global, cooperative))
void rmsnorm_kernel(float *__restrict inp,
                    float *__restrict out,
                    int seq_len,
                    int dim) {
    // -----------------------------
    // Thread info
    // -----------------------------
    int thread_idx = get_thread_idx();
    int thread_num = get_thread_num();

    // -----------------------------
    // DTE context
    // -----------------------------
    tops_dte_ctx_t dte_in;
    tops_dte_ctx_t dte_out;
    dte_in.init();
    dte_out.init();

    // -----------------------------
    // 每线程处理若干行
    // -----------------------------
    int rows_per_thread = (seq_len + thread_num - 1) / thread_num;
    int start_row = thread_idx * rows_per_thread;
    int end_row = (start_row + rows_per_thread < seq_len)
                      ? (start_row + rows_per_thread)
                      : seq_len;

    // -----------------------------
    // L1 buffer
    // -----------------------------
    __local__ __valigned__ char l1_buffer[104000];
    float *row_buf = reinterpret_cast<float *>(l1_buffer);

    for (int r = start_row; r < end_row; ++r) {
        // 1️⃣ 从 L3 读入一行 (dim)
        tops::mdspan md_in_global(tops::Global, inp + r * dim, dim);
        tops::mdspan md_in_private(tops::Private, row_buf, dim);
        tops::memcpy(dte_in, md_in_private, md_in_global);

        // 2️⃣ 求平方均值
        float sum_sq = 0.f;
        for (int i = 0; i < dim; ++i) {
            float v = row_buf[i];
            sum_sq += v * v;
        }
        float mean_sq = sum_sq / (float)dim;

        // 3️⃣ 求倒平方根
        float inv_rms = fast_rsqrt(mean_sq + EPSILON);

        // 4️⃣ 归一化 (gamma=1)
        for (int i = 0; i < dim; ++i) {
            row_buf[i] = row_buf[i] * inv_rms;
        }

        // 5️⃣ 写回结果
        tops::mdspan md_out_global(tops::Global, out + r * dim, dim);
        tops::mdspan md_out_private(tops::Private, row_buf, dim);
        tops::memcpy(dte_out, md_out_global, md_out_private);
    }

    // -----------------------------
    // DTE 结束
    // -----------------------------
    dte_in.destroy();
    dte_out.destroy();
}

// ========== Host Wrapper ==========

void GCU_rmsnorm(float *__restrict dev_input,
                 float *__restrict dev_out,
                 const int seq_len,
                 const int dim) {
    static const size_t blocks = 1;
    static const size_t threads = 12; // gcu210 supports ≤12 threads
    rmsnorm_kernel<<<blocks, threads>>>(dev_input, dev_out, seq_len, dim);
}
</candidate>
<score>60.72</score>
<log>testcase0 -> Passed
testcase1 -> Passed
testcase2 -> Passed
testcase3 -> Passed
testcase4 -> Passed
testcase5 -> Passed
testcase6 -> Passed
testcase7 -> Passed
testcase8 -> Passed
testcase9 -> Passed
</log>