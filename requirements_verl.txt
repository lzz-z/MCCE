# MCCE - verl环境依赖
# 专门用于DPO (Direct Preference Optimization) 训练

# ============ 核心深度学习 ============
torch>=2.0.0
transformers>=4.30.0
accelerate>=1.0.0
einops>=0.8.0

# ============ DPO训练核心 ============
trl>=0.7.0  # Transformer Reinforcement Learning
datasets>=3.0.0
peft>=0.10.0  # Parameter-Efficient Fine-Tuning

# ============ 监控和日志 ============
swanlab>=0.3.0  # 实验追踪和可视化
wandb  # 可选的实验追踪工具

# ============ 模型优化 ============
bitsandbytes>=0.43.0  # 量化支持
flash-attn>=2.0.0  # Flash Attention加速

# ============ 数据处理 ============
numpy>=2.0.0
pandas>=2.0.0
scipy>=1.10.0
h5py>=3.8.0

# ============ 配置管理 ============
pyyaml>=6.0
hydra-core>=1.3.0
omegaconf>=2.3.0

# ============ 推理加速（可选）============
# vllm>=0.3.0  # 高效推理引擎
# xformers>=0.0.20  # 额外的注意力优化

# ============ 工具库 ============
tqdm>=4.65.0
requests>=2.31.0
cloudpickle>=3.0.0
joblib>=1.5.0

# ============ API支持 ============
openai>=1.0.0
google-generativeai>=0.8.0
tiktoken>=0.5.0

# ============ 实用工具 ============
click>=8.1.0
colorful>=0.5.0
fastapi>=0.100.0  # API服务支持

